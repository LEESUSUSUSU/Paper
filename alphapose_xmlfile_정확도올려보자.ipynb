{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/somoon0422/Paper/blob/main/alphapose_xmlfile_%EC%A0%95%ED%99%95%EB%8F%84%EC%98%AC%EB%A0%A4%EB%B3%B4%EC%9E%90.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITXFPsQFu_8P"
      },
      "source": [
        "**I modified the Pillow installation part of the AlphaPose Colab example program.**\n",
        "\n",
        "**This is not thoth000's original program.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cxMU0dmlnCT",
        "outputId": "45c64857-ab95-4249-d77f-2739b96bd64e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyyaml==5.2\n",
            "  Downloading PyYAML-5.2.tar.gz (265 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.26.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "2.4.1+cu121\n",
            "6.0.2\n",
            "1.13.1\n"
          ]
        }
      ],
      "source": [
        "! pip install pyyaml==5.2\n",
        "! pip install scipy\n",
        "! pip install numpy\n",
        "! pip3 install torch torchvision --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "import yaml, scipy, os\n",
        "print(yaml.__version__)\n",
        "print(scipy.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VBhQTOSoWab",
        "outputId": "601b8272-0881-47ff-ac6e-8c92b64872b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AlphaPose'...\n",
            "remote: Enumerating objects: 2749, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 2749 (delta 4), reused 1 (delta 0), pack-reused 2739 (from 1)\u001b[K\n",
            "Receiving objects: 100% (2749/2749), 118.82 MiB | 37.69 MiB/s, done.\n",
            "Resolving deltas: 100% (1379/1379), done.\n"
          ]
        }
      ],
      "source": [
        "!rm -rf /content/AlphaPose\n",
        "os.chdir('/content/')\n",
        "!git clone https://github.com/MVIG-SJTU/AlphaPose.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkkNtO8qolbz",
        "outputId": "3fe12b5a-2b8c-45a6-b301-8f7a8a9fc94b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (3.0.11)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  libyaml-doc\n",
            "The following NEW packages will be installed:\n",
            "  libyaml-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 62.8 kB of archives.\n",
            "After this operation, 257 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libyaml-dev amd64 0.2.2-1build2 [62.8 kB]\n",
            "Fetched 62.8 kB in 1s (104 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libyaml-dev:amd64.\n",
            "(Reading database ... 123599 files and directories currently installed.)\n",
            "Preparing to unpack .../libyaml-dev_0.2.2-1build2_amd64.deb ...\n",
            "Unpacking libyaml-dev:amd64 (0.2.2-1build2) ...\n",
            "Setting up libyaml-dev:amd64 (0.2.2-1build2) ...\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install cython\n",
        "!sudo apt-get install libyaml-dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-Gw3k4coyFD",
        "outputId": "f50f399e-da86-45e0-c189-bb9e1fe2baa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AlphaPose\n",
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "Compiling detector/nms/src/soft_nms_cpu.pyx because it changed.\n",
            "[1/1] Cythonizing detector/nms/src/soft_nms_cpu.pyx\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/__init__.py:85: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Requirements should be satisfied by a PEP 517 installer.\n",
            "        If you are using pip, you can try `pip install --use-pep517`.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  dist.fetch_build_eggs(dist.setup_requires)\n",
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib.linux-x86_64-cpython-310\n",
            "creating build/lib.linux-x86_64-cpython-310/trackers\n",
            "copying trackers/tracker_cfg.py -> build/lib.linux-x86_64-cpython-310/trackers\n",
            "copying trackers/tracker_api.py -> build/lib.linux-x86_64-cpython-310/trackers\n",
            "copying trackers/__init__.py -> build/lib.linux-x86_64-cpython-310/trackers\n",
            "creating build/lib.linux-x86_64-cpython-310/alphapose\n",
            "copying alphapose/opt.py -> build/lib.linux-x86_64-cpython-310/alphapose\n",
            "copying alphapose/version.py -> build/lib.linux-x86_64-cpython-310/alphapose\n",
            "copying alphapose/__init__.py -> build/lib.linux-x86_64-cpython-310/alphapose\n",
            "creating build/lib.linux-x86_64-cpython-310/trackers/tracking\n",
            "copying trackers/tracking/basetrack.py -> build/lib.linux-x86_64-cpython-310/trackers/tracking\n",
            "copying trackers/tracking/matching.py -> build/lib.linux-x86_64-cpython-310/trackers/tracking\n",
            "copying trackers/tracking/__init__.py -> build/lib.linux-x86_64-cpython-310/trackers/tracking\n",
            "creating build/lib.linux-x86_64-cpython-310/trackers/ReidModels\n",
            "copying trackers/ReidModels/resnet_fc.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels\n",
            "copying trackers/ReidModels/osnet_ain.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels\n",
            "copying trackers/ReidModels/bn_linear.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels\n",
            "copying trackers/ReidModels/ResNet.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels\n",
            "copying trackers/ReidModels/osnet.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels\n",
            "copying trackers/ReidModels/ResBnLin.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels\n",
            "copying trackers/ReidModels/net_utils.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels\n",
            "copying trackers/ReidModels/__init__.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels\n",
            "creating build/lib.linux-x86_64-cpython-310/trackers/tracking/utils\n",
            "copying trackers/tracking/utils/timer.py -> build/lib.linux-x86_64-cpython-310/trackers/tracking/utils\n",
            "copying trackers/tracking/utils/io.py -> build/lib.linux-x86_64-cpython-310/trackers/tracking/utils\n",
            "copying trackers/tracking/utils/kalman_filter.py -> build/lib.linux-x86_64-cpython-310/trackers/tracking/utils\n",
            "copying trackers/tracking/utils/utils.py -> build/lib.linux-x86_64-cpython-310/trackers/tracking/utils\n",
            "copying trackers/tracking/utils/__init__.py -> build/lib.linux-x86_64-cpython-310/trackers/tracking/utils\n",
            "copying trackers/tracking/utils/parse_config.py -> build/lib.linux-x86_64-cpython-310/trackers/tracking/utils\n",
            "copying trackers/tracking/utils/nms.py -> build/lib.linux-x86_64-cpython-310/trackers/tracking/utils\n",
            "creating build/lib.linux-x86_64-cpython-310/trackers/ReidModels/psroi_pooling\n",
            "copying trackers/ReidModels/psroi_pooling/__init__.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels/psroi_pooling\n",
            "copying trackers/ReidModels/psroi_pooling/build.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels/psroi_pooling\n",
            "creating build/lib.linux-x86_64-cpython-310/trackers/ReidModels/reid\n",
            "copying trackers/ReidModels/reid/image_part_aligned.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels/reid\n",
            "copying trackers/ReidModels/reid/__init__.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels/reid\n",
            "creating build/lib.linux-x86_64-cpython-310/trackers/ReidModels/classification\n",
            "copying trackers/ReidModels/classification/rfcn_cls.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels/classification\n",
            "copying trackers/ReidModels/classification/classifier.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels/classification\n",
            "copying trackers/ReidModels/classification/__init__.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels/classification\n",
            "creating build/lib.linux-x86_64-cpython-310/trackers/ReidModels/backbone\n",
            "copying trackers/ReidModels/backbone/googlenet.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels/backbone\n",
            "copying trackers/ReidModels/backbone/sqeezenet.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels/backbone\n",
            "copying trackers/ReidModels/backbone/lrn.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels/backbone\n",
            "copying trackers/ReidModels/backbone/__init__.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels/backbone\n",
            "creating build/lib.linux-x86_64-cpython-310/trackers/ReidModels/psroi_pooling/modules\n",
            "copying trackers/ReidModels/psroi_pooling/modules/psroi_pool.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels/psroi_pooling/modules\n",
            "copying trackers/ReidModels/psroi_pooling/modules/__init__.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels/psroi_pooling/modules\n",
            "creating build/lib.linux-x86_64-cpython-310/trackers/ReidModels/psroi_pooling/functions\n",
            "copying trackers/ReidModels/psroi_pooling/functions/__init__.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels/psroi_pooling/functions\n",
            "copying trackers/ReidModels/psroi_pooling/functions/psroi_pooling.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels/psroi_pooling/functions\n",
            "creating build/lib.linux-x86_64-cpython-310/trackers/ReidModels/psroi_pooling/_ext\n",
            "copying trackers/ReidModels/psroi_pooling/_ext/__init__.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels/psroi_pooling/_ext\n",
            "creating build/lib.linux-x86_64-cpython-310/trackers/ReidModels/psroi_pooling/_ext/psroi_pooling\n",
            "copying trackers/ReidModels/psroi_pooling/_ext/psroi_pooling/__init__.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels/psroi_pooling/_ext/psroi_pooling\n",
            "creating build/lib.linux-x86_64-cpython-310/alphapose/models\n",
            "copying alphapose/models/hardnet.py -> build/lib.linux-x86_64-cpython-310/alphapose/models\n",
            "copying alphapose/models/fastpose_duc_dense.py -> build/lib.linux-x86_64-cpython-310/alphapose/models\n",
            "copying alphapose/models/simple3dposeSMPLWithCam.py -> build/lib.linux-x86_64-cpython-310/alphapose/models\n",
            "copying alphapose/models/criterion.py -> build/lib.linux-x86_64-cpython-310/alphapose/models\n",
            "copying alphapose/models/builder.py -> build/lib.linux-x86_64-cpython-310/alphapose/models\n",
            "copying alphapose/models/fastpose_duc.py -> build/lib.linux-x86_64-cpython-310/alphapose/models\n",
            "copying alphapose/models/__init__.py -> build/lib.linux-x86_64-cpython-310/alphapose/models\n",
            "copying alphapose/models/fastpose.py -> build/lib.linux-x86_64-cpython-310/alphapose/models\n",
            "copying alphapose/models/simplepose.py -> build/lib.linux-x86_64-cpython-310/alphapose/models\n",
            "copying alphapose/models/hrnet.py -> build/lib.linux-x86_64-cpython-310/alphapose/models\n",
            "creating build/lib.linux-x86_64-cpython-310/alphapose/utils\n",
            "copying alphapose/utils/writer_smpl.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils\n",
            "copying alphapose/utils/registry.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils\n",
            "copying alphapose/utils/render_pytorch3d.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils\n",
            "copying alphapose/utils/pPose_nms.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils\n",
            "copying alphapose/utils/bbox.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils\n",
            "copying alphapose/utils/config.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils\n",
            "copying alphapose/utils/writer.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils\n",
            "copying alphapose/utils/detector.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils\n",
            "copying alphapose/utils/logger.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils\n",
            "copying alphapose/utils/metrics.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils\n",
            "copying alphapose/utils/file_detector.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils\n",
            "copying alphapose/utils/webcam_detector.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils\n",
            "copying alphapose/utils/__init__.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils\n",
            "copying alphapose/utils/transforms.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils\n",
            "copying alphapose/utils/vis.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils\n",
            "copying alphapose/utils/env.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils\n",
            "creating build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/single_hand.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/mpii.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/halpe_68_noface_det.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/halpe_26_det.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/halpe_26.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/custom.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/coco_wholebody.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/halpe_136.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/halpe_coco_wholebody_26.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/halpe_coco_wholebody_26_det.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/halpe_136_det.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/coco_det.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/halpe_68_noface.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/halpe_coco_wholebody_136_det.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/coco_wholebody_det.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/__init__.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/halpe_coco_wholebody_136.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/mscoco.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/concat_dataset.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/single_hand_det.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "creating build/lib.linux-x86_64-cpython-310/alphapose/utils/presets\n",
            "copying alphapose/utils/presets/simple_transform.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils/presets\n",
            "copying alphapose/utils/presets/__init__.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils/presets\n",
            "copying alphapose/utils/presets/simple_transform_3d_smpl.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils/presets\n",
            "creating build/lib.linux-x86_64-cpython-310/alphapose/utils/roi_align\n",
            "copying alphapose/utils/roi_align/__init__.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils/roi_align\n",
            "copying alphapose/utils/roi_align/roi_align.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils/roi_align\n",
            "running build_ext\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:495: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:414: UserWarning: The detected CUDA version (12.2) has a minor version mismatch with the version that was used to compile PyTorch (12.1). Most likely this shouldn't be a problem.\n",
            "  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:424: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 12.2\n",
            "  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
            "building 'detector.nms.soft_nms_cpu' extension\n",
            "creating build/temp.linux-x86_64-cpython-310\n",
            "creating build/temp.linux-x86_64-cpython-310/detector\n",
            "creating build/temp.linux-x86_64-cpython-310/detector/nms\n",
            "creating build/temp.linux-x86_64-cpython-310/detector/nms/src\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/numpy/core/include -I/usr/include/python3.10 -c detector/nms/src/soft_nms_cpu.cpp -o build/temp.linux-x86_64-cpython-310/detector/nms/src/soft_nms_cpu.o -Wno-unused-function -Wno-write-strings -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=soft_nms_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1929\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/numpy/core/include/numpy/arrayobject.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kdetector/nms/src/soft_nms_cpu.cpp:1268\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wcpp\u0007-Wcpp\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "creating build/lib.linux-x86_64-cpython-310/detector\n",
            "creating build/lib.linux-x86_64-cpython-310/detector/nms\n",
            "x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/detector/nms/src/soft_nms_cpu.o -L/usr/lib/x86_64-linux-gnu -o build/lib.linux-x86_64-cpython-310/detector/nms/soft_nms_cpu.cpython-310-x86_64-linux-gnu.so\n",
            "building 'detector.nms.nms_cpu' extension\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c detector/nms/src/nms_cpu.cpp -o build/temp.linux-x86_64-cpython-310/detector/nms/src/nms_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=nms_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/detector/nms/src/nms_cpu.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/local/cuda/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/detector/nms/nms_cpu.cpython-310-x86_64-linux-gnu.so\n",
            "building 'detector.nms.nms_cuda' extension\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c detector/nms/src/nms_cuda.cpp -o build/temp.linux-x86_64-cpython-310/detector/nms/src/nms_cuda.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=nms_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1965: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/AlphaPose/setup.py\", line 187, in <module>\n",
            "    setup(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/__init__.py\", line 108, in setup\n",
            "    return distutils.core.setup(**attrs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/core.py\", line 184, in setup\n",
            "    return run_commands(dist)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/core.py\", line 200, in run_commands\n",
            "    dist.run_commands()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/dist.py\", line 970, in run_commands\n",
            "    self.run_command(cmd)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/dist.py\", line 956, in run_command\n",
            "    super().run_command(command)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/dist.py\", line 989, in run_command\n",
            "    cmd_obj.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/command/build.py\", line 135, in run\n",
            "    self.run_command(cmd_name)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py\", line 316, in run_command\n",
            "    self.distribution.run_command(command)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/dist.py\", line 956, in run_command\n",
            "    super().run_command(command)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/dist.py\", line 989, in run_command\n",
            "    cmd_obj.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/command/build_ext.py\", line 93, in run\n",
            "    _build_ext.run(self)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/command/build_ext.py\", line 359, in run\n",
            "    self.build_extensions()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py\", line 866, in build_extensions\n",
            "    build_ext.build_extensions(self)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/command/build_ext.py\", line 479, in build_extensions\n",
            "    self._build_extensions_serial()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/command/build_ext.py\", line 505, in _build_extensions_serial\n",
            "    self.build_extension(ext)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/command/build_ext.py\", line 254, in build_extension\n",
            "    _build_ext.build_extension(self, ext)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/Cython/Distutils/build_ext.py\", line 135, in build_extension\n",
            "    super(build_ext, self).build_extension(ext)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/command/build_ext.py\", line 560, in build_extension\n",
            "    objects = self.compiler.compile(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/ccompiler.py\", line 605, in compile\n",
            "    self._compile(obj, src, ext, cc_args, extra_postargs, pp_opts)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py\", line 602, in unix_wrap_single_compile\n",
            "    cflags = unix_cuda_flags(cflags)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py\", line 569, in unix_cuda_flags\n",
            "    cflags + _get_cuda_arch_flags(cflags))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py\", line 1985, in _get_cuda_arch_flags\n",
            "    arch_list[-1] += '+PTX'\n",
            "IndexError: list index out of range\n"
          ]
        }
      ],
      "source": [
        "\n",
        "os.chdir('/content/AlphaPose')\n",
        "print(os.getcwd())\n",
        "! python setup.py build develop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9tg0Z2RznSv",
        "outputId": "03586dc0-72de-4f57-d2ad-b1856e8dc79f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-09-23 09:22:49--  https://github.com/Megvii-BaseDetection/YOLOX/releases/download/0.1.0/yolox_x.pth\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/386811486/24b68daf-00bc-41f7-8d5d-92d673d84a63?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240923%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240923T092249Z&X-Amz-Expires=300&X-Amz-Signature=771fead529861bd9a7c2ea7b9feef65c2c390370f65eb70d4f7ad2d7f6a901b2&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolox_x.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-09-23 09:22:49--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/386811486/24b68daf-00bc-41f7-8d5d-92d673d84a63?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240923%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240923T092249Z&X-Amz-Expires=300&X-Amz-Signature=771fead529861bd9a7c2ea7b9feef65c2c390370f65eb70d4f7ad2d7f6a901b2&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolox_x.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 793388371 (757M) [application/octet-stream]\n",
            "Saving to: ‘./detector/yolox/data/yolox_x.pth’\n",
            "\n",
            "yolox_x.pth         100%[===================>] 756.63M   255MB/s    in 3.0s    \n",
            "\n",
            "2024-09-23 09:22:52 (255 MB/s) - ‘./detector/yolox/data/yolox_x.pth’ saved [793388371/793388371]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "! mkdir /content/AlphaPose/detector/yolo/data\n",
        "file_id = '1D47msNOOiJKvPOXlnpyzdKA3k6E97NTC'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('/content/AlphaPose/detector/yolo/data/yolov3-spp.weights')\n",
        "\n",
        "! mkdir /content/AlphaPose/detector/tracker/data\n",
        "file_id = '1nlnuYfGNuHWZztQHXwVZSL_FvfE551pA'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('/content/AlphaPose/detector/tracker/data/JDE-1088x608-uncertainty')\n",
        "\n",
        "file_id = '1kQhnMRURFiy7NsdS8EFL-8vtqEXOgECn'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('/content/AlphaPose/pretrained_models/fast_res50_256x192.pth')\n",
        "\n",
        "!wget -P ./detector/yolox/data/ https://github.com/Megvii-BaseDetection/YOLOX/releases/download/0.1.0/yolox_x.pth\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiJCOUjj-g-M",
        "outputId": "4fe1052e-642f-4d83-a6f8-b9b0b45e9a45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alphapose  configs   docs      LICENSE\t    pretrained_models  scripts\t  setup.py  yolov8n.pt\n",
            "build\t   detector  examples  model_files  README.md\t       setup.cfg  trackers\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/AlphaPose/scripts/demo_inference.py\", line 13, in <module>\n",
            "    from detector.apis import get_detector\n",
            "ModuleNotFoundError: No module named 'detector'\n",
            "ls: cannot access 'examples/res/': No such file or directory\n",
            "ls: cannot access 'examples/res/vis': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.chdir('/content/AlphaPose')\n",
        "! ls\n",
        "! python3 scripts/demo_inference.py --cfg configs/coco/resnet/256x192_res50_lr1e-3_1x.yaml --checkpoint pretrained_models/fast_res50_256x192.pth --indir examples/demo/ --save_img\n",
        "# result json and rendered images are saved here:\n",
        "! ls examples/res/\n",
        "! ls examples/res/vis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C17tdN7MrmyL",
        "outputId": "5b74d89f-e7c9-486d-d40c-034e1a2d23cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.2.99)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (10.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.19.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.4)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.8)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7RryumnqpJD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xml.etree.ElementTree as ET\n",
        "from ultralytics import YOLO\n",
        "from alphapose.utils.config import update_config\n",
        "from alphapose.models import builder\n",
        "from alphapose.utils.transforms import get_func_heatmap_to_coord\n",
        "from PIL import Image, ImageDraw  # PIL 라이브러리에서 Image, ImageDraw 가져오기\n",
        "\n",
        "class Opt:\n",
        "    def __init__(self):\n",
        "        self.dataset = 'coco'\n",
        "        self.sp = False\n",
        "        self.save_img = False\n",
        "        self.outputpath = './results/'\n",
        "        self.pose_flow = False\n",
        "        self.vis = True\n",
        "\n",
        "class GetKeypoint:\n",
        "    NOSE = 0\n",
        "    LEFT_EYE = 1\n",
        "    RIGHT_EYE = 2\n",
        "    LEFT_EAR = 3\n",
        "    RIGHT_EAR = 4\n",
        "    LEFT_SHOULDER = 5\n",
        "    RIGHT_SHOULDER = 6\n",
        "    LEFT_ELBOW = 7\n",
        "    RIGHT_ELBOW = 8\n",
        "    LEFT_WRIST = 9\n",
        "    RIGHT_WRIST = 10\n",
        "    LEFT_HIP = 11\n",
        "    RIGHT_HIP = 12\n",
        "    LEFT_KNEE = 13\n",
        "    RIGHT_KNEE = 14\n",
        "    LEFT_ANKLE = 15\n",
        "    RIGHT_ANKLE = 16\n",
        "\n",
        "get_keypoint = GetKeypoint()\n",
        "\n",
        "\n",
        "\n",
        "# XML 파일에서 폭행이 일어나는 시간과 행동 정보 파싱\n",
        "def parse_assault_frames(xml_file):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "    event = root.find('event')\n",
        "\n",
        "    start_time = event.find('starttime').text\n",
        "    duration = event.find('duration').text\n",
        "\n",
        "    start_frame = time_to_frames(start_time)  # starttime을 프레임으로 변환\n",
        "    end_frame = start_frame + time_to_frames(duration)  # duration을 프레임으로 변환 후 더함\n",
        "\n",
        "    return start_frame, end_frame\n",
        "\n",
        "def time_to_frames(time_str, fps=30):\n",
        "    \"\"\"시간 문자열을 프레임 수로 변환하는 함수 (fps는 30으로 가정).\"\"\"\n",
        "    time_parts = time_str.split(':')\n",
        "\n",
        "    if len(time_parts) == 3:\n",
        "        hours, minutes, seconds = map(float, time_parts)\n",
        "    elif len(time_parts) == 2:\n",
        "        hours = 0\n",
        "        minutes, seconds = map(float, time_parts)\n",
        "    else:\n",
        "        raise ValueError(f\"Unexpected time format: {time_str}\")\n",
        "\n",
        "    total_seconds = hours * 3600 + minutes * 60 + seconds\n",
        "    return int(total_seconds * fps)\n",
        "\n",
        "# XML에서 객체의 행동을 프레임 범위와 함께 파싱\n",
        "def parse_xml(xml_file):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    actions = {}\n",
        "    for obj in root.findall('object'):\n",
        "        obj_name = obj.find('objectname').text\n",
        "        actions[obj_name] = {}\n",
        "\n",
        "        for action in obj.findall('action'):\n",
        "            action_name = action.find('actionname').text\n",
        "            frames = []\n",
        "            for frame in action.findall('frame'):\n",
        "                start_frame = int(frame.find('start').text)\n",
        "                end_frame = int(frame.find('end').text)\n",
        "                frames.append((start_frame, end_frame))\n",
        "            actions[obj_name][action_name] = frames\n",
        "\n",
        "    print(f\"Parsed Actions: {actions}\")  # Debug: 확인용 출력\n",
        "    return actions\n",
        "\n",
        "\n",
        "def get_label_from_frame(actions, frame_num, person_name, assault_frames, keypoints=None):\n",
        "    # 폭력 상황 프레임 확인\n",
        "    if not assault_frames or not (assault_frames[0] <= frame_num <= assault_frames[1]):\n",
        "        return 'normal'  # 폭력 상황이 아닐 경우 'normal'로 리턴\n",
        "\n",
        "    # XML에서 현재 사람에 대한 행동 정보가 있는지 확인\n",
        "    if person_name in actions:\n",
        "        for action, frames in actions[person_name].items():\n",
        "            for (start_frame, end_frame) in frames:\n",
        "                if start_frame <= frame_num <= end_frame:\n",
        "                    print(f\"Action detected for {person_name}: {action} at frame {frame_num}\")  # Debug: 액션 출력\n",
        "                    return action  # 액션 이름을 라벨로 반환\n",
        "\n",
        "    # 폭력 상황인데 라벨이 없는 경우 classify_pose로 라벨을 추정\n",
        "    if keypoints is not None:\n",
        "        return classify_pose(keypoints)  # 포즈 분석을 통해 라벨 추정\n",
        "\n",
        "    # 기본적으로 폭력 상황이면 'assault'로 리턴\n",
        "    return 'assault'\n",
        "\n",
        "\n",
        "def classify_pose(keypoints):\n",
        "    nose_y = keypoints[GetKeypoint.NOSE * 2 + 1]\n",
        "    left_knee_y = keypoints[GetKeypoint.LEFT_KNEE * 2 + 1]\n",
        "    right_knee_y = keypoints[GetKeypoint.RIGHT_KNEE * 2 + 1]\n",
        "    left_ankle_y = keypoints[GetKeypoint.LEFT_ANKLE * 2 + 1]\n",
        "    right_ankle_y = keypoints[GetKeypoint.RIGHT_ANKLE * 2 + 1]\n",
        "\n",
        "    fall_threshold = 50\n",
        "    height_threshold = 100\n",
        "\n",
        "    if max(left_knee_y, right_knee_y) < left_ankle_y + fall_threshold and max(left_knee_y, right_knee_y) < nose_y + height_threshold:\n",
        "          return 'falling'\n",
        "    elif (abs(left_knee_y - right_knee_y) > 20) and (nose_y < min(left_knee_y, right_knee_y)):\n",
        "          return 'fighting'\n",
        "    else:\n",
        "          return 'assault'\n",
        "\n",
        "\n",
        "def calculate_euclidean_distance(point1, point2):\n",
        "    \"\"\"\n",
        "    두 점 간의 유클리드 거리를 계산하는 함수\n",
        "    :param point1: 첫 번째 점 (x, y)\n",
        "    :param point2: 두 번째 점 (x, y)\n",
        "    :return: 유클리드 거리\n",
        "    \"\"\"\n",
        "    return np.linalg.norm(np.array(point1) - np.array(point2))\n",
        "\n",
        "def calculate_angle(point1, point2, point3):\n",
        "    \"\"\"\n",
        "    세 점을 기준으로 각도를 계산하는 함수\n",
        "    :param point1: 첫 번째 점 (x, y)\n",
        "    :param point2: 기준점 (x, y)\n",
        "    :param point3: 세 번째 점 (x, y)\n",
        "    :return: 각도 (degree)\n",
        "    \"\"\"\n",
        "    vector1 = np.array([point1[0] - point2[0], point1[1] - point2[1]])\n",
        "    vector2 = np.array([point3[0] - point2[0], point3[1] - point2[1]])\n",
        "    unit_vector1 = vector1 / np.linalg.norm(vector1)\n",
        "    unit_vector2 = vector2 / np.linalg.norm(vector2)\n",
        "    dot_product = np.dot(unit_vector1, unit_vector2)\n",
        "    angle = np.arccos(dot_product)  # 라디안 값으로 각도 계산\n",
        "    return np.degrees(angle)  # 각도를 도(degree)로 변환\n",
        "\n",
        "def calculate_joint_angles(keypoints):\n",
        "    \"\"\"\n",
        "    각 관절에 대한 각도를 계산하는 함수\n",
        "    :param keypoints: 신체 키포인트 리스트\n",
        "    :return: 각 관절의 각도 (왼쪽 팔꿈치, 오른쪽 팔꿈치, 왼쪽 다리, 오른쪽 다리)\n",
        "    \"\"\"\n",
        "    left_elbow_angle = calculate_angle(\n",
        "        [keypoints[GetKeypoint.LEFT_WRIST * 2], keypoints[GetKeypoint.LEFT_WRIST * 2 + 1]],\n",
        "        [keypoints[GetKeypoint.LEFT_ELBOW * 2], keypoints[GetKeypoint.LEFT_ELBOW * 2 + 1]],\n",
        "        [keypoints[GetKeypoint.LEFT_SHOULDER * 2], keypoints[GetKeypoint.LEFT_SHOULDER * 2 + 1]]\n",
        "    )\n",
        "\n",
        "    right_elbow_angle = calculate_angle(\n",
        "        [keypoints[GetKeypoint.RIGHT_WRIST * 2], keypoints[GetKeypoint.RIGHT_WRIST * 2 + 1]],\n",
        "        [keypoints[GetKeypoint.RIGHT_ELBOW * 2], keypoints[GetKeypoint.RIGHT_ELBOW * 2 + 1]],\n",
        "        [keypoints[GetKeypoint.RIGHT_SHOULDER * 2], keypoints[GetKeypoint.RIGHT_SHOULDER * 2 + 1]]\n",
        "    )\n",
        "\n",
        "    left_knee_angle = calculate_angle(\n",
        "        [keypoints[GetKeypoint.LEFT_ANKLE * 2], keypoints[GetKeypoint.LEFT_ANKLE * 2 + 1]],\n",
        "        [keypoints[GetKeypoint.LEFT_KNEE * 2], keypoints[GetKeypoint.LEFT_KNEE * 2 + 1]],\n",
        "        [keypoints[GetKeypoint.LEFT_HIP * 2], keypoints[GetKeypoint.LEFT_HIP * 2 + 1]]\n",
        "    )\n",
        "\n",
        "    right_knee_angle = calculate_angle(\n",
        "        [keypoints[GetKeypoint.RIGHT_ANKLE * 2], keypoints[GetKeypoint.RIGHT_ANKLE * 2 + 1]],\n",
        "        [keypoints[GetKeypoint.RIGHT_KNEE * 2], keypoints[GetKeypoint.RIGHT_KNEE * 2 + 1]],\n",
        "        [keypoints[GetKeypoint.RIGHT_HIP * 2], keypoints[GetKeypoint.RIGHT_HIP * 2 + 1]]\n",
        "    )\n",
        "\n",
        "    return left_elbow_angle, right_elbow_angle, left_knee_angle, right_knee_angle\n",
        "\n",
        "\n",
        "def classify_and_store_keypoints(yolo_model, pose_model, input_image, frame_num, actions, csv_file_path, keypoint_header, assault_frames, cfg, device, prev_keypoints=None):\n",
        "    \"\"\"\n",
        "    YOLO 및 AlphaPose를 사용하여 객체 감지 및 포즈 추출, 키포인트 및 라벨 저장.\n",
        "    사람이 나타나면 사람 1로 지정하고, 폭력 상황에서는 사람 1과 사람 2의 위치를 추적.\n",
        "    \"\"\"\n",
        "    results = yolo_model.predict(input_image, save=False, classes=[0])\n",
        "    human_detections = [d for d in results[0].boxes.data.cpu().numpy() if int(d[-1]) == 0]\n",
        "\n",
        "    # 사람이 감지되지 않으면 0으로 채워진 값 반환\n",
        "    if not human_detections:\n",
        "        print(f'No human detections in frame {frame_num}. Skipping this frame...')\n",
        "        return [0] * 34, [0] * 4, [0] * 4, 'normal', [0] * 34, [0] * 4, [0] * 4, 'normal'\n",
        "\n",
        "    inps = []\n",
        "    boxes = []\n",
        "    for detection in human_detections:\n",
        "        x1, y1, x2, y2 = map(int, detection[:4])\n",
        "        boxes.append([x1, y1, x2, y2])\n",
        "        inp = cv2.resize(input_image[y1:y2, x1:x2], (cfg.DATA_PRESET.IMAGE_SIZE[0], cfg.DATA_PRESET.IMAGE_SIZE[1]))\n",
        "        inps.append(inp)\n",
        "\n",
        "    inps = torch.stack([torch.from_numpy(np.array(inp)).permute(2, 0, 1).float() for inp in inps]).to(device)\n",
        "\n",
        "    # AlphaPose 모델로 스켈레톤 추출\n",
        "    with torch.no_grad():\n",
        "        hm = pose_model(inps)\n",
        "\n",
        "    keypoints = []\n",
        "    angles = []\n",
        "    distances = []  # 유클리드 거리 추가\n",
        "    labels = []\n",
        "\n",
        "    # 키포인트 및 라벨 추출\n",
        "    for i, box in enumerate(boxes):\n",
        "        preds, maxvals = get_func_heatmap_to_coord(cfg)(hm[i], box)\n",
        "        keypoints_flatten = preds.flatten().tolist()  # (17개 관절 x 2 좌표) => 34개의 값\n",
        "\n",
        "        # 관절 각도 계산\n",
        "        left_elbow_angle, right_elbow_angle, left_knee_angle, right_knee_angle = calculate_joint_angles(keypoints_flatten)\n",
        "\n",
        "        # 유클리드 거리 계산 (예: 왼쪽 어깨-왼쪽 팔꿈치)\n",
        "        left_shoulder_left_elbow_dist = calculate_euclidean_distance(\n",
        "            (keypoints_flatten[GetKeypoint.LEFT_SHOULDER * 2], keypoints_flatten[GetKeypoint.LEFT_SHOULDER * 2 + 1]),\n",
        "            (keypoints_flatten[GetKeypoint.LEFT_ELBOW * 2], keypoints_flatten[GetKeypoint.LEFT_ELBOW * 2 + 1])\n",
        "        )\n",
        "\n",
        "        right_shoulder_right_elbow_dist = calculate_euclidean_distance(\n",
        "            (keypoints_flatten[GetKeypoint.RIGHT_SHOULDER * 2], keypoints_flatten[GetKeypoint.RIGHT_SHOULDER * 2 + 1]),\n",
        "            (keypoints_flatten[GetKeypoint.RIGHT_ELBOW * 2], keypoints_flatten[GetKeypoint.RIGHT_ELBOW * 2 + 1])\n",
        "        )\n",
        "\n",
        "        # 추가된 거리 정보: 힙-무릎 거리도 추가로 계산 (총 4개의 거리)\n",
        "        left_hip_left_knee_dist = calculate_euclidean_distance(\n",
        "            (keypoints_flatten[GetKeypoint.LEFT_HIP * 2], keypoints_flatten[GetKeypoint.LEFT_HIP * 2 + 1]),\n",
        "            (keypoints_flatten[GetKeypoint.LEFT_KNEE * 2], keypoints_flatten[GetKeypoint.LEFT_KNEE * 2 + 1])\n",
        "        )\n",
        "\n",
        "        right_hip_right_knee_dist = calculate_euclidean_distance(\n",
        "            (keypoints_flatten[GetKeypoint.RIGHT_HIP * 2], keypoints_flatten[GetKeypoint.RIGHT_HIP * 2 + 1]),\n",
        "            (keypoints_flatten[GetKeypoint.RIGHT_KNEE * 2], keypoints_flatten[GetKeypoint.RIGHT_KNEE * 2 + 1])\n",
        "        )\n",
        "\n",
        "        distances.append([left_shoulder_left_elbow_dist, right_shoulder_right_elbow_dist, left_hip_left_knee_dist, right_hip_right_knee_dist])\n",
        "\n",
        "        # 키포인트와 각도를 저장\n",
        "        keypoints.append(keypoints_flatten)\n",
        "        angles.append([left_elbow_angle, right_elbow_angle, left_knee_angle, right_knee_angle])\n",
        "\n",
        "        # XML에서 라벨 가져오기\n",
        "        label = get_label_from_frame(actions, frame_num, f\"person_{i+1}\", assault_frames, keypoints_flatten)\n",
        "        labels.append(label)\n",
        "\n",
        "    # 사람 1명일 경우, 두 번째 사람의 데이터를 모두 0으로 처리\n",
        "    if len(boxes) == 1:\n",
        "        second_person_keypoints = [0] * 34\n",
        "        second_person_angles = [0] * 4\n",
        "        second_person_distances = [0] * 4\n",
        "        second_person_label = 'normal'\n",
        "    else:\n",
        "        second_person_keypoints = keypoints[1]\n",
        "        second_person_angles = angles[1]\n",
        "        second_person_distances = distances[1]\n",
        "        second_person_label = labels[1]\n",
        "\n",
        "    # 기존 리턴값 구조 유지\n",
        "    return keypoints[0], angles[0], distances[0], labels[0], second_person_keypoints, second_person_angles, second_person_distances, second_person_label\n",
        "\n",
        "\n",
        "limb_pairs = [\n",
        "    (GetKeypoint.NOSE, GetKeypoint.LEFT_EYE), (GetKeypoint.NOSE, GetKeypoint.RIGHT_EYE),\n",
        "    (GetKeypoint.LEFT_EYE, GetKeypoint.LEFT_EAR), (GetKeypoint.RIGHT_EYE, GetKeypoint.RIGHT_EAR),\n",
        "    (GetKeypoint.NOSE, GetKeypoint.LEFT_SHOULDER), (GetKeypoint.NOSE, GetKeypoint.RIGHT_SHOULDER),\n",
        "    (GetKeypoint.LEFT_SHOULDER, GetKeypoint.LEFT_ELBOW), (GetKeypoint.RIGHT_SHOULDER, GetKeypoint.RIGHT_ELBOW),\n",
        "    (GetKeypoint.LEFT_ELBOW, GetKeypoint.LEFT_WRIST), (GetKeypoint.RIGHT_ELBOW, GetKeypoint.RIGHT_WRIST),\n",
        "    (GetKeypoint.LEFT_SHOULDER, GetKeypoint.LEFT_HIP), (GetKeypoint.RIGHT_SHOULDER, GetKeypoint.RIGHT_HIP),\n",
        "    (GetKeypoint.LEFT_HIP, GetKeypoint.LEFT_KNEE), (GetKeypoint.RIGHT_HIP, GetKeypoint.RIGHT_KNEE),\n",
        "    (GetKeypoint.LEFT_KNEE, GetKeypoint.LEFT_ANKLE), (GetKeypoint.RIGHT_KNEE, GetKeypoint.RIGHT_ANKLE)\n",
        "]\n",
        "\n",
        "\n",
        "def vis_frame(orig_img, boxes, keypoints, labels):\n",
        "    vis_img = Image.fromarray(cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB))\n",
        "    draw = ImageDraw.Draw(vis_img)\n",
        "    joint_color = (255, 0, 0)\n",
        "    limb_color = (255, 0, 0)\n",
        "\n",
        "    for i, box in enumerate(boxes):\n",
        "        keypoint_coords = []\n",
        "        for j in range(0, len(keypoints[i]), 2):\n",
        "            keypoint_x, keypoint_y = int(keypoints[i][j]), int(keypoints[i][j + 1])\n",
        "            keypoint_coords.append((keypoint_x, keypoint_y))\n",
        "            if keypoint_x > 0 and keypoint_y > 0:\n",
        "                draw.ellipse([(keypoint_x - 4, keypoint_y - 4), (keypoint_x + 4, keypoint_y + 4)], fill=joint_color)\n",
        "\n",
        "        for (start, end) in limb_pairs:\n",
        "            if keypoint_coords[start][0] > 0 and keypoint_coords[start][1] > 0 and keypoint_coords[end][0] > 0 and keypoint_coords[end][1] > 0:\n",
        "                draw.line([keypoint_coords[start], keypoint_coords[end]], fill=limb_color, width=4)\n",
        "\n",
        "    return cv2.cvtColor(np.array(vis_img), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "def load_existing_csv(csv_file_path):\n",
        "    \"\"\"이미 존재하는 CSV 파일이 있으면 읽어옵니다.\"\"\"\n",
        "    if os.path.exists(csv_file_path):\n",
        "        df_existing = pd.read_csv(csv_file_path)\n",
        "        processed_videos = set(df_existing['video_name'].unique())  # 이미 처리된 비디오 목록\n",
        "        return df_existing, processed_videos\n",
        "    else:\n",
        "        df_existing = pd.DataFrame(columns=['video_name', 'frame_num'])  # 비어 있는 데이터프레임 (필요한 컬럼 지정)\n",
        "        processed_videos = set()  # 빈 비디오 목록\n",
        "        return df_existing, processed_videos\n",
        "\n",
        "# 비디오 처리 후 CSV 저장하는 부분 수정:\n",
        "def save_to_csv(df_existing, all_keypoints, header, csv_file_path):\n",
        "    \"\"\"키포인트 데이터를 CSV 파일에 저장합니다.\"\"\"\n",
        "    if all_keypoints:\n",
        "        df_temp = pd.DataFrame(all_keypoints, columns=header)\n",
        "\n",
        "\n",
        "        # 기존 CSV와 합치기 전에 중복 확인 (video_name과 frame_num 기준으로 중복 제거)\n",
        "        df_combined = pd.concat([df_existing, df_temp], ignore_index=True)\n",
        "        df_combined.drop_duplicates(subset=['video_name', 'frame_num'], keep='last', inplace=True)\n",
        "\n",
        "        # 덮어쓰기 방지하며 저장\n",
        "        df_combined.to_csv(csv_file_path, index=False)\n",
        "        print(f'CSV 파일 {csv_file_path}에 저장되었습니다.')\n",
        "\n",
        "\n",
        "def check_row_data_lengths(video_filename, frame_num, keypoint_data_1, angle_data_1, distance_data_1, label_data_1, keypoint_data_2, angle_data_2, distance_data_2, label_data_2):\n",
        "    print(f\"Video filename: {video_filename}\")\n",
        "    print(f\"Frame number: {frame_num}\")\n",
        "    print(f\"Keypoint data 1 length: {len(keypoint_data_1)}\")  # 34개여야 함\n",
        "    print(f\"Angle data 1 length: {len(angle_data_1)}\")        # 4개여야 함\n",
        "    print(f\"Distance data 1 length: {len(distance_data_1)}\")  # 4개여야 함\n",
        "    print(f\"Label 1 length: {len(label_data_1)}\")             # 1개여야 함\n",
        "\n",
        "    print(f\"Keypoint data 2 length: {len(keypoint_data_2)}\")  # 34개여야 함\n",
        "    print(f\"Angle data 2 length: {len(angle_data_2)}\")        # 4개여야 함\n",
        "    print(f\"Distance data 2 length: {len(distance_data_2)}\")  # 4개여야 함\n",
        "    print(f\"Label 2 length: {len(label_data_2)}\")             # 1개여야 함\n",
        "\n",
        "\n",
        "import logging  # 로깅 추가\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "def main(root_dir, output_dir, csv_base_path, frame_skip_interval=5):\n",
        "    try:\n",
        "        yolo_model = YOLO('yolov8n.pt')\n",
        "        image_files = []\n",
        "\n",
        "        # root_dir에서 모든 비디오 파일 탐색\n",
        "        for root, dirs, files in os.walk(root_dir):\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.mp4', '.avi')):\n",
        "                    image_files.append(os.path.join(root, file))  # 동영상 파일 경로 저장\n",
        "\n",
        "        image_files = sorted(image_files)  # 파일 정렬\n",
        "\n",
        "        # 출력 디렉토리가 없으면 생성\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        # AlphaPose 모델 설정\n",
        "        pretrained_model_path = '/content/drive/MyDrive/논문주제/Final_project/pretrained_models/fast_res50_256x192.pth'\n",
        "        cfg_file = '/content/AlphaPose/configs/coco/resnet/256x192_res50_lr1e-3_1x.yaml'\n",
        "\n",
        "        # Config 파일 업데이트\n",
        "        cfg = update_config(cfg_file)\n",
        "\n",
        "        # checkpoint 키 추가\n",
        "        cfg['checkpoint'] = pretrained_model_path  # 체크포인트 경로 설정\n",
        "\n",
        "        # AlphaPose 모델 빌드\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        pose_model = builder.build_sppe(cfg.MODEL, preset_cfg=cfg.DATA_PRESET)\n",
        "        pose_model.load_state_dict(torch.load(cfg['checkpoint'], map_location=device))\n",
        "        pose_model = torch.nn.DataParallel(pose_model).to(device)\n",
        "        pose_model.eval()  # AlphaPose 모델을 평가 모드로 전환\n",
        "\n",
        "        # CSV 파일의 헤더 정의\n",
        "        header = [\n",
        "        'video_filename', 'frame_num',\n",
        "        'target_person_nose_x', 'target_person_nose_y',\n",
        "        'target_person_left_eye_x', 'target_person_left_eye_y',\n",
        "        'target_person_right_eye_x', 'target_person_right_eye_y',\n",
        "        'target_person_left_ear_x', 'target_person_left_ear_y',\n",
        "        'target_person_right_ear_x', 'target_person_right_ear_y',\n",
        "        'target_person_left_shoulder_x', 'target_person_left_shoulder_y',\n",
        "        'target_person_right_shoulder_x', 'target_person_right_shoulder_y',\n",
        "        'target_person_left_elbow_x', 'target_person_left_elbow_y',\n",
        "        'target_person_right_elbow_x', 'target_person_right_elbow_y',\n",
        "        'target_person_left_wrist_x', 'target_person_left_wrist_y',\n",
        "        'target_person_right_wrist_x', 'target_person_right_wrist_y',\n",
        "        'target_person_left_hip_x', 'target_person_left_hip_y',\n",
        "        'target_person_right_hip_x', 'target_person_right_hip_y',\n",
        "        'target_person_left_knee_x', 'target_person_left_knee_y',\n",
        "        'target_person_right_knee_x', 'target_person_right_knee_y',\n",
        "        'target_person_left_ankle_x', 'target_person_left_ankle_y',\n",
        "        'target_person_right_ankle_x', 'target_person_right_ankle_y',\n",
        "        # Additional joint angles (first person)\n",
        "        'left_elbow_angle_1', 'right_elbow_angle_1',\n",
        "        'left_knee_angle_1', 'right_knee_angle_1',\n",
        "        # Additional Euclidean distances (first person)\n",
        "        'left_shoulder_left_elbow_dist_1',\n",
        "        'right_shoulder_right_elbow_dist_1',\n",
        "        'left_hip_left_knee_dist_1',\n",
        "        'right_hip_right_knee_dist_1',\n",
        "        'target_person_label',\n",
        "        # Second person\n",
        "        'closest_person_nose_x', 'closest_person_nose_y',\n",
        "        'closest_person_left_eye_x', 'closest_person_left_eye_y',\n",
        "        'closest_person_right_eye_x', 'closest_person_right_eye_y',\n",
        "        'closest_person_left_ear_x', 'closest_person_left_ear_y',\n",
        "        'closest_person_right_ear_x', 'closest_person_right_ear_y',\n",
        "        'closest_person_left_shoulder_x', 'closest_person_left_shoulder_y',\n",
        "        'closest_person_right_shoulder_x', 'closest_person_right_shoulder_y',\n",
        "        'closest_person_left_elbow_x', 'closest_person_left_elbow_y',\n",
        "        'closest_person_right_elbow_x', 'closest_person_right_elbow_y',\n",
        "        'closest_person_left_wrist_x', 'closest_person_left_wrist_y',\n",
        "        'closest_person_right_wrist_x', 'closest_person_right_wrist_y',\n",
        "        'closest_person_left_hip_x', 'closest_person_left_hip_y',\n",
        "        'closest_person_right_hip_x', 'closest_person_right_hip_y',\n",
        "        'closest_person_left_knee_x', 'closest_person_left_knee_y',\n",
        "        'closest_person_right_knee_x', 'closest_person_right_knee_y',\n",
        "        'closest_person_left_ankle_x', 'closest_person_left_ankle_y',\n",
        "        'closest_person_right_ankle_x', 'closest_person_right_ankle_y',\n",
        "        # Second person joint angles\n",
        "        'left_elbow_angle_2', 'right_elbow_angle_2',\n",
        "        'left_knee_angle_2', 'right_knee_angle_2',\n",
        "        # Second person Euclidean distances\n",
        "        'left_shoulder_left_elbow_dist_2',\n",
        "        'right_shoulder_right_elbow_dist_2',\n",
        "        'left_hip_left_knee_dist_2',\n",
        "        'right_hip_right_knee_dist_2',\n",
        "        'closest_person_label'\n",
        "    ]\n",
        "\n",
        "        all_keypoints = []\n",
        "        batch_number = 1\n",
        "        batch_size = 2  # 두 개씩 처리\n",
        "\n",
        "        # 비디오 파일을 배치 단위로 처리\n",
        "        for i in range(0, len(image_files), batch_size):\n",
        "            batch_files = image_files[i:i + batch_size]\n",
        "            csv_file_path = f\"{csv_base_path}_batch_{batch_number}.csv\"\n",
        "\n",
        "            for video_file in batch_files:\n",
        "                try:\n",
        "                    logging.info(f\"Processing video file: {video_file}\")\n",
        "\n",
        "                    # 각 비디오 파일에서 XML 파일과 라벨 가져오기\n",
        "                    xml_filename = os.path.splitext(os.path.basename(video_file))[0] + \".xml\"\n",
        "                    xml_path = os.path.join(os.path.dirname(video_file), xml_filename)\n",
        "\n",
        "                    if os.path.exists(xml_path):\n",
        "                        assault_frames = parse_assault_frames(xml_path)\n",
        "                        actions = parse_xml(xml_path)\n",
        "                    else:\n",
        "                        assault_frames = None\n",
        "                        actions = None\n",
        "\n",
        "                    keypoints = process_video(video_file, yolo_model, pose_model, cfg, device, header, frame_skip_interval, assault_frames, actions)\n",
        "\n",
        "                    if keypoints:\n",
        "                        all_keypoints.extend(keypoints)\n",
        "                        logging.info(f\"Processed {len(keypoints)} keypoints from {video_file}\")\n",
        "                    else:\n",
        "                        logging.warning(f\"No keypoints found for {video_file}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    logging.error(f\"Error processing {video_file}: {e}\")\n",
        "\n",
        "            # CSV 저장\n",
        "            if all_keypoints:\n",
        "                logging.info(f\"Saving batch {batch_number} to {csv_file_path}\")\n",
        "                df_temp = pd.DataFrame(all_keypoints, columns=header)\n",
        "                df_temp.to_csv(csv_file_path, index=False)\n",
        "                logging.info(f\"Batch {batch_number} saved to {csv_file_path}\")\n",
        "            else:\n",
        "                logging.warning(f\"No keypoints to save for batch {batch_number}\")\n",
        "\n",
        "            all_keypoints = []  # 다음 배치 처리를 위해 초기화\n",
        "            batch_number += 1\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Main function error: {e}\")\n",
        "\n",
        "def process_video(video_file, yolo_model, pose_model, cfg, device, header, frame_skip_interval, assault_frames, actions):\n",
        "    \"\"\"주어진 비디오 파일에서 키포인트를 추출하여 반환\"\"\"\n",
        "    keypoints_list = []\n",
        "    cap = cv2.VideoCapture(video_file)\n",
        "    frame_num = 0\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # XML에서 제공된 폭력 상황에서만 프레임 건너뛰지 않음\n",
        "        if assault_frames and (assault_frames[0] <= frame_num <= assault_frames[1]):\n",
        "            frame_skip_interval = 1  # 폭력 상황에서는 모든 프레임 처리\n",
        "        else:\n",
        "            if frame_num % frame_skip_interval != 0:\n",
        "                frame_num += 1\n",
        "                continue\n",
        "\n",
        "        try:\n",
        "            # classify_and_store_keypoints 함수로 키포인트 추출\n",
        "            keypoint_data_1, angles_1, distances_1, label_1, keypoint_data_2, angles_2, distances_2, label_2 = classify_and_store_keypoints(\n",
        "                yolo_model, pose_model, frame, frame_num, actions, None, header, assault_frames, cfg, device\n",
        "            )\n",
        "\n",
        "            if keypoint_data_1 is not None and label_1 is not None:\n",
        "                row = (\n",
        "                    [os.path.basename(video_file), frame_num] + keypoint_data_1 + angles_1 + distances_1 +\n",
        "                    [label_1] + keypoint_data_2 + angles_2 + distances_2 + [label_2]\n",
        "                )\n",
        "\n",
        "                if len(row) == len(header):\n",
        "                    keypoints_list.append(row)\n",
        "                else:\n",
        "                    logging.warning(f\"Row length mismatch for frame {frame_num} in {video_file}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error processing frame {frame_num} in {video_file}: {e}\")\n",
        "\n",
        "        frame_num += 1\n",
        "\n",
        "    cap.release()\n",
        "    return keypoints_list\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    root_dir = '/content/drive/MyDrive/논문주제/이상행동 CCTV 영상/01.폭행(assult)'\n",
        "    output_dir = '/content/drive/MyDrive/논문주제/이상행동 CCTV 영상/01.폭행(assult)3'\n",
        "    csv_base_path = '/content/drive/MyDrive/논문주제/이상행동 CCTV 영상/results_batch'\n",
        "\n",
        "    main(root_dir, output_dir, csv_base_path, frame_skip_interval=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CxA_suRJDnT",
        "outputId": "dbdb9074-fb79-43e3-c749-8721dd23b7d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsed Actions: {'person_1': {'pushing': [(4912, 5008), (5253, 5293)], 'kicking': [(5296, 5336), (5403, 5451), (5859, 5930), (5994, 6043)], 'punching': [(5664, 5690), (6271, 6303), (6725, 6906), (6906, 6967), (6976, 7100)], 'throwing': [(5768, 5827), (6577, 6618), (7313, 7376)], 'threaten': [(7777, 7848)]}, 'person_2': {'falldown': [(5403, 5478), (5653, 5733), (6261, 6331)]}}\n",
            "\n",
            "0: 384x640 1 person, 101.7ms\n",
            "Speed: 4.3ms preprocess, 101.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 60.6ms\n",
            "Speed: 7.9ms preprocess, 60.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 55.2ms\n",
            "Speed: 23.8ms preprocess, 55.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 63.7ms\n",
            "Speed: 3.8ms preprocess, 63.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 70.8ms\n",
            "Speed: 7.0ms preprocess, 70.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 69.5ms\n",
            "Speed: 15.5ms preprocess, 69.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 58.5ms\n",
            "Speed: 12.1ms preprocess, 58.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 56.9ms\n",
            "Speed: 6.6ms preprocess, 56.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 53.3ms\n",
            "Speed: 41.4ms preprocess, 53.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 87.4ms\n",
            "Speed: 2.9ms preprocess, 87.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 60.7ms\n",
            "Speed: 24.0ms preprocess, 60.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 59.5ms\n",
            "Speed: 14.5ms preprocess, 59.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 75.1ms\n",
            "Speed: 6.7ms preprocess, 75.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 72.8ms\n",
            "Speed: 20.2ms preprocess, 72.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 60.6ms\n",
            "Speed: 26.4ms preprocess, 60.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 59.9ms\n",
            "Speed: 38.9ms preprocess, 59.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 75.8ms\n",
            "Speed: 5.9ms preprocess, 75.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 68.9ms\n",
            "Speed: 11.1ms preprocess, 68.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 73.0ms\n",
            "Speed: 3.2ms preprocess, 73.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 72.9ms\n",
            "Speed: 16.5ms preprocess, 72.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 60.4ms\n",
            "Speed: 19.8ms preprocess, 60.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 58.9ms\n",
            "Speed: 38.0ms preprocess, 58.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 118.4ms\n",
            "Speed: 9.9ms preprocess, 118.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 105.6ms\n",
            "Speed: 7.3ms preprocess, 105.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 68.3ms\n",
            "Speed: 38.3ms preprocess, 68.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 61.2ms\n",
            "Speed: 37.2ms preprocess, 61.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 58.1ms\n",
            "Speed: 34.7ms preprocess, 58.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 101.2ms\n",
            "Speed: 8.2ms preprocess, 101.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 110.5ms\n",
            "Speed: 41.7ms preprocess, 110.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 86.8ms\n",
            "Speed: 32.8ms preprocess, 86.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 110.2ms\n",
            "Speed: 7.0ms preprocess, 110.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 58.0ms\n",
            "Speed: 27.7ms preprocess, 58.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 75.1ms\n",
            "Speed: 7.2ms preprocess, 75.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 67.2ms\n",
            "Speed: 10.0ms preprocess, 67.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 97.6ms\n",
            "Speed: 12.4ms preprocess, 97.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-77d003e2e815>:156: RuntimeWarning: invalid value encountered in divide\n",
            "  unit_vector2 = vector2 / np.linalg.norm(vector2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 64.4ms\n",
            "Speed: 10.8ms preprocess, 64.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 59.0ms\n",
            "Speed: 11.0ms preprocess, 59.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 57.9ms\n",
            "Speed: 34.1ms preprocess, 57.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 67.3ms\n",
            "Speed: 28.3ms preprocess, 67.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 58.6ms\n",
            "Speed: 6.9ms preprocess, 58.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 75.9ms\n",
            "Speed: 3.5ms preprocess, 75.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 60.1ms\n",
            "Speed: 18.3ms preprocess, 60.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 59.1ms\n",
            "Speed: 3.7ms preprocess, 59.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 58.3ms\n",
            "Speed: 19.4ms preprocess, 58.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 57.7ms\n",
            "Speed: 30.3ms preprocess, 57.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 66.6ms\n",
            "Speed: 2.9ms preprocess, 66.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 60.1ms\n",
            "Speed: 29.7ms preprocess, 60.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 61.6ms\n",
            "Speed: 22.2ms preprocess, 61.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 68.4ms\n",
            "Speed: 4.0ms preprocess, 68.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 69.3ms\n",
            "Speed: 7.4ms preprocess, 69.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 58.4ms\n",
            "Speed: 17.0ms preprocess, 58.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 101.5ms\n",
            "Speed: 3.8ms preprocess, 101.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 65.3ms\n",
            "Speed: 6.2ms preprocess, 65.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 58.3ms\n",
            "Speed: 27.0ms preprocess, 58.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-77d003e2e815>:155: RuntimeWarning: invalid value encountered in divide\n",
            "  unit_vector1 = vector1 / np.linalg.norm(vector1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 69.4ms\n",
            "Speed: 3.7ms preprocess, 69.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 60.1ms\n",
            "Speed: 37.5ms preprocess, 60.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 57.7ms\n",
            "Speed: 3.6ms preprocess, 57.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 107.4ms\n",
            "Speed: 3.7ms preprocess, 107.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 58.4ms\n",
            "Speed: 23.2ms preprocess, 58.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 61.3ms\n",
            "Speed: 35.6ms preprocess, 61.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 56.8ms\n",
            "Speed: 18.3ms preprocess, 56.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 68.7ms\n",
            "Speed: 18.5ms preprocess, 68.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 59.0ms\n",
            "Speed: 21.1ms preprocess, 59.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 75.2ms\n",
            "Speed: 18.8ms preprocess, 75.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 75.5ms\n",
            "Speed: 12.7ms preprocess, 75.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 59.3ms\n",
            "Speed: 8.4ms preprocess, 59.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 59.5ms\n",
            "Speed: 3.8ms preprocess, 59.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 65.0ms\n",
            "Speed: 3.1ms preprocess, 65.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 59.6ms\n",
            "Speed: 7.5ms preprocess, 59.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 91.9ms\n",
            "Speed: 3.1ms preprocess, 91.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 72.9ms\n",
            "Speed: 35.0ms preprocess, 72.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 58.0ms\n",
            "Speed: 30.2ms preprocess, 58.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 64.4ms\n",
            "Speed: 31.4ms preprocess, 64.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 85.9ms\n",
            "Speed: 6.3ms preprocess, 85.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 90.1ms\n",
            "Speed: 46.3ms preprocess, 90.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 69.7ms\n",
            "Speed: 39.6ms preprocess, 69.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 61.9ms\n",
            "Speed: 30.5ms preprocess, 61.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 92.8ms\n",
            "Speed: 5.8ms preprocess, 92.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 67.8ms\n",
            "Speed: 29.8ms preprocess, 67.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 70.4ms\n",
            "Speed: 27.8ms preprocess, 70.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 92.0ms\n",
            "Speed: 52.6ms preprocess, 92.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 78.0ms\n",
            "Speed: 21.3ms preprocess, 78.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 57.4ms\n",
            "Speed: 29.7ms preprocess, 57.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 67.5ms\n",
            "Speed: 7.8ms preprocess, 67.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 56.9ms\n",
            "Speed: 19.6ms preprocess, 56.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 58.6ms\n",
            "Speed: 17.7ms preprocess, 58.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 79.1ms\n",
            "Speed: 49.4ms preprocess, 79.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 59.4ms\n",
            "Speed: 9.1ms preprocess, 59.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 57.4ms\n",
            "Speed: 18.5ms preprocess, 57.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 57.8ms\n",
            "Speed: 18.6ms preprocess, 57.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 55.7ms\n",
            "Speed: 27.3ms preprocess, 55.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 70.2ms\n",
            "Speed: 4.2ms preprocess, 70.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.6ms\n",
            "Speed: 42.5ms preprocess, 62.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.1ms\n",
            "Speed: 3.0ms preprocess, 66.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 67.6ms\n",
            "Speed: 5.8ms preprocess, 67.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.2ms\n",
            "Speed: 3.2ms preprocess, 61.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 74.6ms\n",
            "Speed: 4.4ms preprocess, 74.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.3ms\n",
            "Speed: 27.3ms preprocess, 59.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 55.7ms\n",
            "Speed: 22.3ms preprocess, 55.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 76.1ms\n",
            "Speed: 14.0ms preprocess, 76.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 57.9ms\n",
            "Speed: 29.5ms preprocess, 57.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 74.0ms\n",
            "Speed: 5.5ms preprocess, 74.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 57.5ms\n",
            "Speed: 20.9ms preprocess, 57.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 127.6ms\n",
            "Speed: 4.0ms preprocess, 127.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 54.3ms\n",
            "Speed: 14.3ms preprocess, 54.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 73.7ms\n",
            "Speed: 3.9ms preprocess, 73.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 69.6ms\n",
            "Speed: 7.9ms preprocess, 69.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 58.8ms\n",
            "Speed: 25.4ms preprocess, 58.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.4ms\n",
            "Speed: 17.6ms preprocess, 61.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 83.2ms\n",
            "Speed: 3.2ms preprocess, 83.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 57.6ms\n",
            "Speed: 22.6ms preprocess, 57.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 74.6ms\n",
            "Speed: 3.6ms preprocess, 74.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 66.2ms\n",
            "Speed: 15.5ms preprocess, 66.2ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 67.7ms\n",
            "Speed: 3.8ms preprocess, 67.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 58.6ms\n",
            "Speed: 18.0ms preprocess, 58.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 81.6ms\n",
            "Speed: 40.2ms preprocess, 81.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 61.1ms\n",
            "Speed: 33.3ms preprocess, 61.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 59.1ms\n",
            "Speed: 38.3ms preprocess, 59.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 60.3ms\n",
            "Speed: 27.9ms preprocess, 60.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 92.4ms\n",
            "Speed: 4.5ms preprocess, 92.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 85.9ms\n",
            "Speed: 36.3ms preprocess, 85.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 122.4ms\n",
            "Speed: 3.7ms preprocess, 122.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 73.8ms\n",
            "Speed: 31.1ms preprocess, 73.8ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 76.0ms\n",
            "Speed: 8.7ms preprocess, 76.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 83.4ms\n",
            "Speed: 24.6ms preprocess, 83.4ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 68.3ms\n",
            "Speed: 16.8ms preprocess, 68.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 83.0ms\n",
            "Speed: 29.7ms preprocess, 83.0ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.6ms\n",
            "Speed: 19.7ms preprocess, 60.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 58.0ms\n",
            "Speed: 30.8ms preprocess, 58.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 55.8ms\n",
            "Speed: 18.7ms preprocess, 55.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 56.5ms\n",
            "Speed: 19.0ms preprocess, 56.5ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 61.7ms\n",
            "Speed: 11.3ms preprocess, 61.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 93.0ms\n",
            "Speed: 3.5ms preprocess, 93.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 59.8ms\n",
            "Speed: 18.8ms preprocess, 59.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-77d003e2e815>:158: RuntimeWarning: invalid value encountered in arccos\n",
            "  angle = np.arccos(dot_product)  # 라디안 값으로 각도 계산\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "Speed: 2.7ms preprocess, 64.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 84.4ms\n",
            "Speed: 7.6ms preprocess, 84.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 61.7ms\n",
            "Speed: 19.4ms preprocess, 61.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 66.7ms\n",
            "Speed: 3.2ms preprocess, 66.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 72.8ms\n",
            "Speed: 13.7ms preprocess, 72.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 73.5ms\n",
            "Speed: 18.5ms preprocess, 73.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.8ms\n",
            "Speed: 8.1ms preprocess, 62.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 63.7ms\n",
            "Speed: 33.3ms preprocess, 63.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 108.6ms\n",
            "Speed: 10.3ms preprocess, 108.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 61.2ms\n",
            "Speed: 8.6ms preprocess, 61.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 68.1ms\n",
            "Speed: 11.7ms preprocess, 68.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 63.8ms\n",
            "Speed: 17.9ms preprocess, 63.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 72.7ms\n",
            "Speed: 9.0ms preprocess, 72.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 60.5ms\n",
            "Speed: 7.6ms preprocess, 60.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 62.5ms\n",
            "Speed: 2.8ms preprocess, 62.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 62.7ms\n",
            "Speed: 17.9ms preprocess, 62.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 59.7ms\n",
            "Speed: 9.1ms preprocess, 59.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.9ms\n",
            "Speed: 9.6ms preprocess, 63.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 68.7ms\n",
            "Speed: 3.8ms preprocess, 68.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.4ms\n",
            "Speed: 7.1ms preprocess, 60.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.0ms\n",
            "Speed: 7.7ms preprocess, 62.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.5ms\n",
            "Speed: 5.9ms preprocess, 65.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 61.8ms\n",
            "Speed: 14.2ms preprocess, 61.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 65.8ms\n",
            "Speed: 7.2ms preprocess, 65.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.3ms\n",
            "Speed: 13.5ms preprocess, 66.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.2ms\n",
            "Speed: 6.3ms preprocess, 64.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 67.7ms\n",
            "Speed: 6.2ms preprocess, 67.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.0ms\n",
            "Speed: 6.4ms preprocess, 62.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 66.0ms\n",
            "Speed: 6.0ms preprocess, 66.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.2ms\n",
            "Speed: 10.2ms preprocess, 61.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.0ms\n",
            "Speed: 7.6ms preprocess, 63.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.3ms\n",
            "Speed: 4.7ms preprocess, 66.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.7ms\n",
            "Speed: 4.6ms preprocess, 63.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.1ms\n",
            "Speed: 11.0ms preprocess, 63.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.9ms\n",
            "Speed: 9.0ms preprocess, 62.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.1ms\n",
            "Speed: 5.5ms preprocess, 60.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.2ms\n",
            "Speed: 12.2ms preprocess, 60.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.3ms\n",
            "Speed: 8.4ms preprocess, 61.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.8ms\n",
            "Speed: 3.7ms preprocess, 60.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 83.9ms\n",
            "Speed: 15.5ms preprocess, 83.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.8ms\n",
            "Speed: 9.8ms preprocess, 60.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.0ms\n",
            "Speed: 6.4ms preprocess, 61.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.4ms\n",
            "Speed: 8.0ms preprocess, 62.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.5ms\n",
            "Speed: 5.5ms preprocess, 63.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.0ms\n",
            "Speed: 8.4ms preprocess, 66.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 68.8ms\n",
            "Speed: 10.9ms preprocess, 68.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 74.3ms\n",
            "Speed: 6.6ms preprocess, 74.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.4ms\n",
            "Speed: 18.7ms preprocess, 63.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 68.5ms\n",
            "Speed: 18.7ms preprocess, 68.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 91.5ms\n",
            "Speed: 13.5ms preprocess, 91.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.9ms\n",
            "Speed: 17.6ms preprocess, 63.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.2ms\n",
            "Speed: 23.5ms preprocess, 60.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 98.7ms\n",
            "Speed: 6.9ms preprocess, 98.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 118.2ms\n",
            "Speed: 11.6ms preprocess, 118.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 69.9ms\n",
            "Speed: 17.1ms preprocess, 69.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 85.0ms\n",
            "Speed: 4.6ms preprocess, 85.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.5ms\n",
            "Speed: 8.7ms preprocess, 60.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 92.7ms\n",
            "Speed: 27.5ms preprocess, 92.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.3ms\n",
            "Speed: 6.4ms preprocess, 61.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 67.3ms\n",
            "Speed: 8.6ms preprocess, 67.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.7ms\n",
            "Speed: 8.9ms preprocess, 62.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.1ms\n",
            "Speed: 6.4ms preprocess, 60.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.0ms\n",
            "Speed: 6.5ms preprocess, 63.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.7ms\n",
            "Speed: 4.3ms preprocess, 63.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.6ms\n",
            "Speed: 11.0ms preprocess, 62.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.9ms\n",
            "Speed: 3.3ms preprocess, 62.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 68.7ms\n",
            "Speed: 8.1ms preprocess, 68.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.6ms\n",
            "Speed: 7.7ms preprocess, 61.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.6ms\n",
            "Speed: 8.6ms preprocess, 60.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.3ms\n",
            "Speed: 6.4ms preprocess, 64.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.5ms\n",
            "Speed: 7.2ms preprocess, 62.5ms inference, 8.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.8ms\n",
            "Speed: 8.5ms preprocess, 61.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 67.8ms\n",
            "Speed: 4.1ms preprocess, 67.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.3ms\n",
            "Speed: 7.3ms preprocess, 62.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 86.3ms\n",
            "Speed: 11.9ms preprocess, 86.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.7ms\n",
            "Speed: 7.7ms preprocess, 60.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 68.9ms\n",
            "Speed: 9.1ms preprocess, 68.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.1ms\n",
            "Speed: 13.9ms preprocess, 63.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.6ms\n",
            "Speed: 6.9ms preprocess, 65.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.5ms\n",
            "Speed: 3.2ms preprocess, 66.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.7ms\n",
            "Speed: 10.0ms preprocess, 64.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 76.6ms\n",
            "Speed: 9.9ms preprocess, 76.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.9ms\n",
            "Speed: 6.5ms preprocess, 64.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.6ms\n",
            "Speed: 8.1ms preprocess, 63.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.4ms\n",
            "Speed: 8.3ms preprocess, 62.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.3ms\n",
            "Speed: 21.4ms preprocess, 65.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.5ms\n",
            "Speed: 2.7ms preprocess, 65.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.0ms\n",
            "Speed: 8.6ms preprocess, 64.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 69.2ms\n",
            "Speed: 7.8ms preprocess, 69.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.7ms\n",
            "Speed: 20.0ms preprocess, 64.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.1ms\n",
            "Speed: 7.8ms preprocess, 60.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.8ms\n",
            "Speed: 5.6ms preprocess, 62.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 87.1ms\n",
            "Speed: 9.1ms preprocess, 87.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 71.0ms\n",
            "Speed: 10.2ms preprocess, 71.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.6ms\n",
            "Speed: 11.1ms preprocess, 63.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 78.9ms\n",
            "Speed: 9.9ms preprocess, 78.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.0ms\n",
            "Speed: 17.5ms preprocess, 63.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.1ms\n",
            "Speed: 20.1ms preprocess, 64.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 86.2ms\n",
            "Speed: 3.9ms preprocess, 86.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 146.3ms\n",
            "Speed: 14.3ms preprocess, 146.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 71.1ms\n",
            "Speed: 5.3ms preprocess, 71.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 81.2ms\n",
            "Speed: 11.3ms preprocess, 81.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 78.4ms\n",
            "Speed: 9.7ms preprocess, 78.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 80.0ms\n",
            "Speed: 22.0ms preprocess, 80.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.7ms\n",
            "Speed: 16.0ms preprocess, 62.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 82.2ms\n",
            "Speed: 3.9ms preprocess, 82.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.6ms\n",
            "Speed: 13.5ms preprocess, 60.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.1ms\n",
            "Speed: 8.5ms preprocess, 64.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 82.8ms\n",
            "Speed: 7.7ms preprocess, 82.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 67.6ms\n",
            "Speed: 10.3ms preprocess, 67.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.1ms\n",
            "Speed: 6.9ms preprocess, 62.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 71.4ms\n",
            "Speed: 7.4ms preprocess, 71.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.4ms\n",
            "Speed: 13.6ms preprocess, 60.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 71.2ms\n",
            "Speed: 3.0ms preprocess, 71.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 70.4ms\n",
            "Speed: 9.1ms preprocess, 70.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 66.1ms\n",
            "Speed: 7.5ms preprocess, 66.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 61.2ms\n",
            "Speed: 21.0ms preprocess, 61.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 68.2ms\n",
            "Speed: 12.3ms preprocess, 68.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.0ms\n",
            "Speed: 9.5ms preprocess, 62.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.8ms\n",
            "Speed: 13.2ms preprocess, 62.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.4ms\n",
            "Speed: 7.6ms preprocess, 62.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.8ms\n",
            "Speed: 10.2ms preprocess, 62.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.6ms\n",
            "Speed: 4.4ms preprocess, 64.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.9ms\n",
            "Speed: 9.2ms preprocess, 63.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.5ms\n",
            "Speed: 7.9ms preprocess, 66.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 68.5ms\n",
            "Speed: 6.2ms preprocess, 68.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.3ms\n",
            "Speed: 6.4ms preprocess, 62.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 67.1ms\n",
            "Speed: 10.0ms preprocess, 67.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 69.6ms\n",
            "Speed: 7.4ms preprocess, 69.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 64.2ms\n",
            "Speed: 18.6ms preprocess, 64.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 70.2ms\n",
            "Speed: 7.4ms preprocess, 70.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.2ms\n",
            "Speed: 5.9ms preprocess, 64.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 81.4ms\n",
            "Speed: 6.0ms preprocess, 81.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.8ms\n",
            "Speed: 16.8ms preprocess, 66.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 58.0ms\n",
            "Speed: 19.8ms preprocess, 58.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.8ms\n",
            "Speed: 16.1ms preprocess, 64.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.1ms\n",
            "Speed: 8.1ms preprocess, 62.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.6ms\n",
            "Speed: 8.3ms preprocess, 64.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.6ms\n",
            "Speed: 6.1ms preprocess, 65.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.4ms\n",
            "Speed: 10.2ms preprocess, 61.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 60.1ms\n",
            "Speed: 5.7ms preprocess, 60.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.9ms\n",
            "Speed: 8.9ms preprocess, 61.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 69.3ms\n",
            "Speed: 14.0ms preprocess, 69.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8023\n",
            "\n",
            "0: 384x640 2 persons, 99.2ms\n",
            "Speed: 7.1ms preprocess, 99.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8024\n",
            "\n",
            "0: 384x640 2 persons, 212.7ms\n",
            "Speed: 8.3ms preprocess, 212.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8025\n",
            "\n",
            "0: 384x640 2 persons, 70.2ms\n",
            "Speed: 31.1ms preprocess, 70.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8026\n",
            "\n",
            "0: 384x640 2 persons, 99.4ms\n",
            "Speed: 7.9ms preprocess, 99.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8027\n",
            "\n",
            "0: 384x640 2 persons, 73.2ms\n",
            "Speed: 32.8ms preprocess, 73.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8028\n",
            "\n",
            "0: 384x640 2 persons, 61.7ms\n",
            "Speed: 16.8ms preprocess, 61.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8029\n",
            "\n",
            "0: 384x640 2 persons, 83.7ms\n",
            "Speed: 6.1ms preprocess, 83.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8030\n",
            "\n",
            "0: 384x640 3 persons, 82.8ms\n",
            "Speed: 9.9ms preprocess, 82.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8031\n",
            "\n",
            "0: 384x640 3 persons, 62.3ms\n",
            "Speed: 12.2ms preprocess, 62.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8032\n",
            "\n",
            "0: 384x640 2 persons, 79.9ms\n",
            "Speed: 11.3ms preprocess, 79.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8033\n",
            "\n",
            "0: 384x640 2 persons, 93.5ms\n",
            "Speed: 6.4ms preprocess, 93.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8034\n",
            "\n",
            "0: 384x640 2 persons, 65.0ms\n",
            "Speed: 9.7ms preprocess, 65.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8035\n",
            "\n",
            "0: 384x640 2 persons, 61.7ms\n",
            "Speed: 9.0ms preprocess, 61.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8036\n",
            "\n",
            "0: 384x640 2 persons, 61.2ms\n",
            "Speed: 8.2ms preprocess, 61.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8037\n",
            "\n",
            "0: 384x640 2 persons, 59.6ms\n",
            "Speed: 8.8ms preprocess, 59.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8038\n",
            "\n",
            "0: 384x640 2 persons, 61.0ms\n",
            "Speed: 7.7ms preprocess, 61.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8039\n",
            "\n",
            "0: 384x640 2 persons, 61.9ms\n",
            "Speed: 7.2ms preprocess, 61.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8040\n",
            "\n",
            "0: 384x640 2 persons, 76.0ms\n",
            "Speed: 4.4ms preprocess, 76.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8041\n",
            "\n",
            "0: 384x640 2 persons, 69.0ms\n",
            "Speed: 7.5ms preprocess, 69.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8042\n",
            "\n",
            "0: 384x640 2 persons, 69.1ms\n",
            "Speed: 3.1ms preprocess, 69.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8043\n",
            "\n",
            "0: 384x640 2 persons, 66.4ms\n",
            "Speed: 13.6ms preprocess, 66.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8044\n",
            "\n",
            "0: 384x640 2 persons, 74.7ms\n",
            "Speed: 7.4ms preprocess, 74.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8045\n",
            "\n",
            "0: 384x640 2 persons, 67.3ms\n",
            "Speed: 7.8ms preprocess, 67.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8046\n",
            "\n",
            "0: 384x640 2 persons, 66.7ms\n",
            "Speed: 8.2ms preprocess, 66.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8047\n",
            "\n",
            "0: 384x640 2 persons, 61.7ms\n",
            "Speed: 14.8ms preprocess, 61.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8048\n",
            "\n",
            "0: 384x640 2 persons, 61.6ms\n",
            "Speed: 6.8ms preprocess, 61.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8049\n",
            "\n",
            "0: 384x640 2 persons, 68.0ms\n",
            "Speed: 6.5ms preprocess, 68.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8050\n",
            "\n",
            "0: 384x640 2 persons, 66.9ms\n",
            "Speed: 8.0ms preprocess, 66.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8051\n",
            "\n",
            "0: 384x640 2 persons, 66.9ms\n",
            "Speed: 5.4ms preprocess, 66.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8052\n",
            "\n",
            "0: 384x640 2 persons, 67.9ms\n",
            "Speed: 8.0ms preprocess, 67.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8053\n",
            "\n",
            "0: 384x640 2 persons, 65.7ms\n",
            "Speed: 3.4ms preprocess, 65.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8054\n",
            "\n",
            "0: 384x640 2 persons, 61.1ms\n",
            "Speed: 8.6ms preprocess, 61.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8055\n",
            "\n",
            "0: 384x640 2 persons, 66.7ms\n",
            "Speed: 8.4ms preprocess, 66.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8056\n",
            "\n",
            "0: 384x640 2 persons, 61.5ms\n",
            "Speed: 7.1ms preprocess, 61.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8057\n",
            "\n",
            "0: 384x640 2 persons, 62.1ms\n",
            "Speed: 7.8ms preprocess, 62.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8058\n",
            "\n",
            "0: 384x640 2 persons, 59.8ms\n",
            "Speed: 15.8ms preprocess, 59.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8059\n",
            "\n",
            "0: 384x640 2 persons, 61.8ms\n",
            "Speed: 12.8ms preprocess, 61.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8060\n",
            "\n",
            "0: 384x640 2 persons, 61.7ms\n",
            "Speed: 8.0ms preprocess, 61.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8061\n",
            "\n",
            "0: 384x640 2 persons, 56.8ms\n",
            "Speed: 6.6ms preprocess, 56.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8062\n",
            "\n",
            "0: 384x640 2 persons, 67.1ms\n",
            "Speed: 32.8ms preprocess, 67.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8063\n",
            "\n",
            "0: 384x640 2 persons, 58.5ms\n",
            "Speed: 7.6ms preprocess, 58.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8064\n",
            "\n",
            "0: 384x640 2 persons, 67.2ms\n",
            "Speed: 7.4ms preprocess, 67.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8065\n",
            "\n",
            "0: 384x640 2 persons, 60.5ms\n",
            "Speed: 10.0ms preprocess, 60.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: kicking at frame 8066\n",
            "\n",
            "0: 384x640 2 persons, 72.6ms\n",
            "Speed: 7.5ms preprocess, 72.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.6ms\n",
            "Speed: 6.3ms preprocess, 66.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.6ms\n",
            "Speed: 9.0ms preprocess, 63.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.2ms\n",
            "Speed: 2.9ms preprocess, 65.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 75.0ms\n",
            "Speed: 6.4ms preprocess, 75.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.9ms\n",
            "Speed: 40.6ms preprocess, 60.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.7ms\n",
            "Speed: 19.7ms preprocess, 59.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 84.5ms\n",
            "Speed: 20.7ms preprocess, 84.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 85.1ms\n",
            "Speed: 16.6ms preprocess, 85.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.7ms\n",
            "Speed: 14.3ms preprocess, 65.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 92.3ms\n",
            "Speed: 12.8ms preprocess, 92.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 89.4ms\n",
            "Speed: 26.6ms preprocess, 89.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 92.6ms\n",
            "Speed: 5.9ms preprocess, 92.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 70.6ms\n",
            "Speed: 10.4ms preprocess, 70.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.0ms\n",
            "Speed: 16.9ms preprocess, 64.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.7ms\n",
            "Speed: 10.3ms preprocess, 65.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 129.8ms\n",
            "Speed: 7.3ms preprocess, 129.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.7ms\n",
            "Speed: 8.7ms preprocess, 59.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.8ms\n",
            "Speed: 17.5ms preprocess, 60.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.2ms\n",
            "Speed: 9.0ms preprocess, 61.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.0ms\n",
            "Speed: 3.3ms preprocess, 65.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.4ms\n",
            "Speed: 4.5ms preprocess, 65.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.8ms\n",
            "Speed: 9.1ms preprocess, 60.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.8ms\n",
            "Speed: 10.4ms preprocess, 62.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 73.8ms\n",
            "Speed: 6.4ms preprocess, 73.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.3ms\n",
            "Speed: 9.7ms preprocess, 61.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.2ms\n",
            "Speed: 5.8ms preprocess, 65.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.4ms\n",
            "Speed: 10.6ms preprocess, 64.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 68.0ms\n",
            "Speed: 9.8ms preprocess, 68.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.4ms\n",
            "Speed: 22.1ms preprocess, 62.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.7ms\n",
            "Speed: 5.6ms preprocess, 59.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 58.7ms\n",
            "Speed: 6.3ms preprocess, 58.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.0ms\n",
            "Speed: 5.9ms preprocess, 63.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.3ms\n",
            "Speed: 7.4ms preprocess, 63.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.1ms\n",
            "Speed: 5.4ms preprocess, 61.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 58.9ms\n",
            "Speed: 8.4ms preprocess, 58.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.5ms\n",
            "Speed: 5.1ms preprocess, 62.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.7ms\n",
            "Speed: 7.0ms preprocess, 59.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.5ms\n",
            "Speed: 6.5ms preprocess, 59.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.1ms\n",
            "Speed: 5.7ms preprocess, 59.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.4ms\n",
            "Speed: 8.5ms preprocess, 61.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.9ms\n",
            "Speed: 6.4ms preprocess, 59.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.3ms\n",
            "Speed: 7.8ms preprocess, 59.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 70.9ms\n",
            "Speed: 10.4ms preprocess, 70.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.3ms\n",
            "Speed: 7.0ms preprocess, 59.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 60.9ms\n",
            "Speed: 8.6ms preprocess, 60.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 66.3ms\n",
            "Speed: 3.0ms preprocess, 66.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 59.0ms\n",
            "Speed: 8.5ms preprocess, 59.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 61.3ms\n",
            "Speed: 3.7ms preprocess, 61.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 62.5ms\n",
            "Speed: 7.9ms preprocess, 62.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 64.4ms\n",
            "Speed: 15.9ms preprocess, 64.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.1ms\n",
            "Speed: 9.6ms preprocess, 59.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.9ms\n",
            "Speed: 8.0ms preprocess, 64.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.4ms\n",
            "Speed: 24.4ms preprocess, 63.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.1ms\n",
            "Speed: 36.7ms preprocess, 63.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 88.5ms\n",
            "Speed: 6.3ms preprocess, 88.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 68.2ms\n",
            "Speed: 7.8ms preprocess, 68.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 69.2ms\n",
            "Speed: 7.1ms preprocess, 69.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 106.7ms\n",
            "Speed: 11.8ms preprocess, 106.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 69.8ms\n",
            "Speed: 12.9ms preprocess, 69.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.7ms\n",
            "Speed: 12.7ms preprocess, 66.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 69.9ms\n",
            "Speed: 9.8ms preprocess, 69.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 104.0ms\n",
            "Speed: 18.5ms preprocess, 104.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 81.2ms\n",
            "Speed: 11.0ms preprocess, 81.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 76.1ms\n",
            "Speed: 12.6ms preprocess, 76.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 76.1ms\n",
            "Speed: 4.1ms preprocess, 76.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 71.9ms\n",
            "Speed: 7.5ms preprocess, 71.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.2ms\n",
            "Speed: 6.6ms preprocess, 60.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 57.6ms\n",
            "Speed: 8.7ms preprocess, 57.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.0ms\n",
            "Speed: 10.6ms preprocess, 61.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 72.9ms\n",
            "Speed: 6.3ms preprocess, 72.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.6ms\n",
            "Speed: 8.8ms preprocess, 60.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.4ms\n",
            "Speed: 2.9ms preprocess, 62.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 64.8ms\n",
            "Speed: 5.8ms preprocess, 64.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 61.6ms\n",
            "Speed: 10.2ms preprocess, 61.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 60.2ms\n",
            "Speed: 6.5ms preprocess, 60.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 59.5ms\n",
            "Speed: 6.7ms preprocess, 59.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 65.9ms\n",
            "Speed: 3.3ms preprocess, 65.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 65.7ms\n",
            "Speed: 6.1ms preprocess, 65.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 67.7ms\n",
            "Speed: 5.9ms preprocess, 67.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 66.3ms\n",
            "Speed: 7.6ms preprocess, 66.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 61.5ms\n",
            "Speed: 10.3ms preprocess, 61.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 58.2ms\n",
            "Speed: 8.5ms preprocess, 58.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 60.2ms\n",
            "Speed: 5.8ms preprocess, 60.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 60.9ms\n",
            "Speed: 7.3ms preprocess, 60.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 62.4ms\n",
            "Speed: 5.1ms preprocess, 62.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 61.5ms\n",
            "Speed: 4.9ms preprocess, 61.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.0ms\n",
            "Speed: 6.9ms preprocess, 65.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 58.9ms\n",
            "Speed: 7.2ms preprocess, 58.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 60.8ms\n",
            "Speed: 13.9ms preprocess, 60.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 66.6ms\n",
            "Speed: 7.8ms preprocess, 66.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 62.2ms\n",
            "Speed: 6.9ms preprocess, 62.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 62.0ms\n",
            "Speed: 6.3ms preprocess, 62.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 57.9ms\n",
            "Speed: 20.2ms preprocess, 57.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.5ms\n",
            "Speed: 10.5ms preprocess, 62.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 66.2ms\n",
            "Speed: 3.4ms preprocess, 66.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.2ms\n",
            "Speed: 6.2ms preprocess, 61.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.6ms\n",
            "Speed: 7.6ms preprocess, 59.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 60.8ms\n",
            "Speed: 7.0ms preprocess, 60.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 141.5ms\n",
            "Speed: 15.4ms preprocess, 141.5ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 59.1ms\n",
            "Speed: 17.0ms preprocess, 59.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 70.6ms\n",
            "Speed: 7.4ms preprocess, 70.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 64.4ms\n",
            "Speed: 19.2ms preprocess, 64.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 138.2ms\n",
            "Speed: 40.4ms preprocess, 138.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 76.2ms\n",
            "Speed: 23.6ms preprocess, 76.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 71.1ms\n",
            "Speed: 14.0ms preprocess, 71.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 64.3ms\n",
            "Speed: 11.2ms preprocess, 64.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 73.2ms\n",
            "Speed: 7.0ms preprocess, 73.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 80.8ms\n",
            "Speed: 9.3ms preprocess, 80.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 71.4ms\n",
            "Speed: 6.3ms preprocess, 71.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 57.4ms\n",
            "Speed: 8.8ms preprocess, 57.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.1ms\n",
            "Speed: 4.8ms preprocess, 60.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 57.2ms\n",
            "Speed: 26.9ms preprocess, 57.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 66.5ms\n",
            "Speed: 2.6ms preprocess, 66.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 65.2ms\n",
            "Speed: 10.6ms preprocess, 65.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 58.7ms\n",
            "Speed: 9.5ms preprocess, 58.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 75.0ms\n",
            "Speed: 5.5ms preprocess, 75.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 58.3ms\n",
            "Speed: 7.8ms preprocess, 58.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 61.2ms\n",
            "Speed: 7.6ms preprocess, 61.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.8ms\n",
            "Speed: 18.0ms preprocess, 60.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.4ms\n",
            "Speed: 8.4ms preprocess, 62.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 67.2ms\n",
            "Speed: 11.6ms preprocess, 67.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 58.2ms\n",
            "Speed: 7.1ms preprocess, 58.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 63.5ms\n",
            "Speed: 10.2ms preprocess, 63.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 64.4ms\n",
            "Speed: 8.6ms preprocess, 64.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 62.3ms\n",
            "Speed: 7.4ms preprocess, 62.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 54.8ms\n",
            "Speed: 8.1ms preprocess, 54.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 59.5ms\n",
            "Speed: 7.3ms preprocess, 59.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 59.5ms\n",
            "Speed: 8.3ms preprocess, 59.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 58.7ms\n",
            "Speed: 7.2ms preprocess, 58.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.8ms\n",
            "Speed: 8.0ms preprocess, 59.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 55.3ms\n",
            "Speed: 16.2ms preprocess, 55.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 69.8ms\n",
            "Speed: 7.2ms preprocess, 69.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.6ms\n",
            "Speed: 5.9ms preprocess, 65.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.9ms\n",
            "Speed: 6.3ms preprocess, 64.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 61.6ms\n",
            "Speed: 8.0ms preprocess, 61.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 55.7ms\n",
            "Speed: 7.8ms preprocess, 55.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 55.9ms\n",
            "Speed: 25.4ms preprocess, 55.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 67.6ms\n",
            "Speed: 4.2ms preprocess, 67.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 60.0ms\n",
            "Speed: 4.1ms preprocess, 60.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 61.8ms\n",
            "Speed: 8.7ms preprocess, 61.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 90.9ms\n",
            "Speed: 9.9ms preprocess, 90.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 62.0ms\n",
            "Speed: 14.5ms preprocess, 62.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 68.2ms\n",
            "Speed: 15.0ms preprocess, 68.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 69.0ms\n",
            "Speed: 7.5ms preprocess, 69.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 72.1ms\n",
            "Speed: 40.7ms preprocess, 72.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 64.5ms\n",
            "Speed: 7.0ms preprocess, 64.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 62.3ms\n",
            "Speed: 28.5ms preprocess, 62.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 73.5ms\n",
            "Speed: 10.7ms preprocess, 73.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 110.6ms\n",
            "Speed: 42.0ms preprocess, 110.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 69.1ms\n",
            "Speed: 5.8ms preprocess, 69.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 62.4ms\n",
            "Speed: 2.8ms preprocess, 62.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.6ms\n",
            "Speed: 5.8ms preprocess, 64.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 85.9ms\n",
            "Speed: 4.1ms preprocess, 85.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 61.3ms\n",
            "Speed: 7.2ms preprocess, 61.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 57.0ms\n",
            "Speed: 12.6ms preprocess, 57.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 66.0ms\n",
            "Speed: 9.4ms preprocess, 66.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 64.2ms\n",
            "Speed: 9.6ms preprocess, 64.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 62.9ms\n",
            "Speed: 7.2ms preprocess, 62.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 67.2ms\n",
            "Speed: 12.2ms preprocess, 67.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 62.2ms\n",
            "Speed: 7.2ms preprocess, 62.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 59.3ms\n",
            "Speed: 9.8ms preprocess, 59.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 70.0ms\n",
            "Speed: 13.7ms preprocess, 70.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 55.6ms\n",
            "Speed: 10.7ms preprocess, 55.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.2ms\n",
            "Speed: 5.1ms preprocess, 60.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.9ms\n",
            "Speed: 7.1ms preprocess, 59.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 58.4ms\n",
            "Speed: 21.9ms preprocess, 58.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.5ms\n",
            "Speed: 4.2ms preprocess, 60.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.6ms\n",
            "Speed: 6.8ms preprocess, 60.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 58.8ms\n",
            "Speed: 10.0ms preprocess, 58.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 58.0ms\n",
            "Speed: 6.8ms preprocess, 58.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.5ms\n",
            "Speed: 6.6ms preprocess, 60.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 60.8ms\n",
            "Speed: 6.5ms preprocess, 60.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 71.0ms\n",
            "Speed: 2.8ms preprocess, 71.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.2ms\n",
            "Speed: 6.0ms preprocess, 62.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 58.6ms\n",
            "Speed: 16.0ms preprocess, 58.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.3ms\n",
            "Speed: 5.5ms preprocess, 63.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.6ms\n",
            "Speed: 8.4ms preprocess, 66.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.6ms\n",
            "Speed: 8.4ms preprocess, 61.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.1ms\n",
            "Speed: 7.9ms preprocess, 61.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.4ms\n",
            "Speed: 7.8ms preprocess, 63.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.4ms\n",
            "Speed: 7.3ms preprocess, 63.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.0ms\n",
            "Speed: 6.6ms preprocess, 60.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.7ms\n",
            "Speed: 13.7ms preprocess, 65.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.3ms\n",
            "Speed: 20.2ms preprocess, 60.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.8ms\n",
            "Speed: 10.2ms preprocess, 61.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 84.3ms\n",
            "Speed: 8.5ms preprocess, 84.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.4ms\n",
            "Speed: 13.9ms preprocess, 59.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 73.5ms\n",
            "Speed: 12.9ms preprocess, 73.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 67.3ms\n",
            "Speed: 12.6ms preprocess, 67.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 100.6ms\n",
            "Speed: 6.4ms preprocess, 100.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 80.3ms\n",
            "Speed: 21.6ms preprocess, 80.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 90.3ms\n",
            "Speed: 10.8ms preprocess, 90.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.8ms\n",
            "Speed: 12.2ms preprocess, 63.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 67.4ms\n",
            "Speed: 8.8ms preprocess, 67.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 87.7ms\n",
            "Speed: 4.9ms preprocess, 87.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.0ms\n",
            "Speed: 11.4ms preprocess, 65.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.1ms\n",
            "Speed: 12.9ms preprocess, 60.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 72.1ms\n",
            "Speed: 10.6ms preprocess, 72.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.0ms\n",
            "Speed: 9.6ms preprocess, 61.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 58.3ms\n",
            "Speed: 6.6ms preprocess, 58.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.1ms\n",
            "Speed: 7.4ms preprocess, 60.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.4ms\n",
            "Speed: 6.8ms preprocess, 63.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 70.9ms\n",
            "Speed: 19.7ms preprocess, 70.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.8ms\n",
            "Speed: 7.2ms preprocess, 61.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 74.1ms\n",
            "Speed: 7.3ms preprocess, 74.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.0ms\n",
            "Speed: 6.4ms preprocess, 64.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.0ms\n",
            "Speed: 7.0ms preprocess, 64.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 70.7ms\n",
            "Speed: 3.6ms preprocess, 70.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.2ms\n",
            "Speed: 8.9ms preprocess, 66.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.6ms\n",
            "Speed: 9.9ms preprocess, 63.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.6ms\n",
            "Speed: 7.1ms preprocess, 65.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 60.9ms\n",
            "Speed: 7.0ms preprocess, 60.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 59.6ms\n",
            "Speed: 15.4ms preprocess, 59.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 66.8ms\n",
            "Speed: 5.1ms preprocess, 66.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 64.6ms\n",
            "Speed: 8.0ms preprocess, 64.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.1ms\n",
            "Speed: 6.5ms preprocess, 63.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 69.5ms\n",
            "Speed: 2.9ms preprocess, 69.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.8ms\n",
            "Speed: 9.5ms preprocess, 59.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 68.5ms\n",
            "Speed: 13.5ms preprocess, 68.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.4ms\n",
            "Speed: 9.3ms preprocess, 60.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.0ms\n",
            "Speed: 6.5ms preprocess, 64.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.7ms\n",
            "Speed: 6.2ms preprocess, 63.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 65.9ms\n",
            "Speed: 9.6ms preprocess, 65.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 58.8ms\n",
            "Speed: 7.2ms preprocess, 58.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 63.6ms\n",
            "Speed: 10.4ms preprocess, 63.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.4ms\n",
            "Speed: 6.9ms preprocess, 64.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 68.1ms\n",
            "Speed: 7.6ms preprocess, 68.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 67.3ms\n",
            "Speed: 6.7ms preprocess, 67.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 80.8ms\n",
            "Speed: 9.3ms preprocess, 80.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.8ms\n",
            "Speed: 7.5ms preprocess, 61.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 61.4ms\n",
            "Speed: 6.4ms preprocess, 61.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.6ms\n",
            "Speed: 3.6ms preprocess, 62.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.3ms\n",
            "Speed: 7.8ms preprocess, 61.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 74.8ms\n",
            "Speed: 9.2ms preprocess, 74.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.0ms\n",
            "Speed: 30.9ms preprocess, 63.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 108.7ms\n",
            "Speed: 27.0ms preprocess, 108.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.0ms\n",
            "Speed: 7.1ms preprocess, 61.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.2ms\n",
            "Speed: 18.8ms preprocess, 59.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 68.2ms\n",
            "Speed: 20.0ms preprocess, 68.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 75.1ms\n",
            "Speed: 37.2ms preprocess, 75.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 76.2ms\n",
            "Speed: 14.2ms preprocess, 76.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 75.9ms\n",
            "Speed: 6.7ms preprocess, 75.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.7ms\n",
            "Speed: 21.6ms preprocess, 61.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 121.9ms\n",
            "Speed: 7.4ms preprocess, 121.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 83.9ms\n",
            "Speed: 7.1ms preprocess, 83.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 56.6ms\n",
            "Speed: 4.5ms preprocess, 56.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.2ms\n",
            "Speed: 9.1ms preprocess, 61.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.5ms\n",
            "Speed: 4.2ms preprocess, 63.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 69.5ms\n",
            "Speed: 8.0ms preprocess, 69.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.3ms\n",
            "Speed: 6.5ms preprocess, 59.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.8ms\n",
            "Speed: 7.8ms preprocess, 61.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.6ms\n",
            "Speed: 6.6ms preprocess, 60.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.9ms\n",
            "Speed: 5.1ms preprocess, 63.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.0ms\n",
            "Speed: 7.4ms preprocess, 63.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.7ms\n",
            "Speed: 10.0ms preprocess, 60.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 58.3ms\n",
            "Speed: 10.4ms preprocess, 58.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 77.4ms\n",
            "Speed: 5.4ms preprocess, 77.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.8ms\n",
            "Speed: 3.7ms preprocess, 61.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.5ms\n",
            "Speed: 8.0ms preprocess, 59.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 57.7ms\n",
            "Speed: 4.7ms preprocess, 57.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 76.6ms\n",
            "Speed: 6.0ms preprocess, 76.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.6ms\n",
            "Speed: 6.4ms preprocess, 61.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 58.9ms\n",
            "Speed: 7.7ms preprocess, 58.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.9ms\n",
            "Speed: 3.5ms preprocess, 61.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 71.5ms\n",
            "Speed: 21.4ms preprocess, 71.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.9ms\n",
            "Speed: 5.9ms preprocess, 59.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.3ms\n",
            "Speed: 6.2ms preprocess, 61.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.7ms\n",
            "Speed: 8.5ms preprocess, 60.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.2ms\n",
            "Speed: 7.8ms preprocess, 59.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.1ms\n",
            "Speed: 14.8ms preprocess, 59.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.3ms\n",
            "Speed: 11.1ms preprocess, 63.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.1ms\n",
            "Speed: 6.9ms preprocess, 60.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 76.8ms\n",
            "Speed: 5.3ms preprocess, 76.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.0ms\n",
            "Speed: 5.7ms preprocess, 60.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.6ms\n",
            "Speed: 11.9ms preprocess, 59.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.4ms\n",
            "Speed: 8.7ms preprocess, 61.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.8ms\n",
            "Speed: 5.2ms preprocess, 62.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.3ms\n",
            "Speed: 5.6ms preprocess, 61.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 58.0ms\n",
            "Speed: 6.7ms preprocess, 58.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 74.5ms\n",
            "Speed: 7.4ms preprocess, 74.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.0ms\n",
            "Speed: 6.5ms preprocess, 64.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 57.8ms\n",
            "Speed: 5.7ms preprocess, 57.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.6ms\n",
            "Speed: 12.6ms preprocess, 66.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 69.6ms\n",
            "Speed: 6.5ms preprocess, 69.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 67.5ms\n",
            "Speed: 7.7ms preprocess, 67.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 87.8ms\n",
            "Speed: 4.8ms preprocess, 87.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 79.5ms\n",
            "Speed: 11.2ms preprocess, 79.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.3ms\n",
            "Speed: 12.2ms preprocess, 64.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.4ms\n",
            "Speed: 11.2ms preprocess, 64.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 109.2ms\n",
            "Speed: 18.7ms preprocess, 109.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 95.8ms\n",
            "Speed: 19.5ms preprocess, 95.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 76.4ms\n",
            "Speed: 16.7ms preprocess, 76.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.9ms\n",
            "Speed: 21.9ms preprocess, 60.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.0ms\n",
            "Speed: 47.5ms preprocess, 65.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 76.6ms\n",
            "Speed: 10.0ms preprocess, 76.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.1ms\n",
            "Speed: 4.1ms preprocess, 61.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.1ms\n",
            "Speed: 13.1ms preprocess, 60.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.8ms\n",
            "Speed: 7.6ms preprocess, 63.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.1ms\n",
            "Speed: 7.8ms preprocess, 60.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.2ms\n",
            "Speed: 6.9ms preprocess, 59.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.6ms\n",
            "Speed: 8.3ms preprocess, 60.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.9ms\n",
            "Speed: 7.7ms preprocess, 62.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.0ms\n",
            "Speed: 9.8ms preprocess, 63.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 73.5ms\n",
            "Speed: 6.7ms preprocess, 73.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 58.7ms\n",
            "Speed: 7.2ms preprocess, 58.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 84.2ms\n",
            "Speed: 12.2ms preprocess, 84.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.2ms\n",
            "Speed: 6.2ms preprocess, 62.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 71.2ms\n",
            "Speed: 9.0ms preprocess, 71.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.8ms\n",
            "Speed: 2.5ms preprocess, 60.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.3ms\n",
            "Speed: 6.2ms preprocess, 61.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.8ms\n",
            "Speed: 5.5ms preprocess, 62.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.1ms\n",
            "Speed: 16.0ms preprocess, 66.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.3ms\n",
            "Speed: 4.4ms preprocess, 63.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.6ms\n",
            "Speed: 6.8ms preprocess, 64.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.1ms\n",
            "Speed: 6.7ms preprocess, 64.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 73.0ms\n",
            "Speed: 6.4ms preprocess, 73.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.0ms\n",
            "Speed: 4.0ms preprocess, 64.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.3ms\n",
            "Speed: 8.2ms preprocess, 65.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 68.6ms\n",
            "Speed: 7.3ms preprocess, 68.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.3ms\n",
            "Speed: 7.7ms preprocess, 59.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.1ms\n",
            "Speed: 3.3ms preprocess, 65.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 67.6ms\n",
            "Speed: 7.9ms preprocess, 67.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 76.6ms\n",
            "Speed: 7.6ms preprocess, 76.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.7ms\n",
            "Speed: 7.6ms preprocess, 64.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.5ms\n",
            "Speed: 4.1ms preprocess, 60.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.9ms\n",
            "Speed: 7.8ms preprocess, 59.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.8ms\n",
            "Speed: 6.8ms preprocess, 66.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 58.0ms\n",
            "Speed: 8.7ms preprocess, 58.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.7ms\n",
            "Speed: 19.2ms preprocess, 60.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.7ms\n",
            "Speed: 5.4ms preprocess, 61.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.8ms\n",
            "Speed: 5.2ms preprocess, 64.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.6ms\n",
            "Speed: 4.1ms preprocess, 60.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.7ms\n",
            "Speed: 17.5ms preprocess, 59.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 73.9ms\n",
            "Speed: 7.8ms preprocess, 73.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 163.4ms\n",
            "Speed: 16.5ms preprocess, 163.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.8ms\n",
            "Speed: 12.4ms preprocess, 63.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 75.4ms\n",
            "Speed: 14.2ms preprocess, 75.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 70.3ms\n",
            "Speed: 3.6ms preprocess, 70.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.2ms\n",
            "Speed: 11.6ms preprocess, 62.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.9ms\n",
            "Speed: 21.4ms preprocess, 61.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 79.8ms\n",
            "Speed: 12.4ms preprocess, 79.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 66.9ms\n",
            "Speed: 7.3ms preprocess, 66.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 80.0ms\n",
            "Speed: 17.4ms preprocess, 80.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 123.8ms\n",
            "Speed: 8.7ms preprocess, 123.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 66.7ms\n",
            "Speed: 30.4ms preprocess, 66.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 65.1ms\n",
            "Speed: 12.8ms preprocess, 65.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 65.9ms\n",
            "Speed: 10.3ms preprocess, 65.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 92.7ms\n",
            "Speed: 51.6ms preprocess, 92.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 67.5ms\n",
            "Speed: 7.9ms preprocess, 67.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 75.3ms\n",
            "Speed: 13.7ms preprocess, 75.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 60.0ms\n",
            "Speed: 17.8ms preprocess, 60.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 81.3ms\n",
            "Speed: 18.5ms preprocess, 81.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 58.4ms\n",
            "Speed: 8.3ms preprocess, 58.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 59.2ms\n",
            "Speed: 7.5ms preprocess, 59.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 62.0ms\n",
            "Speed: 6.7ms preprocess, 62.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 62.8ms\n",
            "Speed: 7.8ms preprocess, 62.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8423\n",
            "\n",
            "0: 384x640 3 persons, 61.6ms\n",
            "Speed: 4.1ms preprocess, 61.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8424\n",
            "\n",
            "0: 384x640 3 persons, 60.4ms\n",
            "Speed: 6.5ms preprocess, 60.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8425\n",
            "\n",
            "0: 384x640 3 persons, 62.0ms\n",
            "Speed: 9.4ms preprocess, 62.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8426\n",
            "\n",
            "0: 384x640 3 persons, 62.7ms\n",
            "Speed: 5.5ms preprocess, 62.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8427\n",
            "\n",
            "0: 384x640 3 persons, 58.5ms\n",
            "Speed: 8.5ms preprocess, 58.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8428\n",
            "\n",
            "0: 384x640 3 persons, 68.2ms\n",
            "Speed: 13.8ms preprocess, 68.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8429\n",
            "\n",
            "0: 384x640 3 persons, 59.3ms\n",
            "Speed: 5.7ms preprocess, 59.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8430\n",
            "\n",
            "0: 384x640 3 persons, 59.4ms\n",
            "Speed: 5.1ms preprocess, 59.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8431\n",
            "\n",
            "0: 384x640 3 persons, 70.0ms\n",
            "Speed: 6.4ms preprocess, 70.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8432\n",
            "\n",
            "0: 384x640 3 persons, 60.6ms\n",
            "Speed: 2.9ms preprocess, 60.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8433\n",
            "\n",
            "0: 384x640 3 persons, 60.2ms\n",
            "Speed: 5.9ms preprocess, 60.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8434\n",
            "\n",
            "0: 384x640 3 persons, 62.4ms\n",
            "Speed: 5.8ms preprocess, 62.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8435\n",
            "\n",
            "0: 384x640 3 persons, 59.6ms\n",
            "Speed: 14.2ms preprocess, 59.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8436\n",
            "\n",
            "0: 384x640 3 persons, 61.5ms\n",
            "Speed: 7.3ms preprocess, 61.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8437\n",
            "\n",
            "0: 384x640 4 persons, 79.5ms\n",
            "Speed: 12.6ms preprocess, 79.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8438\n",
            "\n",
            "0: 384x640 3 persons, 62.1ms\n",
            "Speed: 8.1ms preprocess, 62.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8439\n",
            "\n",
            "0: 384x640 3 persons, 88.9ms\n",
            "Speed: 10.0ms preprocess, 88.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8440\n",
            "\n",
            "0: 384x640 3 persons, 68.5ms\n",
            "Speed: 17.0ms preprocess, 68.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8441\n",
            "\n",
            "0: 384x640 3 persons, 68.2ms\n",
            "Speed: 15.0ms preprocess, 68.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8442\n",
            "\n",
            "0: 384x640 3 persons, 74.1ms\n",
            "Speed: 11.8ms preprocess, 74.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8443\n",
            "\n",
            "0: 384x640 4 persons, 101.2ms\n",
            "Speed: 17.8ms preprocess, 101.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8444\n",
            "\n",
            "0: 384x640 3 persons, 70.0ms\n",
            "Speed: 22.8ms preprocess, 70.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8445\n",
            "\n",
            "0: 384x640 3 persons, 73.2ms\n",
            "Speed: 16.5ms preprocess, 73.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8446\n",
            "\n",
            "0: 384x640 3 persons, 78.3ms\n",
            "Speed: 16.5ms preprocess, 78.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8447\n",
            "\n",
            "0: 384x640 3 persons, 91.1ms\n",
            "Speed: 39.3ms preprocess, 91.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8448\n",
            "\n",
            "0: 384x640 3 persons, 87.6ms\n",
            "Speed: 10.6ms preprocess, 87.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8449\n",
            "\n",
            "0: 384x640 3 persons, 65.0ms\n",
            "Speed: 7.4ms preprocess, 65.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8450\n",
            "\n",
            "0: 384x640 3 persons, 67.8ms\n",
            "Speed: 8.6ms preprocess, 67.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8451\n",
            "\n",
            "0: 384x640 3 persons, 71.3ms\n",
            "Speed: 6.3ms preprocess, 71.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8452\n",
            "\n",
            "0: 384x640 3 persons, 60.8ms\n",
            "Speed: 4.4ms preprocess, 60.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8453\n",
            "\n",
            "0: 384x640 3 persons, 74.4ms\n",
            "Speed: 4.0ms preprocess, 74.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8454\n",
            "\n",
            "0: 384x640 3 persons, 65.8ms\n",
            "Speed: 4.5ms preprocess, 65.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8455\n",
            "\n",
            "0: 384x640 3 persons, 60.0ms\n",
            "Speed: 6.8ms preprocess, 60.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8456\n",
            "\n",
            "0: 384x640 3 persons, 62.4ms\n",
            "Speed: 7.3ms preprocess, 62.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8457\n",
            "\n",
            "0: 384x640 3 persons, 61.9ms\n",
            "Speed: 6.0ms preprocess, 61.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8458\n",
            "\n",
            "0: 384x640 3 persons, 65.0ms\n",
            "Speed: 15.5ms preprocess, 65.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8459\n",
            "\n",
            "0: 384x640 3 persons, 93.5ms\n",
            "Speed: 6.4ms preprocess, 93.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8460\n",
            "\n",
            "0: 384x640 3 persons, 63.0ms\n",
            "Speed: 5.5ms preprocess, 63.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8461\n",
            "\n",
            "0: 384x640 3 persons, 60.7ms\n",
            "Speed: 8.3ms preprocess, 60.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8462\n",
            "\n",
            "0: 384x640 3 persons, 74.1ms\n",
            "Speed: 2.9ms preprocess, 74.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8463\n",
            "\n",
            "0: 384x640 3 persons, 60.0ms\n",
            "Speed: 5.6ms preprocess, 60.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8464\n",
            "\n",
            "0: 384x640 3 persons, 58.6ms\n",
            "Speed: 12.5ms preprocess, 58.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8465\n",
            "\n",
            "0: 384x640 3 persons, 63.3ms\n",
            "Speed: 15.3ms preprocess, 63.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8466\n",
            "\n",
            "0: 384x640 3 persons, 63.1ms\n",
            "Speed: 3.0ms preprocess, 63.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8467\n",
            "\n",
            "0: 384x640 3 persons, 60.7ms\n",
            "Speed: 10.1ms preprocess, 60.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8468\n",
            "\n",
            "0: 384x640 3 persons, 66.3ms\n",
            "Speed: 5.4ms preprocess, 66.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8469\n",
            "\n",
            "0: 384x640 3 persons, 59.5ms\n",
            "Speed: 8.2ms preprocess, 59.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8470\n",
            "\n",
            "0: 384x640 3 persons, 59.4ms\n",
            "Speed: 9.2ms preprocess, 59.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8471\n",
            "\n",
            "0: 384x640 3 persons, 65.4ms\n",
            "Speed: 8.8ms preprocess, 65.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8472\n",
            "\n",
            "0: 384x640 3 persons, 62.3ms\n",
            "Speed: 36.7ms preprocess, 62.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8473\n",
            "\n",
            "0: 384x640 3 persons, 59.6ms\n",
            "Speed: 16.3ms preprocess, 59.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8474\n",
            "\n",
            "0: 384x640 3 persons, 64.8ms\n",
            "Speed: 21.7ms preprocess, 64.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8475\n",
            "\n",
            "0: 384x640 3 persons, 60.8ms\n",
            "Speed: 5.8ms preprocess, 60.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8476\n",
            "\n",
            "0: 384x640 3 persons, 90.0ms\n",
            "Speed: 7.0ms preprocess, 90.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8477\n",
            "\n",
            "0: 384x640 3 persons, 65.6ms\n",
            "Speed: 9.2ms preprocess, 65.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8478\n",
            "\n",
            "0: 384x640 3 persons, 70.2ms\n",
            "Speed: 6.0ms preprocess, 70.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8479\n",
            "\n",
            "0: 384x640 3 persons, 77.4ms\n",
            "Speed: 6.9ms preprocess, 77.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8480\n",
            "\n",
            "0: 384x640 3 persons, 102.9ms\n",
            "Speed: 25.9ms preprocess, 102.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8481\n",
            "\n",
            "0: 384x640 3 persons, 60.4ms\n",
            "Speed: 22.0ms preprocess, 60.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8482\n",
            "\n",
            "0: 384x640 3 persons, 61.0ms\n",
            "Speed: 35.3ms preprocess, 61.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8483\n",
            "\n",
            "0: 384x640 3 persons, 64.7ms\n",
            "Speed: 34.5ms preprocess, 64.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8484\n",
            "\n",
            "0: 384x640 3 persons, 77.2ms\n",
            "Speed: 41.0ms preprocess, 77.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8485\n",
            "\n",
            "0: 384x640 3 persons, 75.4ms\n",
            "Speed: 31.5ms preprocess, 75.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8486\n",
            "\n",
            "0: 384x640 3 persons, 82.9ms\n",
            "Speed: 9.4ms preprocess, 82.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8487\n",
            "\n",
            "0: 384x640 3 persons, 68.6ms\n",
            "Speed: 27.3ms preprocess, 68.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8488\n",
            "\n",
            "0: 384x640 3 persons, 130.3ms\n",
            "Speed: 16.9ms preprocess, 130.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8489\n",
            "\n",
            "0: 384x640 3 persons, 61.2ms\n",
            "Speed: 10.5ms preprocess, 61.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8490\n",
            "\n",
            "0: 384x640 3 persons, 65.7ms\n",
            "Speed: 16.5ms preprocess, 65.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8491\n",
            "\n",
            "0: 384x640 3 persons, 61.2ms\n",
            "Speed: 13.0ms preprocess, 61.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8492\n",
            "\n",
            "0: 384x640 3 persons, 59.5ms\n",
            "Speed: 8.0ms preprocess, 59.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8493\n",
            "\n",
            "0: 384x640 4 persons, 64.2ms\n",
            "Speed: 19.5ms preprocess, 64.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8494\n",
            "\n",
            "0: 384x640 3 persons, 60.0ms\n",
            "Speed: 13.1ms preprocess, 60.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8495\n",
            "\n",
            "0: 384x640 4 persons, 56.6ms\n",
            "Speed: 6.8ms preprocess, 56.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8496\n",
            "\n",
            "0: 384x640 4 persons, 63.9ms\n",
            "Speed: 16.0ms preprocess, 63.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8497\n",
            "\n",
            "0: 384x640 4 persons, 61.6ms\n",
            "Speed: 32.4ms preprocess, 61.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8498\n",
            "\n",
            "0: 384x640 4 persons, 55.5ms\n",
            "Speed: 14.2ms preprocess, 55.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8499\n",
            "\n",
            "0: 384x640 4 persons, 63.3ms\n",
            "Speed: 7.8ms preprocess, 63.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8500\n",
            "\n",
            "0: 384x640 4 persons, 61.5ms\n",
            "Speed: 6.7ms preprocess, 61.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8501\n",
            "\n",
            "0: 384x640 3 persons, 68.9ms\n",
            "Speed: 8.4ms preprocess, 68.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8502\n",
            "\n",
            "0: 384x640 3 persons, 62.7ms\n",
            "Speed: 12.5ms preprocess, 62.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8503\n",
            "\n",
            "0: 384x640 3 persons, 62.8ms\n",
            "Speed: 19.7ms preprocess, 62.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8504\n",
            "\n",
            "0: 384x640 3 persons, 64.8ms\n",
            "Speed: 14.7ms preprocess, 64.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8505\n",
            "\n",
            "0: 384x640 3 persons, 62.0ms\n",
            "Speed: 2.9ms preprocess, 62.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8506\n",
            "\n",
            "0: 384x640 3 persons, 67.0ms\n",
            "Speed: 4.8ms preprocess, 67.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8507\n",
            "\n",
            "0: 384x640 3 persons, 69.6ms\n",
            "Speed: 8.4ms preprocess, 69.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8508\n",
            "\n",
            "0: 384x640 3 persons, 64.7ms\n",
            "Speed: 11.0ms preprocess, 64.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8509\n",
            "\n",
            "0: 384x640 2 persons, 61.1ms\n",
            "Speed: 24.6ms preprocess, 61.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8510\n",
            "\n",
            "0: 384x640 3 persons, 71.5ms\n",
            "Speed: 5.8ms preprocess, 71.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8511\n",
            "\n",
            "0: 384x640 3 persons, 61.2ms\n",
            "Speed: 14.4ms preprocess, 61.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8512\n",
            "\n",
            "0: 384x640 3 persons, 59.4ms\n",
            "Speed: 7.6ms preprocess, 59.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8513\n",
            "\n",
            "0: 384x640 3 persons, 68.7ms\n",
            "Speed: 4.1ms preprocess, 68.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8514\n",
            "\n",
            "0: 384x640 2 persons, 58.9ms\n",
            "Speed: 12.3ms preprocess, 58.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8515\n",
            "\n",
            "0: 384x640 2 persons, 64.7ms\n",
            "Speed: 10.4ms preprocess, 64.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8516\n",
            "\n",
            "0: 384x640 2 persons, 58.2ms\n",
            "Speed: 7.2ms preprocess, 58.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8517\n",
            "\n",
            "0: 384x640 2 persons, 93.7ms\n",
            "Speed: 8.0ms preprocess, 93.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8518\n",
            "\n",
            "0: 384x640 2 persons, 73.8ms\n",
            "Speed: 5.3ms preprocess, 73.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8519\n",
            "\n",
            "0: 384x640 2 persons, 59.9ms\n",
            "Speed: 28.2ms preprocess, 59.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8520\n",
            "\n",
            "0: 384x640 2 persons, 63.5ms\n",
            "Speed: 11.1ms preprocess, 63.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8521\n",
            "\n",
            "0: 384x640 2 persons, 81.8ms\n",
            "Speed: 6.9ms preprocess, 81.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_2: punching at frame 8522\n",
            "\n",
            "0: 384x640 2 persons, 64.3ms\n",
            "Speed: 25.5ms preprocess, 64.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 77.9ms\n",
            "Speed: 16.1ms preprocess, 77.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 68.2ms\n",
            "Speed: 16.2ms preprocess, 68.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.6ms\n",
            "Speed: 8.3ms preprocess, 62.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 75.8ms\n",
            "Speed: 19.5ms preprocess, 75.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 71.7ms\n",
            "Speed: 5.1ms preprocess, 71.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.6ms\n",
            "Speed: 12.2ms preprocess, 64.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.6ms\n",
            "Speed: 16.2ms preprocess, 59.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 102.6ms\n",
            "Speed: 18.0ms preprocess, 102.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.1ms\n",
            "Speed: 9.7ms preprocess, 63.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.8ms\n",
            "Speed: 6.0ms preprocess, 61.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.2ms\n",
            "Speed: 13.8ms preprocess, 60.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.2ms\n",
            "Speed: 7.0ms preprocess, 62.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.3ms\n",
            "Speed: 9.0ms preprocess, 62.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.7ms\n",
            "Speed: 10.3ms preprocess, 60.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 75.6ms\n",
            "Speed: 6.7ms preprocess, 75.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 70.0ms\n",
            "Speed: 6.0ms preprocess, 70.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 72.9ms\n",
            "Speed: 9.5ms preprocess, 72.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.1ms\n",
            "Speed: 8.5ms preprocess, 62.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.9ms\n",
            "Speed: 8.0ms preprocess, 65.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 68.4ms\n",
            "Speed: 8.4ms preprocess, 68.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.0ms\n",
            "Speed: 6.6ms preprocess, 66.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.0ms\n",
            "Speed: 8.7ms preprocess, 59.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.9ms\n",
            "Speed: 5.3ms preprocess, 60.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.8ms\n",
            "Speed: 26.5ms preprocess, 63.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.3ms\n",
            "Speed: 6.3ms preprocess, 60.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 80.7ms\n",
            "Speed: 7.1ms preprocess, 80.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 68.7ms\n",
            "Speed: 3.7ms preprocess, 68.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.7ms\n",
            "Speed: 9.9ms preprocess, 63.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 58.9ms\n",
            "Speed: 7.5ms preprocess, 58.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.4ms\n",
            "Speed: 7.6ms preprocess, 59.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.9ms\n",
            "Speed: 6.9ms preprocess, 62.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.3ms\n",
            "Speed: 10.0ms preprocess, 61.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.5ms\n",
            "Speed: 6.6ms preprocess, 64.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.7ms\n",
            "Speed: 10.9ms preprocess, 62.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.9ms\n",
            "Speed: 7.6ms preprocess, 60.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.8ms\n",
            "Speed: 6.0ms preprocess, 61.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.2ms\n",
            "Speed: 8.4ms preprocess, 60.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.7ms\n",
            "Speed: 9.4ms preprocess, 60.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.6ms\n",
            "Speed: 16.0ms preprocess, 59.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.2ms\n",
            "Speed: 8.8ms preprocess, 63.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 79.3ms\n",
            "Speed: 5.6ms preprocess, 79.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.4ms\n",
            "Speed: 7.2ms preprocess, 59.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.8ms\n",
            "Speed: 2.9ms preprocess, 64.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.9ms\n",
            "Speed: 7.0ms preprocess, 60.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 72.8ms\n",
            "Speed: 8.5ms preprocess, 72.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 80.8ms\n",
            "Speed: 8.1ms preprocess, 80.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.0ms\n",
            "Speed: 22.0ms preprocess, 60.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.8ms\n",
            "Speed: 21.1ms preprocess, 60.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 79.6ms\n",
            "Speed: 44.6ms preprocess, 79.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 68.6ms\n",
            "Speed: 40.5ms preprocess, 68.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 75.3ms\n",
            "Speed: 15.8ms preprocess, 75.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 82.0ms\n",
            "Speed: 6.3ms preprocess, 82.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 127.9ms\n",
            "Speed: 53.9ms preprocess, 127.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 81.7ms\n",
            "Speed: 15.5ms preprocess, 81.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 60.1ms\n",
            "Speed: 11.7ms preprocess, 60.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 73.2ms\n",
            "Speed: 10.4ms preprocess, 73.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 60.3ms\n",
            "Speed: 7.1ms preprocess, 60.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 60.1ms\n",
            "Speed: 6.4ms preprocess, 60.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 58.3ms\n",
            "Speed: 6.7ms preprocess, 58.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 59.1ms\n",
            "Speed: 8.1ms preprocess, 59.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 58.9ms\n",
            "Speed: 14.7ms preprocess, 58.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 61.9ms\n",
            "Speed: 42.4ms preprocess, 61.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 58.9ms\n",
            "Speed: 8.8ms preprocess, 58.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 61.5ms\n",
            "Speed: 6.4ms preprocess, 61.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 62.7ms\n",
            "Speed: 14.5ms preprocess, 62.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 64.9ms\n",
            "Speed: 7.5ms preprocess, 64.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 61.0ms\n",
            "Speed: 7.0ms preprocess, 61.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 60.2ms\n",
            "Speed: 7.3ms preprocess, 60.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 82.7ms\n",
            "Speed: 4.5ms preprocess, 82.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 65.9ms\n",
            "Speed: 4.4ms preprocess, 65.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 60.8ms\n",
            "Speed: 19.7ms preprocess, 60.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 69.8ms\n",
            "Speed: 7.8ms preprocess, 69.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 61.4ms\n",
            "Speed: 8.2ms preprocess, 61.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 66.4ms\n",
            "Speed: 4.9ms preprocess, 66.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 61.6ms\n",
            "Speed: 8.8ms preprocess, 61.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 59.7ms\n",
            "Speed: 8.2ms preprocess, 59.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 62.1ms\n",
            "Speed: 10.9ms preprocess, 62.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 69.5ms\n",
            "Speed: 3.4ms preprocess, 69.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 67.1ms\n",
            "Speed: 6.7ms preprocess, 67.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 60.3ms\n",
            "Speed: 11.3ms preprocess, 60.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 59.7ms\n",
            "Speed: 8.8ms preprocess, 59.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 62.4ms\n",
            "Speed: 8.3ms preprocess, 62.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 61.1ms\n",
            "Speed: 3.6ms preprocess, 61.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 62.3ms\n",
            "Speed: 2.8ms preprocess, 62.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 61.1ms\n",
            "Speed: 12.0ms preprocess, 61.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 66.4ms\n",
            "Speed: 5.2ms preprocess, 66.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 66.7ms\n",
            "Speed: 34.5ms preprocess, 66.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 71.3ms\n",
            "Speed: 15.8ms preprocess, 71.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 84.2ms\n",
            "Speed: 17.5ms preprocess, 84.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 64.2ms\n",
            "Speed: 12.2ms preprocess, 64.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 87.0ms\n",
            "Speed: 39.7ms preprocess, 87.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 62.2ms\n",
            "Speed: 12.8ms preprocess, 62.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 74.0ms\n",
            "Speed: 5.6ms preprocess, 74.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 72.7ms\n",
            "Speed: 9.2ms preprocess, 72.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 117.5ms\n",
            "Speed: 35.1ms preprocess, 117.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 68.6ms\n",
            "Speed: 7.1ms preprocess, 68.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 65.9ms\n",
            "Speed: 6.9ms preprocess, 65.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 64.4ms\n",
            "Speed: 10.1ms preprocess, 64.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 66.2ms\n",
            "Speed: 12.2ms preprocess, 66.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 71.8ms\n",
            "Speed: 12.5ms preprocess, 71.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.4ms\n",
            "Speed: 7.8ms preprocess, 61.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.4ms\n",
            "Speed: 6.8ms preprocess, 59.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 64.2ms\n",
            "Speed: 10.1ms preprocess, 64.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 65.0ms\n",
            "Speed: 6.8ms preprocess, 65.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 60.6ms\n",
            "Speed: 7.4ms preprocess, 60.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 75.7ms\n",
            "Speed: 5.9ms preprocess, 75.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 66.8ms\n",
            "Speed: 8.5ms preprocess, 66.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 64.4ms\n",
            "Speed: 9.5ms preprocess, 64.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 82.5ms\n",
            "Speed: 12.9ms preprocess, 82.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 66.7ms\n",
            "Speed: 8.7ms preprocess, 66.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 63.7ms\n",
            "Speed: 8.2ms preprocess, 63.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 61.5ms\n",
            "Speed: 7.5ms preprocess, 61.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 65.4ms\n",
            "Speed: 7.4ms preprocess, 65.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 59.9ms\n",
            "Speed: 3.1ms preprocess, 59.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 60.1ms\n",
            "Speed: 8.6ms preprocess, 60.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 66.1ms\n",
            "Speed: 9.7ms preprocess, 66.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 58.0ms\n",
            "Speed: 7.5ms preprocess, 58.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.4ms\n",
            "Speed: 10.3ms preprocess, 59.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 62.2ms\n",
            "Speed: 12.8ms preprocess, 62.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 60.6ms\n",
            "Speed: 11.6ms preprocess, 60.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 82.7ms\n",
            "Speed: 12.4ms preprocess, 82.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 59.9ms\n",
            "Speed: 6.4ms preprocess, 59.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 65.3ms\n",
            "Speed: 3.9ms preprocess, 65.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 64.3ms\n",
            "Speed: 28.2ms preprocess, 64.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 61.4ms\n",
            "Speed: 7.5ms preprocess, 61.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 65.7ms\n",
            "Speed: 6.8ms preprocess, 65.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 63.2ms\n",
            "Speed: 11.1ms preprocess, 63.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 99.0ms\n",
            "Speed: 45.7ms preprocess, 99.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 75.9ms\n",
            "Speed: 7.9ms preprocess, 75.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 65.9ms\n",
            "Speed: 19.9ms preprocess, 65.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 64.1ms\n",
            "Speed: 21.5ms preprocess, 64.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 88.5ms\n",
            "Speed: 27.7ms preprocess, 88.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.6ms\n",
            "Speed: 17.7ms preprocess, 65.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 67.2ms\n",
            "Speed: 7.5ms preprocess, 67.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 73.2ms\n",
            "Speed: 15.5ms preprocess, 73.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 70.8ms\n",
            "Speed: 7.0ms preprocess, 70.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 95.8ms\n",
            "Speed: 4.9ms preprocess, 95.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 62.5ms\n",
            "Speed: 20.6ms preprocess, 62.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 62.3ms\n",
            "Speed: 3.0ms preprocess, 62.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 61.1ms\n",
            "Speed: 7.0ms preprocess, 61.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 61.4ms\n",
            "Speed: 6.3ms preprocess, 61.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 64.9ms\n",
            "Speed: 4.8ms preprocess, 64.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 60.3ms\n",
            "Speed: 10.6ms preprocess, 60.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 62.0ms\n",
            "Speed: 6.2ms preprocess, 62.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 59.7ms\n",
            "Speed: 7.5ms preprocess, 59.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 60.3ms\n",
            "Speed: 5.4ms preprocess, 60.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 61.1ms\n",
            "Speed: 7.5ms preprocess, 61.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 64.8ms\n",
            "Speed: 8.4ms preprocess, 64.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 61.1ms\n",
            "Speed: 8.9ms preprocess, 61.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 62.5ms\n",
            "Speed: 8.1ms preprocess, 62.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 63.7ms\n",
            "Speed: 14.0ms preprocess, 63.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 63.6ms\n",
            "Speed: 4.3ms preprocess, 63.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 66.9ms\n",
            "Speed: 3.4ms preprocess, 66.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 59.5ms\n",
            "Speed: 7.3ms preprocess, 59.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 61.3ms\n",
            "Speed: 10.4ms preprocess, 61.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 60.3ms\n",
            "Speed: 7.8ms preprocess, 60.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 82.6ms\n",
            "Speed: 11.2ms preprocess, 82.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 61.4ms\n",
            "Speed: 8.9ms preprocess, 61.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 62.8ms\n",
            "Speed: 8.3ms preprocess, 62.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 60.0ms\n",
            "Speed: 7.9ms preprocess, 60.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 60.8ms\n",
            "Speed: 9.2ms preprocess, 60.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 66.2ms\n",
            "Speed: 10.0ms preprocess, 66.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 60.9ms\n",
            "Speed: 12.9ms preprocess, 60.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 60.6ms\n",
            "Speed: 18.3ms preprocess, 60.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 69.2ms\n",
            "Speed: 41.2ms preprocess, 69.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.8ms\n",
            "Speed: 6.3ms preprocess, 64.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 71.3ms\n",
            "Speed: 7.6ms preprocess, 71.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 78.4ms\n",
            "Speed: 4.9ms preprocess, 78.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 128.9ms\n",
            "Speed: 10.7ms preprocess, 128.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 74.6ms\n",
            "Speed: 12.1ms preprocess, 74.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 69.6ms\n",
            "Speed: 4.2ms preprocess, 69.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 60.6ms\n",
            "Speed: 17.2ms preprocess, 60.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 61.7ms\n",
            "Speed: 40.1ms preprocess, 61.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 69.0ms\n",
            "Speed: 13.0ms preprocess, 69.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 66.3ms\n",
            "Speed: 5.3ms preprocess, 66.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 59.9ms\n",
            "Speed: 6.4ms preprocess, 59.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 65.1ms\n",
            "Speed: 4.0ms preprocess, 65.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 66.3ms\n",
            "Speed: 10.0ms preprocess, 66.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.2ms\n",
            "Speed: 6.0ms preprocess, 63.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.3ms\n",
            "Speed: 13.0ms preprocess, 61.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 63.3ms\n",
            "Speed: 11.0ms preprocess, 63.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.2ms\n",
            "Speed: 5.1ms preprocess, 65.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.7ms\n",
            "Speed: 7.4ms preprocess, 62.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.6ms\n",
            "Speed: 7.8ms preprocess, 60.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.5ms\n",
            "Speed: 9.6ms preprocess, 66.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.2ms\n",
            "Speed: 7.3ms preprocess, 64.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.8ms\n",
            "Speed: 7.1ms preprocess, 62.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.2ms\n",
            "Speed: 8.3ms preprocess, 64.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.8ms\n",
            "Speed: 17.0ms preprocess, 59.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.1ms\n",
            "Speed: 5.2ms preprocess, 65.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.6ms\n",
            "Speed: 11.7ms preprocess, 62.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.5ms\n",
            "Speed: 13.5ms preprocess, 62.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.4ms\n",
            "Speed: 7.8ms preprocess, 66.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.6ms\n",
            "Speed: 16.0ms preprocess, 66.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.7ms\n",
            "Speed: 18.1ms preprocess, 60.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.7ms\n",
            "Speed: 8.8ms preprocess, 62.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.5ms\n",
            "Speed: 5.7ms preprocess, 60.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.6ms\n",
            "Speed: 9.1ms preprocess, 65.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.5ms\n",
            "Speed: 8.5ms preprocess, 60.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.6ms\n",
            "Speed: 7.0ms preprocess, 60.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 58.9ms\n",
            "Speed: 7.5ms preprocess, 58.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.2ms\n",
            "Speed: 8.2ms preprocess, 65.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.0ms\n",
            "Speed: 17.2ms preprocess, 63.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 69.5ms\n",
            "Speed: 6.2ms preprocess, 69.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.8ms\n",
            "Speed: 7.8ms preprocess, 60.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.7ms\n",
            "Speed: 9.0ms preprocess, 60.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.5ms\n",
            "Speed: 17.3ms preprocess, 61.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.0ms\n",
            "Speed: 12.4ms preprocess, 64.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.0ms\n",
            "Speed: 10.0ms preprocess, 63.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.3ms\n",
            "Speed: 10.7ms preprocess, 62.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 80.5ms\n",
            "Speed: 50.4ms preprocess, 80.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.9ms\n",
            "Speed: 4.9ms preprocess, 61.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 77.6ms\n",
            "Speed: 6.9ms preprocess, 77.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 74.5ms\n",
            "Speed: 4.6ms preprocess, 74.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 84.8ms\n",
            "Speed: 51.0ms preprocess, 84.8ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.3ms\n",
            "Speed: 25.9ms preprocess, 60.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 71.9ms\n",
            "Speed: 14.0ms preprocess, 71.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 74.7ms\n",
            "Speed: 6.3ms preprocess, 74.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 74.4ms\n",
            "Speed: 8.4ms preprocess, 74.4ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.2ms\n",
            "Speed: 15.4ms preprocess, 62.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 73.2ms\n",
            "Speed: 13.4ms preprocess, 73.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 80.5ms\n",
            "Speed: 18.4ms preprocess, 80.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.1ms\n",
            "Speed: 15.1ms preprocess, 64.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.6ms\n",
            "Speed: 8.1ms preprocess, 63.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.1ms\n",
            "Speed: 7.2ms preprocess, 61.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.8ms\n",
            "Speed: 5.8ms preprocess, 62.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.5ms\n",
            "Speed: 9.3ms preprocess, 59.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.9ms\n",
            "Speed: 5.7ms preprocess, 60.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.8ms\n",
            "Speed: 8.8ms preprocess, 60.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 73.0ms\n",
            "Speed: 7.7ms preprocess, 73.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.9ms\n",
            "Speed: 5.2ms preprocess, 59.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.9ms\n",
            "Speed: 17.5ms preprocess, 59.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.1ms\n",
            "Speed: 9.2ms preprocess, 65.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.7ms\n",
            "Speed: 5.5ms preprocess, 64.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.3ms\n",
            "Speed: 6.6ms preprocess, 61.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.9ms\n",
            "Speed: 11.3ms preprocess, 60.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.0ms\n",
            "Speed: 11.5ms preprocess, 60.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.1ms\n",
            "Speed: 10.8ms preprocess, 61.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.6ms\n",
            "Speed: 12.9ms preprocess, 60.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.2ms\n",
            "Speed: 15.3ms preprocess, 64.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 71.4ms\n",
            "Speed: 15.7ms preprocess, 71.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.6ms\n",
            "Speed: 6.5ms preprocess, 62.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.7ms\n",
            "Speed: 3.7ms preprocess, 64.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.5ms\n",
            "Speed: 5.4ms preprocess, 60.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 74.8ms\n",
            "Speed: 7.9ms preprocess, 74.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.5ms\n",
            "Speed: 4.9ms preprocess, 61.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.0ms\n",
            "Speed: 6.0ms preprocess, 64.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.5ms\n",
            "Speed: 21.5ms preprocess, 59.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 72.5ms\n",
            "Speed: 6.6ms preprocess, 72.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.1ms\n",
            "Speed: 6.0ms preprocess, 63.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.9ms\n",
            "Speed: 9.6ms preprocess, 66.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.9ms\n",
            "Speed: 10.5ms preprocess, 59.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.7ms\n",
            "Speed: 8.3ms preprocess, 59.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.4ms\n",
            "Speed: 2.9ms preprocess, 60.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.2ms\n",
            "Speed: 9.2ms preprocess, 60.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.4ms\n",
            "Speed: 8.5ms preprocess, 61.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 70.2ms\n",
            "Speed: 2.7ms preprocess, 70.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.2ms\n",
            "Speed: 6.6ms preprocess, 62.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.9ms\n",
            "Speed: 6.7ms preprocess, 65.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 88.2ms\n",
            "Speed: 6.1ms preprocess, 88.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 72.0ms\n",
            "Speed: 12.4ms preprocess, 72.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.3ms\n",
            "Speed: 23.1ms preprocess, 60.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 67.7ms\n",
            "Speed: 9.5ms preprocess, 67.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 82.0ms\n",
            "Speed: 20.6ms preprocess, 82.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 70.2ms\n",
            "Speed: 24.7ms preprocess, 70.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 74.8ms\n",
            "Speed: 5.0ms preprocess, 74.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 74.9ms\n",
            "Speed: 6.3ms preprocess, 74.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 78.7ms\n",
            "Speed: 14.0ms preprocess, 78.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 100.8ms\n",
            "Speed: 8.7ms preprocess, 100.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.1ms\n",
            "Speed: 29.9ms preprocess, 61.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.6ms\n",
            "Speed: 18.9ms preprocess, 61.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 71.9ms\n",
            "Speed: 19.2ms preprocess, 71.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 68.7ms\n",
            "Speed: 9.8ms preprocess, 68.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.4ms\n",
            "Speed: 12.5ms preprocess, 65.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.2ms\n",
            "Speed: 9.4ms preprocess, 62.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 67.1ms\n",
            "Speed: 9.1ms preprocess, 67.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 58.7ms\n",
            "Speed: 8.9ms preprocess, 58.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.2ms\n",
            "Speed: 14.3ms preprocess, 63.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.6ms\n",
            "Speed: 16.8ms preprocess, 66.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.1ms\n",
            "Speed: 6.0ms preprocess, 65.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.2ms\n",
            "Speed: 9.4ms preprocess, 60.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.5ms\n",
            "Speed: 9.7ms preprocess, 62.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.9ms\n",
            "Speed: 15.1ms preprocess, 63.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 74.9ms\n",
            "Speed: 2.6ms preprocess, 74.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.3ms\n",
            "Speed: 6.9ms preprocess, 66.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.8ms\n",
            "Speed: 3.7ms preprocess, 65.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.7ms\n",
            "Speed: 5.7ms preprocess, 59.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 68.4ms\n",
            "Speed: 5.7ms preprocess, 68.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.0ms\n",
            "Speed: 18.1ms preprocess, 62.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.3ms\n",
            "Speed: 7.7ms preprocess, 62.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.5ms\n",
            "Speed: 8.3ms preprocess, 66.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 58.7ms\n",
            "Speed: 3.5ms preprocess, 58.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 56.5ms\n",
            "Speed: 9.2ms preprocess, 56.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.0ms\n",
            "Speed: 6.9ms preprocess, 62.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.9ms\n",
            "Speed: 4.2ms preprocess, 59.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.2ms\n",
            "Speed: 10.5ms preprocess, 60.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.5ms\n",
            "Speed: 8.5ms preprocess, 59.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.1ms\n",
            "Speed: 9.5ms preprocess, 61.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 57.0ms\n",
            "Speed: 8.5ms preprocess, 57.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.4ms\n",
            "Speed: 6.3ms preprocess, 64.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.7ms\n",
            "Speed: 10.0ms preprocess, 60.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.1ms\n",
            "Speed: 7.2ms preprocess, 60.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 78.2ms\n",
            "Speed: 4.6ms preprocess, 78.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 68.4ms\n",
            "Speed: 8.2ms preprocess, 68.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.0ms\n",
            "Speed: 20.9ms preprocess, 60.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.1ms\n",
            "Speed: 6.5ms preprocess, 63.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.9ms\n",
            "Speed: 6.1ms preprocess, 66.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.3ms\n",
            "Speed: 5.6ms preprocess, 62.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.1ms\n",
            "Speed: 7.7ms preprocess, 63.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 80.1ms\n",
            "Speed: 6.8ms preprocess, 80.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 72.5ms\n",
            "Speed: 33.8ms preprocess, 72.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.6ms\n",
            "Speed: 16.6ms preprocess, 63.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 69.6ms\n",
            "Speed: 11.6ms preprocess, 69.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 174.8ms\n",
            "Speed: 42.2ms preprocess, 174.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.2ms\n",
            "Speed: 23.9ms preprocess, 64.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 69.7ms\n",
            "Speed: 10.1ms preprocess, 69.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.2ms\n",
            "Speed: 22.3ms preprocess, 64.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.5ms\n",
            "Speed: 10.2ms preprocess, 64.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 70.8ms\n",
            "Speed: 31.3ms preprocess, 70.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 107.5ms\n",
            "Speed: 34.6ms preprocess, 107.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 71.8ms\n",
            "Speed: 6.2ms preprocess, 71.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.9ms\n",
            "Speed: 5.1ms preprocess, 65.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 77.1ms\n",
            "Speed: 11.0ms preprocess, 77.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.9ms\n",
            "Speed: 7.5ms preprocess, 61.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.8ms\n",
            "Speed: 13.5ms preprocess, 64.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.6ms\n",
            "Speed: 5.9ms preprocess, 64.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.8ms\n",
            "Speed: 16.1ms preprocess, 66.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.2ms\n",
            "Speed: 6.3ms preprocess, 60.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.6ms\n",
            "Speed: 14.4ms preprocess, 62.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.2ms\n",
            "Speed: 14.4ms preprocess, 64.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.8ms\n",
            "Speed: 10.2ms preprocess, 60.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.1ms\n",
            "Speed: 6.6ms preprocess, 66.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.7ms\n",
            "Speed: 3.6ms preprocess, 63.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 78.0ms\n",
            "Speed: 3.8ms preprocess, 78.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.5ms\n",
            "Speed: 9.7ms preprocess, 62.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.6ms\n",
            "Speed: 7.9ms preprocess, 62.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.6ms\n",
            "Speed: 3.7ms preprocess, 61.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.7ms\n",
            "Speed: 11.7ms preprocess, 65.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.9ms\n",
            "Speed: 3.3ms preprocess, 61.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.3ms\n",
            "Speed: 7.6ms preprocess, 61.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 70.9ms\n",
            "Speed: 6.9ms preprocess, 70.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.6ms\n",
            "Speed: 3.7ms preprocess, 65.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.2ms\n",
            "Speed: 8.3ms preprocess, 60.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.1ms\n",
            "Speed: 7.5ms preprocess, 61.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 71.3ms\n",
            "Speed: 13.2ms preprocess, 71.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.4ms\n",
            "Speed: 5.9ms preprocess, 60.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 58.2ms\n",
            "Speed: 10.3ms preprocess, 58.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.9ms\n",
            "Speed: 7.1ms preprocess, 66.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 58.3ms\n",
            "Speed: 17.3ms preprocess, 58.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 58.0ms\n",
            "Speed: 7.0ms preprocess, 58.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.6ms\n",
            "Speed: 9.6ms preprocess, 66.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.5ms\n",
            "Speed: 3.3ms preprocess, 62.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.0ms\n",
            "Speed: 3.9ms preprocess, 59.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 67.3ms\n",
            "Speed: 9.5ms preprocess, 67.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.3ms\n",
            "Speed: 8.0ms preprocess, 61.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.5ms\n",
            "Speed: 11.6ms preprocess, 63.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.8ms\n",
            "Speed: 6.9ms preprocess, 64.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.0ms\n",
            "Speed: 6.5ms preprocess, 64.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 86.0ms\n",
            "Speed: 3.4ms preprocess, 86.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 89.0ms\n",
            "Speed: 45.5ms preprocess, 89.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 70.6ms\n",
            "Speed: 8.4ms preprocess, 70.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 71.5ms\n",
            "Speed: 10.5ms preprocess, 71.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 89.5ms\n",
            "Speed: 14.8ms preprocess, 89.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 98.2ms\n",
            "Speed: 41.0ms preprocess, 98.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.9ms\n",
            "Speed: 20.3ms preprocess, 62.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 84.9ms\n",
            "Speed: 6.7ms preprocess, 84.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 67.3ms\n",
            "Speed: 23.3ms preprocess, 67.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 93.0ms\n",
            "Speed: 7.1ms preprocess, 93.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.9ms\n",
            "Speed: 24.6ms preprocess, 61.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 85.6ms\n",
            "Speed: 27.6ms preprocess, 85.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 76.9ms\n",
            "Speed: 6.8ms preprocess, 76.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.8ms\n",
            "Speed: 7.7ms preprocess, 61.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.7ms\n",
            "Speed: 19.5ms preprocess, 60.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.3ms\n",
            "Speed: 6.0ms preprocess, 62.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 67.9ms\n",
            "Speed: 3.6ms preprocess, 67.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.3ms\n",
            "Speed: 7.1ms preprocess, 62.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.2ms\n",
            "Speed: 7.9ms preprocess, 65.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.7ms\n",
            "Speed: 11.7ms preprocess, 59.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.0ms\n",
            "Speed: 7.5ms preprocess, 62.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 67.5ms\n",
            "Speed: 13.6ms preprocess, 67.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.9ms\n",
            "Speed: 7.2ms preprocess, 61.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.3ms\n",
            "Speed: 13.6ms preprocess, 61.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.0ms\n",
            "Speed: 11.9ms preprocess, 63.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.3ms\n",
            "Speed: 4.5ms preprocess, 62.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.8ms\n",
            "Speed: 17.8ms preprocess, 62.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.5ms\n",
            "Speed: 14.4ms preprocess, 63.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.4ms\n",
            "Speed: 9.1ms preprocess, 63.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 68.0ms\n",
            "Speed: 5.7ms preprocess, 68.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 71.7ms\n",
            "Speed: 9.1ms preprocess, 71.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.8ms\n",
            "Speed: 10.1ms preprocess, 60.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.4ms\n",
            "Speed: 7.1ms preprocess, 61.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.8ms\n",
            "Speed: 13.5ms preprocess, 59.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 88.5ms\n",
            "Speed: 6.9ms preprocess, 88.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.6ms\n",
            "Speed: 7.1ms preprocess, 65.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.9ms\n",
            "Speed: 4.2ms preprocess, 65.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.1ms\n",
            "Speed: 5.8ms preprocess, 63.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 75.0ms\n",
            "Speed: 5.7ms preprocess, 75.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 57.7ms\n",
            "Speed: 11.6ms preprocess, 57.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.2ms\n",
            "Speed: 8.5ms preprocess, 61.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.2ms\n",
            "Speed: 4.7ms preprocess, 66.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.0ms\n",
            "Speed: 5.5ms preprocess, 64.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.3ms\n",
            "Speed: 7.1ms preprocess, 61.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.3ms\n",
            "Speed: 3.8ms preprocess, 60.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.1ms\n",
            "Speed: 13.1ms preprocess, 62.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.6ms\n",
            "Speed: 11.3ms preprocess, 59.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 67.7ms\n",
            "Speed: 7.6ms preprocess, 67.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.6ms\n",
            "Speed: 8.5ms preprocess, 64.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.3ms\n",
            "Speed: 9.0ms preprocess, 60.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 70.9ms\n",
            "Speed: 7.7ms preprocess, 70.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.8ms\n",
            "Speed: 39.0ms preprocess, 61.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.2ms\n",
            "Speed: 17.5ms preprocess, 66.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.9ms\n",
            "Speed: 14.5ms preprocess, 64.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 79.3ms\n",
            "Speed: 8.5ms preprocess, 79.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 82.6ms\n",
            "Speed: 41.9ms preprocess, 82.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 91.0ms\n",
            "Speed: 13.6ms preprocess, 91.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 72.6ms\n",
            "Speed: 20.0ms preprocess, 72.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 88.7ms\n",
            "Speed: 4.3ms preprocess, 88.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 84.4ms\n",
            "Speed: 30.7ms preprocess, 84.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 75.9ms\n",
            "Speed: 22.3ms preprocess, 75.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 74.0ms\n",
            "Speed: 21.7ms preprocess, 74.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.5ms\n",
            "Speed: 7.7ms preprocess, 62.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 68.4ms\n",
            "Speed: 4.7ms preprocess, 68.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.8ms\n",
            "Speed: 10.8ms preprocess, 64.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.2ms\n",
            "Speed: 16.5ms preprocess, 66.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.6ms\n",
            "Speed: 10.0ms preprocess, 65.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.1ms\n",
            "Speed: 7.9ms preprocess, 66.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 86.9ms\n",
            "Speed: 7.1ms preprocess, 86.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 67.2ms\n",
            "Speed: 3.7ms preprocess, 67.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 58.7ms\n",
            "Speed: 8.9ms preprocess, 58.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 77.3ms\n",
            "Speed: 3.0ms preprocess, 77.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.8ms\n",
            "Speed: 8.1ms preprocess, 64.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.5ms\n",
            "Speed: 2.8ms preprocess, 61.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.3ms\n",
            "Speed: 9.7ms preprocess, 66.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 58.9ms\n",
            "Speed: 18.1ms preprocess, 58.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.8ms\n",
            "Speed: 8.6ms preprocess, 63.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.2ms\n",
            "Speed: 11.4ms preprocess, 60.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.4ms\n",
            "Speed: 5.8ms preprocess, 62.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.7ms\n",
            "Speed: 8.7ms preprocess, 63.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.7ms\n",
            "Speed: 8.8ms preprocess, 62.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.9ms\n",
            "Speed: 2.8ms preprocess, 62.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 69.4ms\n",
            "Speed: 11.2ms preprocess, 69.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.3ms\n",
            "Speed: 7.9ms preprocess, 61.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.5ms\n",
            "Speed: 7.9ms preprocess, 60.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.6ms\n",
            "Speed: 8.3ms preprocess, 61.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.0ms\n",
            "Speed: 8.1ms preprocess, 59.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.6ms\n",
            "Speed: 9.2ms preprocess, 64.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 70.4ms\n",
            "Speed: 39.1ms preprocess, 70.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.8ms\n",
            "Speed: 7.2ms preprocess, 62.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.4ms\n",
            "Speed: 4.7ms preprocess, 60.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.7ms\n",
            "Speed: 11.4ms preprocess, 65.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.7ms\n",
            "Speed: 23.5ms preprocess, 60.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 69.8ms\n",
            "Speed: 7.6ms preprocess, 69.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.6ms\n",
            "Speed: 4.9ms preprocess, 63.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 56.4ms\n",
            "Speed: 17.7ms preprocess, 56.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.8ms\n",
            "Speed: 8.0ms preprocess, 66.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 71.5ms\n",
            "Speed: 7.0ms preprocess, 71.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 68.8ms\n",
            "Speed: 15.4ms preprocess, 68.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.8ms\n",
            "Speed: 11.7ms preprocess, 61.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 153.0ms\n",
            "Speed: 54.7ms preprocess, 153.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.3ms\n",
            "Speed: 11.0ms preprocess, 63.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.4ms\n",
            "Speed: 14.9ms preprocess, 64.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.0ms\n",
            "Speed: 12.1ms preprocess, 64.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.1ms\n",
            "Speed: 13.3ms preprocess, 63.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.9ms\n",
            "Speed: 37.8ms preprocess, 61.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.5ms\n",
            "Speed: 11.0ms preprocess, 65.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 87.5ms\n",
            "Speed: 3.4ms preprocess, 87.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.1ms\n",
            "Speed: 10.6ms preprocess, 61.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 79.3ms\n",
            "Speed: 10.8ms preprocess, 79.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.6ms\n",
            "Speed: 17.2ms preprocess, 61.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.5ms\n",
            "Speed: 5.8ms preprocess, 65.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 66.5ms\n",
            "Speed: 3.1ms preprocess, 66.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.9ms\n",
            "Speed: 3.2ms preprocess, 62.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.5ms\n",
            "Speed: 2.8ms preprocess, 65.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.0ms\n",
            "Speed: 2.9ms preprocess, 63.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.9ms\n",
            "Speed: 2.8ms preprocess, 63.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 67.0ms\n",
            "Speed: 3.9ms preprocess, 67.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.1ms\n",
            "Speed: 3.7ms preprocess, 62.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 62.6ms\n",
            "Speed: 3.1ms preprocess, 62.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Parsed Actions: {'person_1': {'punching': [(912, 1066), (1648, 1710), (2594, 2651), (3278, 3324), (3845, 3913), (4420, 4481), (4835, 4930), (5006, 5076), (5883, 5929), (7058, 7113), (7856, 7910), (8015, 8055), (8147, 8197)], 'threaten': [(1385, 1435)], 'pulling': [(2271, 2446), (7448, 7579)]}, 'person_2': {'punching': [(6240, 6361), (6548, 6638), (8640, 8819)], 'piercing': [(6944, 6989)], 'kicking': [(7565, 7623)]}, 'person_3': {'falldown': [(6273, 6308), (8739, 8791)]}}\n",
            "\n",
            "0: 384x640 3 persons, 69.6ms\n",
            "Speed: 9.9ms preprocess, 69.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 92.6ms\n",
            "Speed: 50.4ms preprocess, 92.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 82.2ms\n",
            "Speed: 5.8ms preprocess, 82.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 104.1ms\n",
            "Speed: 7.4ms preprocess, 104.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 83.7ms\n",
            "Speed: 4.2ms preprocess, 83.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 71.7ms\n",
            "Speed: 44.4ms preprocess, 71.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 88.9ms\n",
            "Speed: 39.5ms preprocess, 88.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 105.0ms\n",
            "Speed: 8.1ms preprocess, 105.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 101.8ms\n",
            "Speed: 3.7ms preprocess, 101.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 100.0ms\n",
            "Speed: 27.8ms preprocess, 100.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 181.1ms\n",
            "Speed: 41.9ms preprocess, 181.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 65.4ms\n",
            "Speed: 48.8ms preprocess, 65.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 126.0ms\n",
            "Speed: 4.6ms preprocess, 126.0ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 102.7ms\n",
            "Speed: 8.2ms preprocess, 102.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 93.5ms\n",
            "Speed: 6.0ms preprocess, 93.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 146.6ms\n",
            "Speed: 23.5ms preprocess, 146.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 137.0ms\n",
            "Speed: 7.9ms preprocess, 137.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 67.5ms\n",
            "Speed: 7.8ms preprocess, 67.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 75.0ms\n",
            "Speed: 10.6ms preprocess, 75.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 62.4ms\n",
            "Speed: 14.8ms preprocess, 62.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 90.5ms\n",
            "Speed: 7.7ms preprocess, 90.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.5ms\n",
            "Speed: 10.6ms preprocess, 61.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 88.7ms\n",
            "Speed: 3.0ms preprocess, 88.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 72.6ms\n",
            "Speed: 4.3ms preprocess, 72.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 62.2ms\n",
            "Speed: 5.4ms preprocess, 62.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 105.7ms\n",
            "Speed: 8.7ms preprocess, 105.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 85.3ms\n",
            "Speed: 8.7ms preprocess, 85.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 76.2ms\n",
            "Speed: 29.9ms preprocess, 76.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 78.6ms\n",
            "Speed: 6.7ms preprocess, 78.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 60.7ms\n",
            "Speed: 11.0ms preprocess, 60.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 60.0ms\n",
            "Speed: 8.1ms preprocess, 60.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 71.0ms\n",
            "Speed: 7.2ms preprocess, 71.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 77.4ms\n",
            "Speed: 15.4ms preprocess, 77.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.1ms\n",
            "Speed: 11.2ms preprocess, 66.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 80.2ms\n",
            "Speed: 3.2ms preprocess, 80.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.4ms\n",
            "Speed: 8.7ms preprocess, 66.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 74.7ms\n",
            "Speed: 8.5ms preprocess, 74.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 93.5ms\n",
            "Speed: 10.2ms preprocess, 93.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.7ms\n",
            "Speed: 28.6ms preprocess, 60.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 68.9ms\n",
            "Speed: 7.5ms preprocess, 68.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.4ms\n",
            "Speed: 7.2ms preprocess, 61.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 72.1ms\n",
            "Speed: 3.6ms preprocess, 72.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 67.1ms\n",
            "Speed: 5.4ms preprocess, 67.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 71.4ms\n",
            "Speed: 13.8ms preprocess, 71.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 156.1ms\n",
            "Speed: 16.2ms preprocess, 156.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 182.3ms\n",
            "Speed: 30.2ms preprocess, 182.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 67.2ms\n",
            "Speed: 12.4ms preprocess, 67.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 101.7ms\n",
            "Speed: 6.6ms preprocess, 101.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 76.3ms\n",
            "Speed: 6.6ms preprocess, 76.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 122.1ms\n",
            "Speed: 13.8ms preprocess, 122.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 193.1ms\n",
            "Speed: 4.0ms preprocess, 193.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 176.0ms\n",
            "Speed: 37.7ms preprocess, 176.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 58.7ms\n",
            "Speed: 8.9ms preprocess, 58.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 77.6ms\n",
            "Speed: 8.9ms preprocess, 77.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 118.9ms\n",
            "Speed: 9.9ms preprocess, 118.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 87.0ms\n",
            "Speed: 7.8ms preprocess, 87.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.9ms\n",
            "Speed: 25.0ms preprocess, 59.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 78.6ms\n",
            "Speed: 12.0ms preprocess, 78.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.5ms\n",
            "Speed: 9.0ms preprocess, 61.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.8ms\n",
            "Speed: 6.9ms preprocess, 61.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 76.1ms\n",
            "Speed: 15.9ms preprocess, 76.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 66.2ms\n",
            "Speed: 5.5ms preprocess, 66.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 81.1ms\n",
            "Speed: 3.6ms preprocess, 81.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 94.4ms\n",
            "Speed: 9.0ms preprocess, 94.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 71.0ms\n",
            "Speed: 6.3ms preprocess, 71.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 60.3ms\n",
            "Speed: 6.2ms preprocess, 60.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 64.7ms\n",
            "Speed: 19.6ms preprocess, 64.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 62.1ms\n",
            "Speed: 23.4ms preprocess, 62.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 85.3ms\n",
            "Speed: 6.6ms preprocess, 85.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 72.2ms\n",
            "Speed: 37.3ms preprocess, 72.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 59.6ms\n",
            "Speed: 16.5ms preprocess, 59.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 77.5ms\n",
            "Speed: 7.1ms preprocess, 77.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 70.3ms\n",
            "Speed: 16.2ms preprocess, 70.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 71.6ms\n",
            "Speed: 28.2ms preprocess, 71.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 78.1ms\n",
            "Speed: 2.9ms preprocess, 78.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 61.4ms\n",
            "Speed: 6.6ms preprocess, 61.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 73.2ms\n",
            "Speed: 4.1ms preprocess, 73.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 64.1ms\n",
            "Speed: 15.4ms preprocess, 64.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 86.5ms\n",
            "Speed: 50.1ms preprocess, 86.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 67.9ms\n",
            "Speed: 34.1ms preprocess, 67.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 136.6ms\n",
            "Speed: 51.8ms preprocess, 136.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 60.3ms\n",
            "Speed: 13.9ms preprocess, 60.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 62.1ms\n",
            "Speed: 17.1ms preprocess, 62.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 106.4ms\n",
            "Speed: 18.5ms preprocess, 106.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 72.1ms\n",
            "Speed: 18.9ms preprocess, 72.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 74.9ms\n",
            "Speed: 6.5ms preprocess, 74.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 125.4ms\n",
            "Speed: 8.6ms preprocess, 125.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 60.6ms\n",
            "Speed: 5.9ms preprocess, 60.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 64.6ms\n",
            "Speed: 45.4ms preprocess, 64.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 83.0ms\n",
            "Speed: 10.3ms preprocess, 83.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 73.8ms\n",
            "Speed: 8.3ms preprocess, 73.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 69.8ms\n",
            "Speed: 8.4ms preprocess, 69.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 91.4ms\n",
            "Speed: 6.8ms preprocess, 91.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 69.6ms\n",
            "Speed: 7.9ms preprocess, 69.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 86.7ms\n",
            "Speed: 7.4ms preprocess, 86.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 85.9ms\n",
            "Speed: 7.4ms preprocess, 85.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 60.4ms\n",
            "Speed: 27.6ms preprocess, 60.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 60.0ms\n",
            "Speed: 6.8ms preprocess, 60.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 58.3ms\n",
            "Speed: 8.6ms preprocess, 58.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 58.5ms\n",
            "Speed: 27.0ms preprocess, 58.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 75.6ms\n",
            "Speed: 6.3ms preprocess, 75.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 62.6ms\n",
            "Speed: 15.6ms preprocess, 62.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 75.1ms\n",
            "Speed: 14.3ms preprocess, 75.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 74.2ms\n",
            "Speed: 6.5ms preprocess, 74.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 67.2ms\n",
            "Speed: 3.1ms preprocess, 67.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 58.9ms\n",
            "Speed: 26.5ms preprocess, 58.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 78.7ms\n",
            "Speed: 7.6ms preprocess, 78.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 105.7ms\n",
            "Speed: 38.4ms preprocess, 105.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 74.2ms\n",
            "Speed: 19.1ms preprocess, 74.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 115.3ms\n",
            "Speed: 6.5ms preprocess, 115.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 60.9ms\n",
            "Speed: 26.5ms preprocess, 60.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 72.0ms\n",
            "Speed: 19.3ms preprocess, 72.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 113.8ms\n",
            "Speed: 21.1ms preprocess, 113.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 159.2ms\n",
            "Speed: 4.7ms preprocess, 159.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 77.2ms\n",
            "Speed: 9.5ms preprocess, 77.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 73.9ms\n",
            "Speed: 20.4ms preprocess, 73.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 59.5ms\n",
            "Speed: 6.4ms preprocess, 59.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 57.3ms\n",
            "Speed: 17.2ms preprocess, 57.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 79.7ms\n",
            "Speed: 7.0ms preprocess, 79.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 65.2ms\n",
            "Speed: 9.5ms preprocess, 65.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 62.4ms\n",
            "Speed: 10.9ms preprocess, 62.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 92.1ms\n",
            "Speed: 19.4ms preprocess, 92.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 59.6ms\n",
            "Speed: 5.9ms preprocess, 59.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 78.2ms\n",
            "Speed: 6.6ms preprocess, 78.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 86.9ms\n",
            "Speed: 11.9ms preprocess, 86.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 61.6ms\n",
            "Speed: 29.2ms preprocess, 61.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 77.7ms\n",
            "Speed: 7.0ms preprocess, 77.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 72.5ms\n",
            "Speed: 10.3ms preprocess, 72.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 66.7ms\n",
            "Speed: 18.1ms preprocess, 66.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 73.8ms\n",
            "Speed: 3.9ms preprocess, 73.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 71.2ms\n",
            "Speed: 7.3ms preprocess, 71.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 88.2ms\n",
            "Speed: 5.0ms preprocess, 88.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 79.1ms\n",
            "Speed: 17.7ms preprocess, 79.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 80.3ms\n",
            "Speed: 6.2ms preprocess, 80.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 68.2ms\n",
            "Speed: 14.0ms preprocess, 68.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 65.1ms\n",
            "Speed: 17.3ms preprocess, 65.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 90.6ms\n",
            "Speed: 9.1ms preprocess, 90.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 70.1ms\n",
            "Speed: 10.1ms preprocess, 70.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 129.5ms\n",
            "Speed: 6.0ms preprocess, 129.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 59.9ms\n",
            "Speed: 16.7ms preprocess, 59.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 80.2ms\n",
            "Speed: 12.3ms preprocess, 80.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 106.1ms\n",
            "Speed: 26.0ms preprocess, 106.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 68.6ms\n",
            "Speed: 50.9ms preprocess, 68.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 98.5ms\n",
            "Speed: 11.9ms preprocess, 98.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 153.0ms\n",
            "Speed: 54.3ms preprocess, 153.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 60.1ms\n",
            "Speed: 7.8ms preprocess, 60.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 75.0ms\n",
            "Speed: 7.2ms preprocess, 75.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 84.5ms\n",
            "Speed: 6.8ms preprocess, 84.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 57.8ms\n",
            "Speed: 23.4ms preprocess, 57.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 65.9ms\n",
            "Speed: 8.8ms preprocess, 65.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 101.2ms\n",
            "Speed: 4.1ms preprocess, 101.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 59.6ms\n",
            "Speed: 9.8ms preprocess, 59.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 82.1ms\n",
            "Speed: 9.6ms preprocess, 82.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 86.8ms\n",
            "Speed: 8.9ms preprocess, 86.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 60.3ms\n",
            "Speed: 28.0ms preprocess, 60.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 72.5ms\n",
            "Speed: 8.5ms preprocess, 72.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 58.5ms\n",
            "Speed: 7.6ms preprocess, 58.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.9ms\n",
            "Speed: 8.4ms preprocess, 66.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 80.0ms\n",
            "Speed: 3.6ms preprocess, 80.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.2ms\n",
            "Speed: 27.3ms preprocess, 63.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 84.6ms\n",
            "Speed: 4.3ms preprocess, 84.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 90.7ms\n",
            "Speed: 6.6ms preprocess, 90.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 64.1ms\n",
            "Speed: 8.7ms preprocess, 64.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 59.2ms\n",
            "Speed: 12.0ms preprocess, 59.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 62.8ms\n",
            "Speed: 22.3ms preprocess, 62.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 69.4ms\n",
            "Speed: 17.6ms preprocess, 69.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 76.4ms\n",
            "Speed: 10.8ms preprocess, 76.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 112.8ms\n",
            "Speed: 17.0ms preprocess, 112.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.9ms\n",
            "Speed: 5.9ms preprocess, 62.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.7ms\n",
            "Speed: 7.6ms preprocess, 59.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 94.3ms\n",
            "Speed: 7.4ms preprocess, 94.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 79.6ms\n",
            "Speed: 44.6ms preprocess, 79.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 96.5ms\n",
            "Speed: 9.7ms preprocess, 96.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 119.0ms\n",
            "Speed: 24.9ms preprocess, 119.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 77.0ms\n",
            "Speed: 13.2ms preprocess, 77.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 78.2ms\n",
            "Speed: 42.1ms preprocess, 78.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 102.1ms\n",
            "Speed: 5.9ms preprocess, 102.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 102.9ms\n",
            "Speed: 30.7ms preprocess, 102.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 72.9ms\n",
            "Speed: 28.7ms preprocess, 72.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 80.5ms\n",
            "Speed: 7.5ms preprocess, 80.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 76.3ms\n",
            "Speed: 15.0ms preprocess, 76.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 76.0ms\n",
            "Speed: 7.2ms preprocess, 76.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 72.1ms\n",
            "Speed: 9.2ms preprocess, 72.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.2ms\n",
            "Speed: 30.3ms preprocess, 65.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 912\n",
            "\n",
            "0: 384x640 3 persons, 60.5ms\n",
            "Speed: 6.8ms preprocess, 60.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 913\n",
            "\n",
            "0: 384x640 3 persons, 59.9ms\n",
            "Speed: 5.2ms preprocess, 59.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 914\n",
            "\n",
            "0: 384x640 3 persons, 63.8ms\n",
            "Speed: 5.8ms preprocess, 63.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 915\n",
            "\n",
            "0: 384x640 3 persons, 67.2ms\n",
            "Speed: 5.9ms preprocess, 67.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 916\n",
            "\n",
            "0: 384x640 3 persons, 57.8ms\n",
            "Speed: 7.1ms preprocess, 57.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 917\n",
            "\n",
            "0: 384x640 2 persons, 59.6ms\n",
            "Speed: 13.2ms preprocess, 59.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 918\n",
            "\n",
            "0: 384x640 2 persons, 61.4ms\n",
            "Speed: 7.4ms preprocess, 61.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 919\n",
            "\n",
            "0: 384x640 2 persons, 78.8ms\n",
            "Speed: 10.4ms preprocess, 78.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 920\n",
            "\n",
            "0: 384x640 4 persons, 60.0ms\n",
            "Speed: 7.1ms preprocess, 60.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 921\n",
            "\n",
            "0: 384x640 4 persons, 58.2ms\n",
            "Speed: 7.3ms preprocess, 58.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 922\n",
            "\n",
            "0: 384x640 3 persons, 58.9ms\n",
            "Speed: 7.7ms preprocess, 58.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 923\n",
            "\n",
            "0: 384x640 4 persons, 59.3ms\n",
            "Speed: 2.7ms preprocess, 59.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 924\n",
            "\n",
            "0: 384x640 3 persons, 67.2ms\n",
            "Speed: 6.3ms preprocess, 67.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 925\n",
            "\n",
            "0: 384x640 3 persons, 65.7ms\n",
            "Speed: 5.4ms preprocess, 65.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 926\n",
            "\n",
            "0: 384x640 3 persons, 70.6ms\n",
            "Speed: 8.9ms preprocess, 70.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 927\n",
            "\n",
            "0: 384x640 3 persons, 61.2ms\n",
            "Speed: 4.4ms preprocess, 61.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 928\n",
            "\n",
            "0: 384x640 3 persons, 64.2ms\n",
            "Speed: 3.7ms preprocess, 64.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 929\n",
            "\n",
            "0: 384x640 5 persons, 62.2ms\n",
            "Speed: 7.8ms preprocess, 62.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 930\n",
            "\n",
            "0: 384x640 4 persons, 61.8ms\n",
            "Speed: 5.5ms preprocess, 61.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 931\n",
            "\n",
            "0: 384x640 2 persons, 62.1ms\n",
            "Speed: 5.9ms preprocess, 62.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 932\n",
            "\n",
            "0: 384x640 2 persons, 59.7ms\n",
            "Speed: 5.6ms preprocess, 59.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 933\n",
            "\n",
            "0: 384x640 2 persons, 68.9ms\n",
            "Speed: 5.5ms preprocess, 68.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 934\n",
            "\n",
            "0: 384x640 2 persons, 63.8ms\n",
            "Speed: 9.0ms preprocess, 63.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 935\n",
            "\n",
            "0: 384x640 2 persons, 60.2ms\n",
            "Speed: 16.3ms preprocess, 60.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 936\n",
            "\n",
            "0: 384x640 2 persons, 66.8ms\n",
            "Speed: 10.2ms preprocess, 66.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 937\n",
            "\n",
            "0: 384x640 2 persons, 61.5ms\n",
            "Speed: 12.3ms preprocess, 61.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 938\n",
            "\n",
            "0: 384x640 2 persons, 75.4ms\n",
            "Speed: 20.6ms preprocess, 75.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 939\n",
            "\n",
            "0: 384x640 2 persons, 62.1ms\n",
            "Speed: 18.1ms preprocess, 62.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 940\n",
            "\n",
            "0: 384x640 2 persons, 106.3ms\n",
            "Speed: 22.0ms preprocess, 106.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 941\n",
            "\n",
            "0: 384x640 2 persons, 67.9ms\n",
            "Speed: 19.2ms preprocess, 67.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 942\n",
            "\n",
            "0: 384x640 2 persons, 62.0ms\n",
            "Speed: 18.4ms preprocess, 62.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 943\n",
            "\n",
            "0: 384x640 2 persons, 79.4ms\n",
            "Speed: 20.4ms preprocess, 79.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 944\n",
            "\n",
            "0: 384x640 2 persons, 106.0ms\n",
            "Speed: 7.3ms preprocess, 106.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 945\n",
            "\n",
            "0: 384x640 2 persons, 79.4ms\n",
            "Speed: 16.0ms preprocess, 79.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 946\n",
            "\n",
            "0: 384x640 2 persons, 81.8ms\n",
            "Speed: 7.7ms preprocess, 81.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 947\n",
            "\n",
            "0: 384x640 2 persons, 77.9ms\n",
            "Speed: 8.6ms preprocess, 77.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 948\n",
            "\n",
            "0: 384x640 2 persons, 186.3ms\n",
            "Speed: 38.1ms preprocess, 186.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 949\n",
            "\n",
            "0: 384x640 2 persons, 64.6ms\n",
            "Speed: 16.9ms preprocess, 64.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 950\n",
            "\n",
            "0: 384x640 2 persons, 62.9ms\n",
            "Speed: 7.7ms preprocess, 62.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 951\n",
            "\n",
            "0: 384x640 2 persons, 61.7ms\n",
            "Speed: 6.3ms preprocess, 61.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 952\n",
            "\n",
            "0: 384x640 2 persons, 61.4ms\n",
            "Speed: 6.3ms preprocess, 61.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 953\n",
            "\n",
            "0: 384x640 2 persons, 68.1ms\n",
            "Speed: 7.7ms preprocess, 68.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 954\n",
            "\n",
            "0: 384x640 2 persons, 62.4ms\n",
            "Speed: 8.7ms preprocess, 62.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 955\n",
            "\n",
            "0: 384x640 2 persons, 66.1ms\n",
            "Speed: 11.5ms preprocess, 66.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 956\n",
            "\n",
            "0: 384x640 2 persons, 60.8ms\n",
            "Speed: 7.2ms preprocess, 60.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 957\n",
            "\n",
            "0: 384x640 2 persons, 62.8ms\n",
            "Speed: 7.5ms preprocess, 62.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 958\n",
            "\n",
            "0: 384x640 2 persons, 65.1ms\n",
            "Speed: 9.1ms preprocess, 65.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 959\n",
            "\n",
            "0: 384x640 2 persons, 63.0ms\n",
            "Speed: 10.9ms preprocess, 63.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 960\n",
            "\n",
            "0: 384x640 2 persons, 61.4ms\n",
            "Speed: 13.5ms preprocess, 61.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 961\n",
            "\n",
            "0: 384x640 2 persons, 58.6ms\n",
            "Speed: 7.9ms preprocess, 58.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 962\n",
            "\n",
            "0: 384x640 2 persons, 59.0ms\n",
            "Speed: 13.3ms preprocess, 59.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 963\n",
            "\n",
            "0: 384x640 2 persons, 60.4ms\n",
            "Speed: 7.4ms preprocess, 60.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 964\n",
            "\n",
            "0: 384x640 2 persons, 62.2ms\n",
            "Speed: 7.4ms preprocess, 62.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 965\n",
            "\n",
            "0: 384x640 2 persons, 69.8ms\n",
            "Speed: 6.7ms preprocess, 69.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 966\n",
            "\n",
            "0: 384x640 2 persons, 62.1ms\n",
            "Speed: 10.3ms preprocess, 62.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 967\n",
            "\n",
            "0: 384x640 2 persons, 58.2ms\n",
            "Speed: 12.9ms preprocess, 58.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 968\n",
            "\n",
            "0: 384x640 2 persons, 79.2ms\n",
            "Speed: 6.7ms preprocess, 79.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 969\n",
            "\n",
            "0: 384x640 2 persons, 59.8ms\n",
            "Speed: 3.5ms preprocess, 59.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 970\n",
            "\n",
            "0: 384x640 2 persons, 59.6ms\n",
            "Speed: 5.5ms preprocess, 59.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 971\n",
            "\n",
            "0: 384x640 2 persons, 66.3ms\n",
            "Speed: 16.4ms preprocess, 66.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 972\n",
            "\n",
            "0: 384x640 2 persons, 63.0ms\n",
            "Speed: 8.1ms preprocess, 63.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 973\n",
            "\n",
            "0: 384x640 2 persons, 66.2ms\n",
            "Speed: 4.6ms preprocess, 66.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 974\n",
            "\n",
            "0: 384x640 2 persons, 62.4ms\n",
            "Speed: 7.7ms preprocess, 62.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 975\n",
            "\n",
            "0: 384x640 2 persons, 68.7ms\n",
            "Speed: 13.2ms preprocess, 68.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 976\n",
            "\n",
            "0: 384x640 2 persons, 63.6ms\n",
            "Speed: 6.5ms preprocess, 63.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 977\n",
            "\n",
            "0: 384x640 2 persons, 64.5ms\n",
            "Speed: 8.9ms preprocess, 64.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 978\n",
            "\n",
            "0: 384x640 2 persons, 61.0ms\n",
            "Speed: 11.6ms preprocess, 61.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 979\n",
            "\n",
            "0: 384x640 2 persons, 76.6ms\n",
            "Speed: 6.7ms preprocess, 76.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 980\n",
            "\n",
            "0: 384x640 2 persons, 71.1ms\n",
            "Speed: 10.5ms preprocess, 71.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 981\n",
            "\n",
            "0: 384x640 2 persons, 61.2ms\n",
            "Speed: 6.6ms preprocess, 61.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 982\n",
            "\n",
            "0: 384x640 2 persons, 62.2ms\n",
            "Speed: 19.2ms preprocess, 62.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 983\n",
            "\n",
            "0: 384x640 2 persons, 66.2ms\n",
            "Speed: 7.7ms preprocess, 66.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 984\n",
            "\n",
            "0: 384x640 2 persons, 69.2ms\n",
            "Speed: 3.7ms preprocess, 69.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 985\n",
            "\n",
            "0: 384x640 2 persons, 60.8ms\n",
            "Speed: 6.3ms preprocess, 60.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 986\n",
            "\n",
            "0: 384x640 2 persons, 76.1ms\n",
            "Speed: 7.9ms preprocess, 76.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 987\n",
            "\n",
            "0: 384x640 2 persons, 63.9ms\n",
            "Speed: 8.3ms preprocess, 63.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 988\n",
            "\n",
            "0: 384x640 2 persons, 64.6ms\n",
            "Speed: 7.6ms preprocess, 64.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 989\n",
            "\n",
            "0: 384x640 2 persons, 59.5ms\n",
            "Speed: 8.3ms preprocess, 59.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 990\n",
            "\n",
            "0: 384x640 2 persons, 109.2ms\n",
            "Speed: 9.9ms preprocess, 109.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 991\n",
            "\n",
            "0: 384x640 2 persons, 66.6ms\n",
            "Speed: 8.2ms preprocess, 66.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 992\n",
            "\n",
            "0: 384x640 2 persons, 58.4ms\n",
            "Speed: 17.0ms preprocess, 58.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 993\n",
            "\n",
            "0: 384x640 2 persons, 73.2ms\n",
            "Speed: 15.1ms preprocess, 73.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 994\n",
            "\n",
            "0: 384x640 2 persons, 112.8ms\n",
            "Speed: 3.4ms preprocess, 112.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 995\n",
            "\n",
            "0: 384x640 2 persons, 61.8ms\n",
            "Speed: 9.0ms preprocess, 61.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 996\n",
            "\n",
            "0: 384x640 2 persons, 64.3ms\n",
            "Speed: 20.2ms preprocess, 64.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 997\n",
            "\n",
            "0: 384x640 2 persons, 59.4ms\n",
            "Speed: 34.8ms preprocess, 59.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 998\n",
            "\n",
            "0: 384x640 2 persons, 83.6ms\n",
            "Speed: 19.3ms preprocess, 83.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 999\n",
            "\n",
            "0: 384x640 2 persons, 63.4ms\n",
            "Speed: 17.1ms preprocess, 63.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1000\n",
            "\n",
            "0: 384x640 2 persons, 61.6ms\n",
            "Speed: 3.3ms preprocess, 61.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1001\n",
            "\n",
            "0: 384x640 2 persons, 61.8ms\n",
            "Speed: 6.4ms preprocess, 61.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1002\n",
            "\n",
            "0: 384x640 2 persons, 65.5ms\n",
            "Speed: 7.8ms preprocess, 65.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1003\n",
            "\n",
            "0: 384x640 2 persons, 61.1ms\n",
            "Speed: 5.7ms preprocess, 61.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1004\n",
            "\n",
            "0: 384x640 3 persons, 73.2ms\n",
            "Speed: 10.3ms preprocess, 73.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1005\n",
            "\n",
            "0: 384x640 2 persons, 62.9ms\n",
            "Speed: 8.7ms preprocess, 62.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1006\n",
            "\n",
            "0: 384x640 3 persons, 62.1ms\n",
            "Speed: 11.1ms preprocess, 62.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1007\n",
            "\n",
            "0: 384x640 2 persons, 63.3ms\n",
            "Speed: 3.5ms preprocess, 63.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1008\n",
            "\n",
            "0: 384x640 2 persons, 63.6ms\n",
            "Speed: 9.1ms preprocess, 63.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1009\n",
            "\n",
            "0: 384x640 2 persons, 61.0ms\n",
            "Speed: 7.7ms preprocess, 61.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1010\n",
            "\n",
            "0: 384x640 2 persons, 66.6ms\n",
            "Speed: 5.8ms preprocess, 66.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1011\n",
            "\n",
            "0: 384x640 2 persons, 63.2ms\n",
            "Speed: 19.6ms preprocess, 63.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1012\n",
            "\n",
            "0: 384x640 2 persons, 60.8ms\n",
            "Speed: 2.9ms preprocess, 60.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1013\n",
            "\n",
            "0: 384x640 2 persons, 58.2ms\n",
            "Speed: 11.1ms preprocess, 58.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1014\n",
            "\n",
            "0: 384x640 2 persons, 70.6ms\n",
            "Speed: 5.9ms preprocess, 70.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1015\n",
            "\n",
            "0: 384x640 2 persons, 79.8ms\n",
            "Speed: 5.3ms preprocess, 79.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1016\n",
            "\n",
            "0: 384x640 2 persons, 60.0ms\n",
            "Speed: 8.4ms preprocess, 60.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1017\n",
            "\n",
            "0: 384x640 2 persons, 62.5ms\n",
            "Speed: 11.8ms preprocess, 62.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1018\n",
            "\n",
            "0: 384x640 2 persons, 58.9ms\n",
            "Speed: 10.3ms preprocess, 58.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1019\n",
            "\n",
            "0: 384x640 2 persons, 81.7ms\n",
            "Speed: 12.1ms preprocess, 81.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1020\n",
            "\n",
            "0: 384x640 2 persons, 64.5ms\n",
            "Speed: 3.6ms preprocess, 64.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1021\n",
            "\n",
            "0: 384x640 2 persons, 67.2ms\n",
            "Speed: 6.6ms preprocess, 67.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1022\n",
            "\n",
            "0: 384x640 2 persons, 63.4ms\n",
            "Speed: 3.1ms preprocess, 63.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1023\n",
            "\n",
            "0: 384x640 2 persons, 65.0ms\n",
            "Speed: 7.6ms preprocess, 65.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1024\n",
            "\n",
            "0: 384x640 2 persons, 57.0ms\n",
            "Speed: 28.1ms preprocess, 57.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1025\n",
            "\n",
            "0: 384x640 2 persons, 61.6ms\n",
            "Speed: 8.4ms preprocess, 61.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1026\n",
            "\n",
            "0: 384x640 2 persons, 65.7ms\n",
            "Speed: 7.5ms preprocess, 65.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1027\n",
            "\n",
            "0: 384x640 2 persons, 60.0ms\n",
            "Speed: 9.4ms preprocess, 60.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1028\n",
            "\n",
            "0: 384x640 2 persons, 66.4ms\n",
            "Speed: 8.8ms preprocess, 66.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1029\n",
            "\n",
            "0: 384x640 2 persons, 67.1ms\n",
            "Speed: 2.7ms preprocess, 67.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1030\n",
            "\n",
            "0: 384x640 2 persons, 60.2ms\n",
            "Speed: 8.7ms preprocess, 60.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1031\n",
            "\n",
            "0: 384x640 2 persons, 64.9ms\n",
            "Speed: 10.3ms preprocess, 64.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1032\n",
            "\n",
            "0: 384x640 2 persons, 59.2ms\n",
            "Speed: 15.8ms preprocess, 59.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1033\n",
            "\n",
            "0: 384x640 2 persons, 61.6ms\n",
            "Speed: 5.7ms preprocess, 61.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1034\n",
            "\n",
            "0: 384x640 2 persons, 63.0ms\n",
            "Speed: 6.2ms preprocess, 63.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1035\n",
            "\n",
            "0: 384x640 2 persons, 93.0ms\n",
            "Speed: 7.7ms preprocess, 93.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1036\n",
            "\n",
            "0: 384x640 2 persons, 66.7ms\n",
            "Speed: 16.1ms preprocess, 66.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1037\n",
            "\n",
            "0: 384x640 2 persons, 66.2ms\n",
            "Speed: 8.7ms preprocess, 66.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1038\n",
            "\n",
            "0: 384x640 2 persons, 62.8ms\n",
            "Speed: 6.6ms preprocess, 62.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1039\n",
            "\n",
            "0: 384x640 2 persons, 90.9ms\n",
            "Speed: 5.9ms preprocess, 90.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1040\n",
            "\n",
            "0: 384x640 2 persons, 60.2ms\n",
            "Speed: 12.1ms preprocess, 60.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1041\n",
            "\n",
            "0: 384x640 2 persons, 89.5ms\n",
            "Speed: 15.1ms preprocess, 89.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1042\n",
            "\n",
            "0: 384x640 2 persons, 60.3ms\n",
            "Speed: 12.1ms preprocess, 60.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1043\n",
            "\n",
            "0: 384x640 2 persons, 74.6ms\n",
            "Speed: 7.5ms preprocess, 74.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1044\n",
            "\n",
            "0: 384x640 2 persons, 100.1ms\n",
            "Speed: 8.0ms preprocess, 100.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1045\n",
            "\n",
            "0: 384x640 2 persons, 63.1ms\n",
            "Speed: 16.1ms preprocess, 63.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1046\n",
            "\n",
            "0: 384x640 2 persons, 61.0ms\n",
            "Speed: 13.6ms preprocess, 61.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1047\n",
            "\n",
            "0: 384x640 2 persons, 68.5ms\n",
            "Speed: 12.9ms preprocess, 68.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1048\n",
            "\n",
            "0: 384x640 2 persons, 61.1ms\n",
            "Speed: 8.3ms preprocess, 61.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1049\n",
            "\n",
            "0: 384x640 2 persons, 68.9ms\n",
            "Speed: 6.0ms preprocess, 68.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1050\n",
            "\n",
            "0: 384x640 2 persons, 65.7ms\n",
            "Speed: 7.8ms preprocess, 65.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1051\n",
            "\n",
            "0: 384x640 2 persons, 60.0ms\n",
            "Speed: 6.2ms preprocess, 60.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1052\n",
            "\n",
            "0: 384x640 2 persons, 63.2ms\n",
            "Speed: 7.6ms preprocess, 63.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1053\n",
            "\n",
            "0: 384x640 2 persons, 66.0ms\n",
            "Speed: 7.7ms preprocess, 66.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1054\n",
            "\n",
            "0: 384x640 2 persons, 60.0ms\n",
            "Speed: 6.2ms preprocess, 60.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1055\n",
            "\n",
            "0: 384x640 2 persons, 60.2ms\n",
            "Speed: 6.9ms preprocess, 60.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1056\n",
            "\n",
            "0: 384x640 2 persons, 63.3ms\n",
            "Speed: 8.1ms preprocess, 63.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1057\n",
            "\n",
            "0: 384x640 2 persons, 65.7ms\n",
            "Speed: 6.2ms preprocess, 65.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1058\n",
            "\n",
            "0: 384x640 2 persons, 68.4ms\n",
            "Speed: 3.5ms preprocess, 68.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1059\n",
            "\n",
            "0: 384x640 2 persons, 65.1ms\n",
            "Speed: 8.1ms preprocess, 65.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1060\n",
            "\n",
            "0: 384x640 2 persons, 77.4ms\n",
            "Speed: 9.5ms preprocess, 77.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1061\n",
            "\n",
            "0: 384x640 3 persons, 64.0ms\n",
            "Speed: 9.1ms preprocess, 64.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1062\n",
            "\n",
            "0: 384x640 3 persons, 58.4ms\n",
            "Speed: 4.0ms preprocess, 58.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1063\n",
            "\n",
            "0: 384x640 3 persons, 64.2ms\n",
            "Speed: 6.8ms preprocess, 64.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1064\n",
            "\n",
            "0: 384x640 3 persons, 63.3ms\n",
            "Speed: 2.5ms preprocess, 63.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1065\n",
            "\n",
            "0: 384x640 3 persons, 60.4ms\n",
            "Speed: 15.4ms preprocess, 60.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Action detected for person_1: punching at frame 1066\n",
            "\n",
            "0: 384x640 2 persons, 59.6ms\n",
            "Speed: 6.9ms preprocess, 59.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 64.0ms\n",
            "Speed: 7.7ms preprocess, 64.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 62.7ms\n",
            "Speed: 10.7ms preprocess, 62.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 75.5ms\n",
            "Speed: 7.4ms preprocess, 75.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 60.2ms\n",
            "Speed: 7.1ms preprocess, 60.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 60.4ms\n",
            "Speed: 8.4ms preprocess, 60.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 65.3ms\n",
            "Speed: 7.1ms preprocess, 65.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 59.5ms\n",
            "Speed: 4.9ms preprocess, 59.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 62.4ms\n",
            "Speed: 7.2ms preprocess, 62.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 61.9ms\n",
            "Speed: 15.1ms preprocess, 61.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 60.5ms\n",
            "Speed: 8.6ms preprocess, 60.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.0ms\n",
            "Speed: 11.8ms preprocess, 66.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 81.5ms\n",
            "Speed: 6.1ms preprocess, 81.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.3ms\n",
            "Speed: 5.8ms preprocess, 66.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.8ms\n",
            "Speed: 10.5ms preprocess, 59.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 94.7ms\n",
            "Speed: 16.4ms preprocess, 94.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 69.8ms\n",
            "Speed: 11.8ms preprocess, 69.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.8ms\n",
            "Speed: 14.8ms preprocess, 61.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 71.5ms\n",
            "Speed: 5.4ms preprocess, 71.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 106.0ms\n",
            "Speed: 41.3ms preprocess, 106.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.9ms\n",
            "Speed: 17.5ms preprocess, 60.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.6ms\n",
            "Speed: 7.5ms preprocess, 64.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 82.7ms\n",
            "Speed: 8.1ms preprocess, 82.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 74.6ms\n",
            "Speed: 44.8ms preprocess, 74.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.8ms\n",
            "Speed: 6.6ms preprocess, 66.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 60.5ms\n",
            "Speed: 15.8ms preprocess, 60.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 63.0ms\n",
            "Speed: 16.5ms preprocess, 63.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 59.9ms\n",
            "Speed: 6.3ms preprocess, 59.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 60.5ms\n",
            "Speed: 8.6ms preprocess, 60.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 66.5ms\n",
            "Speed: 5.5ms preprocess, 66.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 58.6ms\n",
            "Speed: 8.4ms preprocess, 58.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 58.7ms\n",
            "Speed: 9.4ms preprocess, 58.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 61.7ms\n",
            "Speed: 9.1ms preprocess, 61.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 63.0ms\n",
            "Speed: 8.0ms preprocess, 63.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 57.0ms\n",
            "Speed: 9.1ms preprocess, 57.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 59.9ms\n",
            "Speed: 9.1ms preprocess, 59.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 59.3ms\n",
            "Speed: 19.3ms preprocess, 59.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 62.5ms\n",
            "Speed: 6.2ms preprocess, 62.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 64.3ms\n",
            "Speed: 7.9ms preprocess, 64.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 61.5ms\n",
            "Speed: 11.4ms preprocess, 61.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 60.2ms\n",
            "Speed: 7.7ms preprocess, 60.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 61.5ms\n",
            "Speed: 7.7ms preprocess, 61.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 62.4ms\n",
            "Speed: 8.5ms preprocess, 62.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 59.6ms\n",
            "Speed: 7.1ms preprocess, 59.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 59.5ms\n",
            "Speed: 8.9ms preprocess, 59.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 64.2ms\n",
            "Speed: 12.3ms preprocess, 64.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 68.3ms\n",
            "Speed: 17.8ms preprocess, 68.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 60.4ms\n",
            "Speed: 9.2ms preprocess, 60.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 71.1ms\n",
            "Speed: 4.3ms preprocess, 71.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 60.3ms\n",
            "Speed: 8.1ms preprocess, 60.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 60.2ms\n",
            "Speed: 12.0ms preprocess, 60.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 60.5ms\n",
            "Speed: 7.7ms preprocess, 60.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 64.0ms\n",
            "Speed: 7.9ms preprocess, 64.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 62.8ms\n",
            "Speed: 7.6ms preprocess, 62.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 64.3ms\n",
            "Speed: 3.2ms preprocess, 64.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 63.9ms\n",
            "Speed: 16.6ms preprocess, 63.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 143.9ms\n",
            "Speed: 41.7ms preprocess, 143.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 90.6ms\n",
            "Speed: 15.3ms preprocess, 90.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 66.1ms\n",
            "Speed: 6.8ms preprocess, 66.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 62.4ms\n",
            "Speed: 12.2ms preprocess, 62.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 64.6ms\n",
            "Speed: 37.9ms preprocess, 64.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 80.3ms\n",
            "Speed: 7.2ms preprocess, 80.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 70.5ms\n",
            "Speed: 9.0ms preprocess, 70.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 65.4ms\n",
            "Speed: 13.8ms preprocess, 65.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 60.0ms\n",
            "Speed: 6.9ms preprocess, 60.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 66.8ms\n",
            "Speed: 8.1ms preprocess, 66.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 60.5ms\n",
            "Speed: 13.2ms preprocess, 60.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 61.6ms\n",
            "Speed: 5.8ms preprocess, 61.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 65.3ms\n",
            "Speed: 7.4ms preprocess, 65.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 73.9ms\n",
            "Speed: 8.7ms preprocess, 73.9ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.8ms\n",
            "Speed: 6.2ms preprocess, 65.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.1ms\n",
            "Speed: 4.8ms preprocess, 65.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.0ms\n",
            "Speed: 4.3ms preprocess, 61.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.8ms\n",
            "Speed: 9.6ms preprocess, 61.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.3ms\n",
            "Speed: 8.9ms preprocess, 60.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.9ms\n",
            "Speed: 6.6ms preprocess, 59.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.4ms\n",
            "Speed: 15.7ms preprocess, 62.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.8ms\n",
            "Speed: 5.2ms preprocess, 66.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.4ms\n",
            "Speed: 5.5ms preprocess, 64.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.1ms\n",
            "Speed: 7.9ms preprocess, 60.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.4ms\n",
            "Speed: 7.8ms preprocess, 63.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 66.6ms\n",
            "Speed: 6.3ms preprocess, 66.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.8ms\n",
            "Speed: 8.3ms preprocess, 64.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 58.0ms\n",
            "Speed: 7.9ms preprocess, 58.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 74.7ms\n",
            "Speed: 19.5ms preprocess, 74.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.7ms\n",
            "Speed: 8.8ms preprocess, 60.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.1ms\n",
            "Speed: 10.2ms preprocess, 60.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.2ms\n",
            "Speed: 3.5ms preprocess, 64.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.0ms\n",
            "Speed: 8.2ms preprocess, 61.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.6ms\n",
            "Speed: 9.2ms preprocess, 60.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.3ms\n",
            "Speed: 5.9ms preprocess, 60.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.4ms\n",
            "Speed: 7.2ms preprocess, 63.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 58.7ms\n",
            "Speed: 10.3ms preprocess, 58.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.4ms\n",
            "Speed: 9.1ms preprocess, 65.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 61.4ms\n",
            "Speed: 7.2ms preprocess, 61.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 64.0ms\n",
            "Speed: 2.7ms preprocess, 64.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.8ms\n",
            "Speed: 8.1ms preprocess, 62.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 62.2ms\n",
            "Speed: 3.9ms preprocess, 62.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.3ms\n",
            "Speed: 5.3ms preprocess, 59.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 82.6ms\n",
            "Speed: 9.0ms preprocess, 82.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 63.8ms\n",
            "Speed: 11.7ms preprocess, 63.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.7ms\n",
            "Speed: 10.2ms preprocess, 59.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 71.7ms\n",
            "Speed: 57.1ms preprocess, 71.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 82.9ms\n",
            "Speed: 7.6ms preprocess, 82.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 67.2ms\n",
            "Speed: 13.8ms preprocess, 67.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 60.1ms\n",
            "Speed: 24.2ms preprocess, 60.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 93.3ms\n",
            "Speed: 31.9ms preprocess, 93.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 65.7ms\n",
            "Speed: 31.3ms preprocess, 65.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvxySEI5AzC9"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NKgdmmKqQAIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQKqiNA2P5Eh",
        "outputId": "0ad46bcc-e4e7-49fb-a88b-aaf708a415e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNtnurXG8cqE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f8f8d44-49ad-4c68-f75f-7dd6d443ebf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train 파일: 6개, Val 파일: 2개, Test 파일: 2개로 분할 완료.\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# 파일 경로와 이름 설정\n",
        "files = [\n",
        "    '/content/drive/MyDrive/논문주제/이상행동 CCTV 영상/results_batch_batch_1.csv',\n",
        "    '/content/drive/MyDrive/논문주제/이상행동 CCTV 영상/results_batch_batch_2.csv',\n",
        "    '/content/drive/MyDrive/논문주제/이상행동 CCTV 영상/results_batch_batch_3.csv',\n",
        "    '/content/drive/MyDrive/논문주제/이상행동 CCTV 영상/results_batch_batch_4.csv',\n",
        "    '/content/drive/MyDrive/논문주제/이상행동 CCTV 영상/results_batch_batch_5.csv',\n",
        "    '/content/drive/MyDrive/논문주제/이상행동 CCTV 영상/results_batch_batch_6.csv',\n",
        "    '/content/drive/MyDrive/논문주제/이상행동 CCTV 영상/results_batch_batch_7.csv',\n",
        "    '/content/drive/MyDrive/논문주제/이상행동 CCTV 영상/results_batch_batch_8.csv',\n",
        "    '/content/drive/MyDrive/논문주제/이상행동 CCTV 영상/results_batch_batch_9.csv',\n",
        "    '/content/drive/MyDrive/논문주제/이상행동 CCTV 영상/results_batch_batch_10.csv'\n",
        "]\n",
        "\n",
        "# 각 폴더 경로\n",
        "train_dir = '/content/drive/MyDrive/논문주제/train'\n",
        "val_dir = '/content/drive/MyDrive/논문주제/val'\n",
        "test_dir = '/content/drive/MyDrive/논문주제/test'\n",
        "\n",
        "# 디렉토리 생성\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# 파일을 train, val, test로 나누는 함수\n",
        "def split_files(files, train_dir, val_dir, test_dir):\n",
        "    # 첫 6개 파일은 train, 그 다음 2개는 val, 마지막 2개는 test\n",
        "    train_files = files[:6]\n",
        "    val_files = files[6:8]\n",
        "    test_files = files[8:]\n",
        "\n",
        "    # 각 파일을 해당 폴더로 이동\n",
        "    for file in train_files:\n",
        "        df = pd.read_csv(file)\n",
        "        df.to_csv(os.path.join(train_dir, os.path.basename(file)), index=False)\n",
        "\n",
        "    for file in val_files:\n",
        "        df = pd.read_csv(file)\n",
        "        df.to_csv(os.path.join(val_dir, os.path.basename(file)), index=False)\n",
        "\n",
        "    for file in test_files:\n",
        "        df = pd.read_csv(file)\n",
        "        df.to_csv(os.path.join(test_dir, os.path.basename(file)), index=False)\n",
        "\n",
        "    print(f\"Train 파일: {len(train_files)}개, Val 파일: {len(val_files)}개, Test 파일: {len(test_files)}개로 분할 완료.\")\n",
        "\n",
        "# 함수 실행\n",
        "split_files(files, train_dir, val_dir, test_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QP0YNUNjmyUo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# 데이터 불러오기\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/논문주제/train.csv')\n",
        "val_df = pd.read_csv('/content/drive/MyDrive/논문주제/val.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/논문주제/test.csv')\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# 특징(feature)과 라벨(label) 분리\n",
        "def prepare_data(df):\n",
        "    # 프레임 번호 제거 후 모든 수치형 데이터만 선택\n",
        "    X = df.drop(columns=['frame_num']).select_dtypes(include=[np.number]).values\n",
        "\n",
        "    # 프레임 간격이 1이면 폭력 상황, 5이면 비폭력 상황으로 간주\n",
        "    frame_numbers = df['frame_num'].values\n",
        "    violence_labels = []\n",
        "    for i in range(1, len(frame_numbers)):\n",
        "        frame_gap = frame_numbers[i] - frame_numbers[i - 1]\n",
        "        if frame_gap == 1:\n",
        "            violence_labels.append(1)  # 폭력 상황\n",
        "        else:\n",
        "            violence_labels.append(0)  # 비폭력 상황\n",
        "\n",
        "    # 첫 번째 프레임은 비폭력으로 간주\n",
        "    violence_labels.insert(0, 0)\n",
        "    y = np.array(violence_labels)  # reshape(-1, 1) 제거, 정수형 라벨로 유지\n",
        "    return X, y\n",
        "\n",
        "# 결측치를 채우는 함수 정의\n",
        "def fill_missing_values(df):\n",
        "    labels = df['target_person_label'].values\n",
        "    for col in ['left_elbow_angle_1', 'right_elbow_angle_1', 'left_knee_angle_1', 'right_knee_angle_1',\n",
        "                'left_elbow_angle_2', 'right_elbow_angle_2', 'left_knee_angle_2', 'right_knee_angle_2']:\n",
        "        for i in range(1, len(df)-1):\n",
        "            if labels[i] == 'assault':\n",
        "                if pd.isna(df.loc[i, col]):\n",
        "                    prev_value = df.loc[i-1, col]\n",
        "                    next_value = df.loc[i+1, col]\n",
        "                    if pd.notna(prev_value) and pd.notna(next_value):\n",
        "                        df.loc[i, col] = (prev_value + next_value) / 2\n",
        "                    elif pd.notna(prev_value):\n",
        "                        df.loc[i, col] = prev_value\n",
        "                    elif pd.notna(next_value):\n",
        "                        df.loc[i, col] = next_value\n",
        "            elif pd.isna(df.loc[i, col]):\n",
        "                df.loc[i, col] = 0\n",
        "    return df\n",
        "\n",
        "# NaN 값을 0으로 대체하는 함수\n",
        "def replace_nan_with_zero(df):\n",
        "    return df.fillna(0)\n",
        "\n",
        "\n",
        "# 폭력 구간의 전후로 프레임을 포함하여 추출하는 함수\n",
        "def extract_violence_and_nearby_frames(df, window_before=1000, window_after=200):\n",
        "    extracted_dfs = []\n",
        "\n",
        "    # video_filename을 기준으로 그룹화하여 처리\n",
        "    for video_name, group in df.groupby('video_filename'):\n",
        "        # 폭력 구간을 나타내는 인덱스 추출\n",
        "        violence_indices = group[group['frame_num'] - group['frame_num'].shift(1) == 1].index\n",
        "        extracted_indices = []\n",
        "\n",
        "        # 시작과 끝 폭력 프레임의 인덱스 범위를 찾음\n",
        "        if len(violence_indices) > 0:\n",
        "            for idx in violence_indices:\n",
        "                start_idx = max(0, idx - window_before)  # 폭력 상황 이전 1000 프레임\n",
        "                end_idx = min(len(group), idx + window_after)  # 폭력 상황 이후 200 프레임\n",
        "                extracted_indices.extend(range(start_idx, end_idx))\n",
        "\n",
        "        # 추출된 인덱스를 리스트로 변환하여 중복 제거 후 정렬\n",
        "        extracted_indices = sorted(list(set(extracted_indices)))\n",
        "\n",
        "        # 추출된 인덱스를 기반으로 데이터 선택\n",
        "        selected_df = group.iloc[extracted_indices]\n",
        "        extracted_dfs.append(selected_df)\n",
        "\n",
        "    # 모든 비디오에 대해 추출된 데이터프레임을 병합\n",
        "    final_df = pd.concat(extracted_dfs).reset_index(drop=True)\n",
        "    return final_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_df), len(val_df), len(test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQkjjtEOLxb0",
        "outputId": "06c4aedd-fa45-45cf-d381-f96fd21b4b4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(88469, 29490, 29490)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터프레임에 결측치 처리 적용\n",
        "train_df = replace_nan_with_zero(train_df)\n",
        "val_df = replace_nan_with_zero(val_df)\n",
        "test_df = replace_nan_with_zero(test_df)\n",
        "\n",
        "train_df_balanced = extract_violence_and_nearby_frames(train_df)\n",
        "val_df_balanced = extract_violence_and_nearby_frames(val_df)\n",
        "test_df_balanced = extract_violence_and_nearby_frames(test_df)\n",
        "\n",
        "# 데이터 준비 및 LSTM 모델 학습\n",
        "X_train, y_train = prepare_data(train_df_balanced)\n",
        "X_val, y_val = prepare_data(val_df_balanced)\n",
        "X_test, y_test = prepare_data(test_df_balanced)\n",
        "\n",
        "# 데이터를 숫자형으로 변환하여 처리할 수 있게 합니다\n",
        "X_train = np.array(X_train, dtype=np.float32)\n",
        "X_val = np.array(X_val, dtype=np.float32)\n",
        "X_test = np.array(X_test, dtype=np.float32)\n",
        "\n",
        "# 데이터 정규화\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)  # 학습 데이터로 스케일러 학습 후 변환\n",
        "X_val = scaler.transform(X_val)  # 동일 스케일러로 validation 데이터 변환\n",
        "X_test = scaler.transform(X_test)  # 동일 스케일러로 test 데이터 변환"
      ],
      "metadata": {
        "id": "rAeYkNJRqh49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_df_balanced), len(val_df_balanced), len(test_df_balanced)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5pxdrzzL4P1",
        "outputId": "95f491eb-2a47-496d-df54-1720037adc7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5556, 8901, 8697)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# 데이터를 LSTM에서 사용할 수 있도록 3차원으로 변환 (samples, time_steps, features)\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
        "X_val = X_val.reshape(X_val.shape[0], 1, X_val.shape[1])\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
        "\n",
        "# PyTorch Tensor로 변환\n",
        "\n",
        "# PyTorch Tensor로 변환\n",
        "train_data = TensorDataset(torch.Tensor(X_train), torch.LongTensor(y_train))  # LongTensor 사용\n",
        "val_data = TensorDataset(torch.Tensor(X_val), torch.LongTensor(y_val))\n",
        "test_data = TensorDataset(torch.Tensor(X_test), torch.LongTensor(y_test))\n",
        "\n",
        "\n",
        "# DataLoader 생성\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n"
      ],
      "metadata": {
        "id": "8f8FNt73n9ON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM 모델 정의\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)  # 최종 예측을 위한 FC layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = out[:, -1, :]  # 마지막 타임스텝의 출력 사용\n",
        "        out = self.fc(out)  # violence 여부 예측\n",
        "        return out\n",
        "\n",
        "# 모델 인스턴스 생성\n",
        "input_size = X_train.shape[2]\n",
        "hidden_size = 32\n",
        "output_size = 2  # Binary classification (violence vs non-violence)\n",
        "model = LSTMModel(input_size, hidden_size, output_size)\n",
        "\n",
        "# 손실 함수 및 옵티마이저\n",
        "criterion = nn.CrossEntropyLoss()  # CrossEntropyLoss는 logits을 입력으로 받음\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 학습 함수 정의\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=20):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels.squeeze())  # labels 차원 맞추기\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        val_loss = 0.0\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels.squeeze())  # labels 차원 맞추기\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss/len(train_loader)}, Val Loss: {val_loss/len(val_loader)}')\n",
        "        model.train()\n",
        "\n",
        "# 모델 학습\n",
        "train_model(model, train_loader, val_loader, criterion, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PhzedcAhVTX",
        "outputId": "b012c448-f002-4cf2-be8b-d939110e740c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Train Loss: 0.280832562809703, Val Loss: 0.12290421856640701\n",
            "Epoch 2/20, Train Loss: 0.11194639278297451, Val Loss: 0.13983052963304157\n",
            "Epoch 3/20, Train Loss: 0.07582780713450978, Val Loss: 0.13247514427823137\n",
            "Epoch 4/20, Train Loss: 0.06168732884736068, Val Loss: 0.1525472918021289\n",
            "Epoch 5/20, Train Loss: 0.05431949544226986, Val Loss: 0.13925525048116763\n",
            "Epoch 6/20, Train Loss: 0.049610223441823635, Val Loss: 0.13398117542318586\n",
            "Epoch 7/20, Train Loss: 0.045335930705220365, Val Loss: 0.13473414102261286\n",
            "Epoch 8/20, Train Loss: 0.041393427134106126, Val Loss: 0.14648264132383343\n",
            "Epoch 9/20, Train Loss: 0.038593157236036124, Val Loss: 0.14958276070706966\n",
            "Epoch 10/20, Train Loss: 0.03552025164365126, Val Loss: 0.1698951329953516\n",
            "Epoch 11/20, Train Loss: 0.03291297212494644, Val Loss: 0.21593000613842292\n",
            "Epoch 12/20, Train Loss: 0.03179104210027418, Val Loss: 0.23081181302026588\n",
            "Epoch 13/20, Train Loss: 0.02959017965262863, Val Loss: 0.2400962222418848\n",
            "Epoch 14/20, Train Loss: 0.02753144720617425, Val Loss: 0.23821993527037266\n",
            "Epoch 15/20, Train Loss: 0.026213199236756725, Val Loss: 0.2792663837330938\n",
            "Epoch 16/20, Train Loss: 0.02437986364258967, Val Loss: 0.25335781662848006\n",
            "Epoch 17/20, Train Loss: 0.023079095668582267, Val Loss: 0.3122177418982414\n",
            "Epoch 18/20, Train Loss: 0.021863772376606392, Val Loss: 0.34225468455171665\n",
            "Epoch 19/20, Train Loss: 0.02110652351784038, Val Loss: 0.3754311196705682\n",
            "Epoch 20/20, Train Loss: 0.020171237338050645, Val Loss: 0.361905756368046\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test 데이터에서 모델 성능 평가 함수\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    criterion = nn.CrossEntropyLoss()  # Loss function for evaluation\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            # 입력 텐서에서 불필요한 차원 제거\n",
        "            inputs = inputs.squeeze(1)  # (batch_size, input_size)로 만듭니다.\n",
        "\n",
        "            # 라벨 크기와 타입 확인\n",
        "            print(f\"Input size: {inputs.size()}, Label size: {labels.size()}\")\n",
        "\n",
        "            if labels.size(0) == 0:\n",
        "                continue  # 빈 라벨이면 건너뜀\n",
        "\n",
        "            # 라벨의 크기 맞추기\n",
        "            labels = labels.squeeze()  # 라벨의 차원이 (batch_size,)가 되도록 차원 축소\n",
        "\n",
        "            # 모델 출력\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # 손실 계산\n",
        "            labels = labels.long()  # 라벨을 long 타입으로 변환\n",
        "            loss = criterion(outputs, labels)  # CrossEntropy는 (batch_size, num_classes), (batch_size) 형태 기대\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            # 예측을 logits에서 가장 높은 값의 인덱스로\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # 예측값과 실제 라벨 저장 (추후 분석을 위해)\n",
        "            all_preds.append(predicted.cpu().numpy())\n",
        "            all_labels.append(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = 100 * correct / total if total > 0 else 0\n",
        "    print(f'Test Loss: {test_loss/len(test_loader)}')\n",
        "    print(f'Accuracy: {accuracy}%')\n",
        "\n",
        "    return all_preds, all_labels  # 나중에 분석하거나 리포트를 생성할 때 사용\n",
        "\n",
        "# Test 데이터셋에 대한 모델 평가 수행\n",
        "test_preds, test_labels = evaluate_model(model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "id": "r1obvp-uy8Zr",
        "outputId": "4ab0d6a1-7730-486a-893c-05ec1547465f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Expected input batch_size (1) to match target batch_size (0).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-d9f374e3296a>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# 모델 테스트\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-d9f374e3296a>\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(model, test_loader)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# 손실 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mtest_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1189\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m                                label_smoothing=self.label_smoothing)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3103\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3104\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (1) to match target batch_size (0)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.isnan(X_train).sum(), np.isinf(X_train).sum())  # NaN과 Inf 값이 있는지 확인\n",
        "print(np.isnan(y_train).sum(), np.isinf(y_train).sum())  # NaN과 Inf 값이 있는지 확인"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewn7zkSmjbsT",
        "outputId": "a359a3e3-2f76-4622-f64f-9a4a12a55c1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 0\n",
            "0 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 컬럼별 NaN 값의 개수 확인\n",
        "def check_nan_columns(df):\n",
        "    nan_counts = df.isnull().sum()\n",
        "    nan_columns = nan_counts[nan_counts > 0]\n",
        "    print(f\"NaN이 포함된 컬럼과 그 개수:\\n{nan_columns}\")\n",
        "\n",
        "# train, val, test 데이터에서 NaN이 있는 컬럼 확인\n",
        "print(\"Train 데이터:\")\n",
        "check_nan_columns(train_df)\n",
        "\n",
        "print(\"\\nValidation 데이터:\")\n",
        "check_nan_columns(val_df)\n",
        "\n",
        "print(\"\\nTest 데이터:\")\n",
        "check_nan_columns(test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJw73RaqhdTd",
        "outputId": "aa39fe6c-4273-49e7-d5a2-335b0eaeec37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train 데이터:\n",
            "NaN이 포함된 컬럼과 그 개수:\n",
            "left_elbow_angle_1     27865\n",
            "right_elbow_angle_1    10260\n",
            "left_knee_angle_1       1172\n",
            "right_knee_angle_1       129\n",
            "left_elbow_angle_2     24196\n",
            "right_elbow_angle_2     9658\n",
            "left_knee_angle_2       1148\n",
            "right_knee_angle_2        89\n",
            "dtype: int64\n",
            "\n",
            "Validation 데이터:\n",
            "NaN이 포함된 컬럼과 그 개수:\n",
            "left_elbow_angle_1     9720\n",
            "right_elbow_angle_1    3184\n",
            "left_knee_angle_1       343\n",
            "right_knee_angle_1       10\n",
            "left_elbow_angle_2     9357\n",
            "right_elbow_angle_2    3499\n",
            "left_knee_angle_2       405\n",
            "right_knee_angle_2       14\n",
            "dtype: int64\n",
            "\n",
            "Test 데이터:\n",
            "NaN이 포함된 컬럼과 그 개수:\n",
            "left_elbow_angle_1     8143\n",
            "right_elbow_angle_1    2889\n",
            "left_knee_angle_1       345\n",
            "right_knee_angle_1       34\n",
            "left_elbow_angle_2     9256\n",
            "right_elbow_angle_2    3019\n",
            "left_knee_angle_2       378\n",
            "right_knee_angle_2       22\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4llypaim2v5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 얼굴 관련 키포인트 제거 후 남은 keypoints 리스트 정의\n",
        "keypoints = [\n",
        "    'target_person_left_shoulder_x', 'target_person_left_shoulder_y',\n",
        "    'target_person_right_shoulder_x', 'target_person_right_shoulder_y',\n",
        "    'target_person_left_elbow_x', 'target_person_left_elbow_y',\n",
        "    'target_person_right_elbow_x', 'target_person_right_elbow_y',\n",
        "    'target_person_left_wrist_x', 'target_person_left_wrist_y',\n",
        "    'target_person_right_wrist_x', 'target_person_right_wrist_y',\n",
        "    'target_person_left_hip_x', 'target_person_left_hip_y',\n",
        "    'target_person_right_hip_x', 'target_person_right_hip_y',\n",
        "    'target_person_left_knee_x', 'target_person_left_knee_y',\n",
        "    'target_person_right_knee_x', 'target_person_right_knee_y',\n",
        "    'target_person_left_ankle_x', 'target_person_left_ankle_y',\n",
        "    'target_person_right_ankle_x', 'target_person_right_ankle_y',\n",
        "    'closest_person_left_shoulder_x', 'closest_person_left_shoulder_y',\n",
        "    'closest_person_right_shoulder_x', 'closest_person_right_shoulder_y',\n",
        "    'closest_person_left_elbow_x', 'closest_person_left_elbow_y',\n",
        "    'closest_person_right_elbow_x', 'closest_person_right_elbow_y',\n",
        "    'closest_person_left_wrist_x', 'closest_person_left_wrist_y',\n",
        "    'closest_person_right_wrist_x', 'closest_person_right_wrist_y',\n",
        "    'closest_person_left_hip_x', 'closest_person_left_hip_y',\n",
        "    'closest_person_right_hip_x', 'closest_person_right_hip_y',\n",
        "    'closest_person_left_knee_x', 'closest_person_left_knee_y',\n",
        "    'closest_person_right_knee_x', 'closest_person_right_knee_y',\n",
        "    'closest_person_left_ankle_x', 'closest_person_left_ankle_y',\n",
        "    'closest_person_right_ankle_x', 'closest_person_right_ankle_y'\n",
        "]\n",
        "\n",
        "# 시퀀스 길이 설정\n",
        "n_timesteps = 20\n",
        "\n",
        "# 레이블을 원-핫 인코딩하는 함수\n",
        "def one_hot_encode(labels):\n",
        "    unique_labels = np.unique(labels)\n",
        "    label_map = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "    encoded = np.array([label_map[label] for label in labels])\n",
        "    return np.eye(len(unique_labels))[encoded]\n",
        "\n",
        "# 시퀀스 데이터를 생성하는 함수\n",
        "def create_sequences(data, seq_length):\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for i in range(len(data) - seq_length):\n",
        "        seq = data.iloc[i:i + seq_length]\n",
        "        label = data.iloc[i + seq_length - 1]['target_person_label']\n",
        "\n",
        "        # 필요 없는 컬럼을 제외하고 시퀀스 저장\n",
        "        X.append(seq[keypoints].values)\n",
        "        y.append(label)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# 30,000개의 로우만 사용하도록 데이터프레임을 슬라이스\n",
        "subset_df = combined_df.iloc[:51000]\n",
        "\n",
        "# 시퀀스 생성\n",
        "X, y = create_sequences(subset_df, n_timesteps)\n",
        "\n",
        "# 레이블 원-핫 인코딩\n",
        "y = one_hot_encode(y)\n",
        "\n",
        "# 입력 데이터와 출력 데이터의 shape 확인\n",
        "print(\"X의 shape:\", X.shape)\n",
        "print(\"y의 shape:\", y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ndyhGnRafiO"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 학습 데이터와 테스트 데이터 분리\n",
        "# train test split\n",
        "# 학습 데이터와 테스트 데이터 분리 (stratify 옵션 제거)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, shuffle=True, random_state=7461\n",
        ")\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xweJLAHh9XR"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def create_dataset(X, y, batch_size=32, shuffle=True):\n",
        "    # 데이터셋 객체 생성\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
        "\n",
        "    # 데이터셋 섞기\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=len(X))\n",
        "\n",
        "    # 배치 크기로 분할\n",
        "    dataset = dataset.batch(batch_size)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# 배치 사이즈 설정\n",
        "batch_size = 64\n",
        "\n",
        "# 데이터 세트 생성\n",
        "dataset_train = create_dataset(X_train, y_train, batch_size)\n",
        "dataset_test = create_dataset(X_test, y_test, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uw5497dFhboA"
      },
      "outputs": [],
      "source": [
        "len(dataset_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgymogdFhsDK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, LayerNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "# 모델 파라미터 설정\n",
        "input_shape = (X.shape[1], X.shape[2])  # 입력 시퀀스의 형태 (시퀀스 길이, 특성 수)\n",
        "num_classes = y.shape[1]  # 출력 클래스 수\n",
        "\n",
        "# Early stopping 설정\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=0.001,\n",
        "    patience=10,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# 모델 생성 함수 정의\n",
        "def build_model(lstm_layers, input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "\n",
        "    # LSTM layers\n",
        "    units = [128, 64, 32]  # 각 LSTM 레이어의 유닛 수\n",
        "    for i in range(lstm_layers):\n",
        "        return_sequences = i < lstm_layers - 1  # 마지막 LSTM layer는 return_sequences=False\n",
        "        model.add(LSTM(units[i], return_sequences=return_sequences, activation='tanh', input_shape=input_shape if i == 0 else None))\n",
        "        model.add(LayerNormalization())\n",
        "        model.add(Dropout(0.2))\n",
        "\n",
        "    # Dense layers\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# LSTM layer를 1, 2, 3개 사용하는 모델을 각각 생성 및 훈련\n",
        "models = {}\n",
        "for lstm_layers in [1, 2, 3]:\n",
        "    print(f\"Training model with {lstm_layers} LSTM layer(s)...\")\n",
        "    model = build_model(lstm_layers, input_shape, num_classes)\n",
        "    model.summary()\n",
        "    history = model.fit(dataset_train, epochs=100, callbacks=[early_stopping], validation_data=dataset_test, verbose=0)\n",
        "\n",
        "    # 검증 데이터에 대한 예측 수행\n",
        "    y_pred = model.predict(dataset_test)\n",
        "\n",
        "    # 예측된 확률을 클래스 레이블로 변환\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_true_classes = np.argmax(y_test, axis=1)  # 실제 클래스 레이블\n",
        "\n",
        "    # 정밀도, 재현율, F1 점수 계산\n",
        "    precision = precision_score(y_true_classes, y_pred_classes, average='weighted')\n",
        "    recall = recall_score(y_true_classes, y_pred_classes, average='weighted')\n",
        "    f1 = f1_score(y_true_classes, y_pred_classes, average='weighted')\n",
        "\n",
        "    # 모델 결과 저장\n",
        "    models[f'{lstm_layers}_LSTM'] = {\n",
        "        'accuracy': history.history['val_accuracy'][-1],\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1\n",
        "    }\n",
        "\n",
        "    print(f\"Model with {lstm_layers} LSTM layer(s):\")\n",
        "    print(f\"Accuracy: {history.history['val_accuracy'][-1]}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1 Score: {f1}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkO2HmAlZ9C8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 모델의 성능 지표를 시각화하기 위한 함수 정의\n",
        "def plot_model_performance(models):\n",
        "    lstm_layers = ['1_LSTM', '2_LSTM', '3_LSTM']  # LSTM 레이어 수에 따른 키 설정\n",
        "    metrics = ['accuracy', 'precision', 'recall', 'f1_score']  # 시각화할 성능 지표\n",
        "\n",
        "    for metric in metrics:\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        values = [models[layer][metric] for layer in lstm_layers]\n",
        "        plt.plot(lstm_layers, values, marker='o', linestyle='-', label=metric)\n",
        "        plt.title(f'모델 성능 - {metric.capitalize()}')\n",
        "        plt.xlabel('LSTM 레이어 수')\n",
        "        plt.ylabel(metric.capitalize())\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "# 모델의 성능 지표를 시각화\n",
        "plot_model_performance(models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSPvJKugaM9M"
      },
      "outputs": [],
      "source": [
        "# 모델을 HDF5 파일 형식으로 저장\n",
        "model.save('/content/drive/MyDrive/논문주제/Final_project/xml_lstm.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mhn_5IOmhv1k"
      },
      "outputs": [],
      "source": [
        "# 훈련 과정 시각화 (선택적)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'], label='Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.plot(history.history['loss'], label='Loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.title('lstm3')\n",
        "plt.ylabel('Value')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tP9o6dy9dvdb"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBPjOByodxIf"
      },
      "source": [
        "영상테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jbMJ1mpiHA6"
      },
      "outputs": [],
      "source": [
        "!wget -q -O /content/DejaVuSans-Bold.ttf https://github.com/dejavu-fonts/dejavu-fonts/raw/master/ttf/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CUKZZzLeBLM"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from google.colab.patches import cv2_imshow  # 코랩 환경에서 이미지 표시를 위한 모듈\n",
        "import os\n",
        "\n",
        "# 영상 파일 위치 지정\n",
        "video_file = '/content/drive/MyDrive/논문주제/Final_project/Dataset/학교폭력 영상/F_176_1_0_0_0.mp4'\n",
        "\n",
        "# YOLO 모델 정의 (학습 당시에는 v8x로 진행)\n",
        "yolo_model = YOLO('yolov8n.pt')\n",
        "\n",
        "# LSTM 모델 정의\n",
        "lstm_model = load_model('/content/drive/MyDrive/논문주제/Final_project/my_model_lstm2.h5')\n",
        "\n",
        "# 시퀀스 정의\n",
        "sequences = []\n",
        "\n",
        "# 시퀀스 길이\n",
        "sequence_length = 8\n",
        "\n",
        "# 동작 라벨 정의\n",
        "actions = [\n",
        "    \"falling\", \"attack\", \"defense\", \"aggressive\", \"punch\", \"push\",\n",
        "    \"grab_collar\", \"kicking\", \"elbow_strike\", \"shoving\",\n",
        "    \"choking\", \"stomping\", \"crouching\", \"neutral\"\n",
        "]\n",
        "\n",
        "# 위험한 동작 라벨 정의\n",
        "dangerous_actions = [\n",
        "    \"falling\", \"attack\", \"aggressive\", \"punch\", \"grab_collar\",\n",
        "    \"kicking\", \"elbow_strike\", \"shoving\", \"choking\", \"stomping\"\n",
        "]\n",
        "\n",
        "# 이전에 그려진 박스의 좌표를 저장할 변수\n",
        "prev_box = None\n",
        "\n",
        "# 동영상 파일로부터 비디오 캡처 객체 생성\n",
        "cap = cv2.VideoCapture(video_file)\n",
        "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
        "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
        "\n",
        "\n",
        "def extract_keypoint(keypoints):\n",
        "    # keypoints: [x, y, confidence, ...]\n",
        "    return keypoints[:, :2].flatten().tolist()  # x, y 좌표만 사용\n",
        "\n",
        "def find_closest_pairs(boxes, labels, keypoints):\n",
        "    \"\"\"\n",
        "    주어진 조건에 따라 두 사람 간의 가장 적합한 바운딩 박스를 반환합니다.\n",
        "    \"\"\"\n",
        "    min_distance = float('inf')\n",
        "    closest_pair = None\n",
        "\n",
        "    # 쓰러진 사람이 있는지 확인\n",
        "    falling_indices = [i for i, label in enumerate(labels) if label == 'falling']\n",
        "    if falling_indices:\n",
        "        fallen_index = falling_indices[0]\n",
        "        fallen_keypoints = keypoints[fallen_index]\n",
        "\n",
        "        for i, kp in enumerate(keypoints):\n",
        "            if i != fallen_index:\n",
        "                distance = np.linalg.norm(np.array(fallen_keypoints[GetKeypoint.LEFT_HIP*2:GetKeypoint.LEFT_HIP*2+2]) -\n",
        "                                          np.array(kp[GetKeypoint.LEFT_HIP*2:GetKeypoint.LEFT_HIP*2+2]))\n",
        "                if distance < min_distance:\n",
        "                    min_distance = distance\n",
        "                    closest_pair = (fallen_index, i)\n",
        "\n",
        "    # 웅크리고 있는 사람이 있는지 확인\n",
        "    elif not closest_pair:\n",
        "        crouching_indices = [i for i, label in enumerate(labels) if label == 'crouching']\n",
        "        if crouching_indices:\n",
        "            crouching_index = crouching_indices[0]\n",
        "            crouching_keypoints = keypoints[crouching_index]\n",
        "\n",
        "            for i, kp in enumerate(keypoints):\n",
        "                if i != crouching_index:\n",
        "                    distance = np.linalg.norm(np.array(crouching_keypoints[GetKeypoint.LEFT_HIP*2:GetKeypoint.LEFT_HIP*2+2]) -\n",
        "                                              np.array(kp[GetKeypoint.LEFT_HIP*2:GetKeypoint.LEFT_HIP*2+2]))\n",
        "                    if distance < min_distance:\n",
        "                        min_distance = distance\n",
        "                        closest_pair = (crouching_index, i)\n",
        "\n",
        "    # 두 사람이 있는 경우, 가장 가까운 두 사람을 선택\n",
        "    if not closest_pair:\n",
        "        for i in range(len(boxes)):\n",
        "            for j in range(i + 1, len(boxes)):\n",
        "                center_i = [(boxes[i][0] + boxes[i][2]) / 2, (boxes[i][1] + boxes[i][3]) / 2]\n",
        "                center_j = [(boxes[j][0] + boxes[j][2]) / 2, (boxes[j][1] + boxes[j][3]) / 2]\n",
        "                distance = np.linalg.norm(np.array(center_i) - np.array(center_j))\n",
        "\n",
        "                if distance < min_distance:\n",
        "                    min_distance = distance\n",
        "                    closest_pair = (i, j)\n",
        "\n",
        "    return [boxes[closest_pair[0]], boxes[closest_pair[1]]]\n",
        "\n",
        "def create_largest_box(box1, box2):\n",
        "    \"\"\"\n",
        "    두 사람의 바운딩 박스를 감싸는 가장 큰 바운딩 박스를 생성합니다.\n",
        "    \"\"\"\n",
        "    x1 = min(box1[0], box2[0])\n",
        "    y1 = min(box1[1], box2[1])\n",
        "    x2 = max(box1[2], box2[2])\n",
        "    y2 = max(box1[3], box2[3])\n",
        "    return [x1, y1, x2, y2]\n",
        "\n",
        "def calculate_font_center(box):\n",
        "    \"\"\"\n",
        "    바운딩 박스의 중앙 위치를 계산하여 텍스트를 표시할 위치를 반환합니다.\n",
        "    \"\"\"\n",
        "    center_x = (box[0] + box[2]) / 2\n",
        "    center_y = (box[1] + box[3]) / 2\n",
        "    return center_x, center_y\n",
        "\n",
        "while cap.isOpened():\n",
        "    success, frame = cap.read()\n",
        "    if not success:\n",
        "        break\n",
        "\n",
        "    results = yolo_model(frame, save=False, classes=[0])\n",
        "\n",
        "    if not results:\n",
        "        continue\n",
        "\n",
        "    # 키포인트가 있는지 확인하고 처리\n",
        "    if results[0].keypoints is not None:\n",
        "        results_keypoint = results[0].keypoints.xyn.cpu().numpy()\n",
        "        labels = [classify_pose(extract_keypoint(kp)) for kp in results_keypoint]\n",
        "\n",
        "        if len(results_keypoint) == 1:\n",
        "            keypoint_list = extract_keypoint(results_keypoint[0])\n",
        "            keypoint_list.extend([0] * 24)\n",
        "        elif len(results_keypoint) >= 2:\n",
        "            xy_list = results[0].boxes.xyxy.cpu().numpy().tolist()\n",
        "            closest_boxes = find_closest_pairs(xy_list, labels, results_keypoint)\n",
        "            keypoint_list1 = extract_keypoint(results_keypoint[0])\n",
        "            keypoint_list2 = extract_keypoint(results_keypoint[1])\n",
        "            keypoint_list = keypoint_list1 + keypoint_list2\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        sequences.append(keypoint_list)\n",
        "\n",
        "    if len(sequences) == sequence_length:\n",
        "        sequences_array = np.array(sequences).reshape(1, sequence_length, -1)\n",
        "        predictions = lstm_model.predict(sequences_array)\n",
        "\n",
        "        action_index = np.argmax(predictions)\n",
        "        action_name = actions[action_index]\n",
        "        max_value = np.max(predictions)\n",
        "\n",
        "        if action_name in dangerous_actions and max_value > 0.9:\n",
        "            box_color = (0, 0, 255)\n",
        "            last_dangerous_action_detected = action_name\n",
        "        elif max_value > 0.5:\n",
        "            box_color = (0, 128, 255)\n",
        "            last_dangerous_action_detected = None\n",
        "        else:\n",
        "            box_color = (0, 255, 0)\n",
        "            last_dangerous_action_detected = None\n",
        "\n",
        "        largest_box = create_largest_box(*closest_boxes)\n",
        "\n",
        "        prev_box = largest_box\n",
        "        sequences.clear()\n",
        "\n",
        "    if prev_box is not None:\n",
        "        pil_im = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "        draw = ImageDraw.Draw(pil_im)\n",
        "\n",
        "        draw.rectangle(((prev_box[0], prev_box[1]), (prev_box[2], prev_box[3])), outline=box_color, width=5)\n",
        "        draw.text((prev_box[0], prev_box[1] - 40), action_name, font=font, fill=box_color)\n",
        "\n",
        "        if last_dangerous_action_detected:\n",
        "            danger_text = f\"Danger! {last_dangerous_action_detected} detected!\"\n",
        "            draw.text((50, 100), danger_text, font=font, fill=(255, 0, 0))\n",
        "\n",
        "        frame = cv2.cvtColor(np.array(pil_im), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    cv2_imshow(frame)  # 코랩 환경에서는 cv2_imshow를 사용\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YupojcfklYn1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}