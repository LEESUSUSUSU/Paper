{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LEESUSUSUSU/Paper/blob/main/Preprocessing_with_AlphaPose_and_Filling_Missing_Values.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITXFPsQFu_8P"
      },
      "source": [
        "**I modified the Pillow installation part of the AlphaPose Colab example program.**\n",
        "\n",
        "**This is not thoth000's original program.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cxMU0dmlnCT",
        "outputId": "d0d53e76-7fa2-4cfe-db20-1c0e25ed322f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyyaml==5.2\n",
            "  Downloading PyYAML-5.2.tar.gz (265 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/265.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/265.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.26.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "2.4.1+cu121\n",
            "6.0.2\n",
            "1.13.1\n"
          ]
        }
      ],
      "source": [
        "! pip install pyyaml==5.2\n",
        "! pip install scipy\n",
        "! pip install numpy\n",
        "! pip3 install torch torchvision --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "import yaml, scipy, os\n",
        "print(yaml.__version__)\n",
        "print(scipy.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VBhQTOSoWab",
        "outputId": "d2b42a7b-c09a-4373-8740-ced149dc3e6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AlphaPose'...\n",
            "remote: Enumerating objects: 2749, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 2749 (delta 4), reused 1 (delta 0), pack-reused 2739 (from 1)\u001b[K\n",
            "Receiving objects: 100% (2749/2749), 118.82 MiB | 18.66 MiB/s, done.\n",
            "Resolving deltas: 100% (1379/1379), done.\n"
          ]
        }
      ],
      "source": [
        "!rm -rf /content/AlphaPose\n",
        "os.chdir('/content/')\n",
        "!git clone https://github.com/MVIG-SJTU/AlphaPose.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkkNtO8qolbz",
        "outputId": "8b530b8d-6457-4c0e-b946-f0ae62114776"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (3.0.11)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  libyaml-doc\n",
            "The following NEW packages will be installed:\n",
            "  libyaml-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 62.8 kB of archives.\n",
            "After this operation, 257 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libyaml-dev amd64 0.2.2-1build2 [62.8 kB]\n",
            "Fetched 62.8 kB in 1s (74.4 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libyaml-dev:amd64.\n",
            "(Reading database ... 123620 files and directories currently installed.)\n",
            "Preparing to unpack .../libyaml-dev_0.2.2-1build2_amd64.deb ...\n",
            "Unpacking libyaml-dev:amd64 (0.2.2-1build2) ...\n",
            "Setting up libyaml-dev:amd64 (0.2.2-1build2) ...\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install cython\n",
        "!sudo apt-get install libyaml-dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-Gw3k4coyFD",
        "outputId": "f381b4e0-f476-44eb-b64a-eaa492c2f604"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AlphaPose\n",
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "Compiling detector/nms/src/soft_nms_cpu.pyx because it changed.\n",
            "[1/1] Cythonizing detector/nms/src/soft_nms_cpu.pyx\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/__init__.py:85: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Requirements should be satisfied by a PEP 517 installer.\n",
            "        If you are using pip, you can try `pip install --use-pep517`.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  dist.fetch_build_eggs(dist.setup_requires)\n",
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib.linux-x86_64-cpython-310\n",
            "creating build/lib.linux-x86_64-cpython-310/trackers\n",
            "copying trackers/tracker_cfg.py -> build/lib.linux-x86_64-cpython-310/trackers\n",
            "copying trackers/__init__.py -> build/lib.linux-x86_64-cpython-310/trackers\n",
            "copying trackers/tracker_api.py -> build/lib.linux-x86_64-cpython-310/trackers\n",
            "creating build/lib.linux-x86_64-cpython-310/alphapose\n",
            "copying alphapose/version.py -> build/lib.linux-x86_64-cpython-310/alphapose\n",
            "copying alphapose/opt.py -> build/lib.linux-x86_64-cpython-310/alphapose\n",
            "copying alphapose/__init__.py -> build/lib.linux-x86_64-cpython-310/alphapose\n",
            "creating build/lib.linux-x86_64-cpython-310/trackers/tracking\n",
            "copying trackers/tracking/matching.py -> build/lib.linux-x86_64-cpython-310/trackers/tracking\n",
            "copying trackers/tracking/__init__.py -> build/lib.linux-x86_64-cpython-310/trackers/tracking\n",
            "copying trackers/tracking/basetrack.py -> build/lib.linux-x86_64-cpython-310/trackers/tracking\n",
            "creating build/lib.linux-x86_64-cpython-310/trackers/ReidModels\n",
            "copying trackers/ReidModels/osnet.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels\n",
            "copying trackers/ReidModels/resnet_fc.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels\n",
            "copying trackers/ReidModels/osnet_ain.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels\n",
            "copying trackers/ReidModels/net_utils.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels\n",
            "copying trackers/ReidModels/bn_linear.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels\n",
            "copying trackers/ReidModels/ResNet.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels\n",
            "copying trackers/ReidModels/ResBnLin.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels\n",
            "copying trackers/ReidModels/__init__.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels\n",
            "creating build/lib.linux-x86_64-cpython-310/trackers/tracking/utils\n",
            "copying trackers/tracking/utils/io.py -> build/lib.linux-x86_64-cpython-310/trackers/tracking/utils\n",
            "copying trackers/tracking/utils/nms.py -> build/lib.linux-x86_64-cpython-310/trackers/tracking/utils\n",
            "copying trackers/tracking/utils/parse_config.py -> build/lib.linux-x86_64-cpython-310/trackers/tracking/utils\n",
            "copying trackers/tracking/utils/utils.py -> build/lib.linux-x86_64-cpython-310/trackers/tracking/utils\n",
            "copying trackers/tracking/utils/kalman_filter.py -> build/lib.linux-x86_64-cpython-310/trackers/tracking/utils\n",
            "copying trackers/tracking/utils/timer.py -> build/lib.linux-x86_64-cpython-310/trackers/tracking/utils\n",
            "copying trackers/tracking/utils/__init__.py -> build/lib.linux-x86_64-cpython-310/trackers/tracking/utils\n",
            "creating build/lib.linux-x86_64-cpython-310/trackers/ReidModels/reid\n",
            "copying trackers/ReidModels/reid/image_part_aligned.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels/reid\n",
            "copying trackers/ReidModels/reid/__init__.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels/reid\n",
            "creating build/lib.linux-x86_64-cpython-310/trackers/ReidModels/classification\n",
            "copying trackers/ReidModels/classification/rfcn_cls.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels/classification\n",
            "copying trackers/ReidModels/classification/__init__.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels/classification\n",
            "copying trackers/ReidModels/classification/classifier.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels/classification\n",
            "creating build/lib.linux-x86_64-cpython-310/trackers/ReidModels/psroi_pooling\n",
            "copying trackers/ReidModels/psroi_pooling/build.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels/psroi_pooling\n",
            "copying trackers/ReidModels/psroi_pooling/__init__.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels/psroi_pooling\n",
            "creating build/lib.linux-x86_64-cpython-310/trackers/ReidModels/backbone\n",
            "copying trackers/ReidModels/backbone/sqeezenet.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels/backbone\n",
            "copying trackers/ReidModels/backbone/googlenet.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels/backbone\n",
            "copying trackers/ReidModels/backbone/lrn.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels/backbone\n",
            "copying trackers/ReidModels/backbone/__init__.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels/backbone\n",
            "creating build/lib.linux-x86_64-cpython-310/trackers/ReidModels/psroi_pooling/functions\n",
            "copying trackers/ReidModels/psroi_pooling/functions/psroi_pooling.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels/psroi_pooling/functions\n",
            "copying trackers/ReidModels/psroi_pooling/functions/__init__.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels/psroi_pooling/functions\n",
            "creating build/lib.linux-x86_64-cpython-310/trackers/ReidModels/psroi_pooling/_ext\n",
            "copying trackers/ReidModels/psroi_pooling/_ext/__init__.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels/psroi_pooling/_ext\n",
            "creating build/lib.linux-x86_64-cpython-310/trackers/ReidModels/psroi_pooling/modules\n",
            "copying trackers/ReidModels/psroi_pooling/modules/psroi_pool.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels/psroi_pooling/modules\n",
            "copying trackers/ReidModels/psroi_pooling/modules/__init__.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels/psroi_pooling/modules\n",
            "creating build/lib.linux-x86_64-cpython-310/trackers/ReidModels/psroi_pooling/_ext/psroi_pooling\n",
            "copying trackers/ReidModels/psroi_pooling/_ext/psroi_pooling/__init__.py -> build/lib.linux-x86_64-cpython-310/trackers/ReidModels/psroi_pooling/_ext/psroi_pooling\n",
            "creating build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/custom.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/mscoco.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/halpe_26_det.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/concat_dataset.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/halpe_26.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/coco_wholebody.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/halpe_coco_wholebody_136_det.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/single_hand_det.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/halpe_coco_wholebody_136.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/mpii.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/single_hand.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/halpe_coco_wholebody_26.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/halpe_136.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/halpe_coco_wholebody_26_det.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/halpe_68_noface.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/halpe_68_noface_det.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/coco_det.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/__init__.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/halpe_136_det.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "copying alphapose/datasets/coco_wholebody_det.py -> build/lib.linux-x86_64-cpython-310/alphapose/datasets\n",
            "creating build/lib.linux-x86_64-cpython-310/alphapose/utils\n",
            "copying alphapose/utils/writer.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils\n",
            "copying alphapose/utils/env.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils\n",
            "copying alphapose/utils/render_pytorch3d.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils\n",
            "copying alphapose/utils/config.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils\n",
            "copying alphapose/utils/writer_smpl.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils\n",
            "copying alphapose/utils/bbox.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils\n",
            "copying alphapose/utils/vis.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils\n",
            "copying alphapose/utils/logger.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils\n",
            "copying alphapose/utils/transforms.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils\n",
            "copying alphapose/utils/detector.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils\n",
            "copying alphapose/utils/file_detector.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils\n",
            "copying alphapose/utils/webcam_detector.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils\n",
            "copying alphapose/utils/metrics.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils\n",
            "copying alphapose/utils/pPose_nms.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils\n",
            "copying alphapose/utils/__init__.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils\n",
            "copying alphapose/utils/registry.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils\n",
            "creating build/lib.linux-x86_64-cpython-310/alphapose/models\n",
            "copying alphapose/models/hardnet.py -> build/lib.linux-x86_64-cpython-310/alphapose/models\n",
            "copying alphapose/models/fastpose_duc.py -> build/lib.linux-x86_64-cpython-310/alphapose/models\n",
            "copying alphapose/models/criterion.py -> build/lib.linux-x86_64-cpython-310/alphapose/models\n",
            "copying alphapose/models/hrnet.py -> build/lib.linux-x86_64-cpython-310/alphapose/models\n",
            "copying alphapose/models/simple3dposeSMPLWithCam.py -> build/lib.linux-x86_64-cpython-310/alphapose/models\n",
            "copying alphapose/models/builder.py -> build/lib.linux-x86_64-cpython-310/alphapose/models\n",
            "copying alphapose/models/fastpose_duc_dense.py -> build/lib.linux-x86_64-cpython-310/alphapose/models\n",
            "copying alphapose/models/simplepose.py -> build/lib.linux-x86_64-cpython-310/alphapose/models\n",
            "copying alphapose/models/__init__.py -> build/lib.linux-x86_64-cpython-310/alphapose/models\n",
            "copying alphapose/models/fastpose.py -> build/lib.linux-x86_64-cpython-310/alphapose/models\n",
            "creating build/lib.linux-x86_64-cpython-310/alphapose/utils/roi_align\n",
            "copying alphapose/utils/roi_align/roi_align.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils/roi_align\n",
            "copying alphapose/utils/roi_align/__init__.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils/roi_align\n",
            "creating build/lib.linux-x86_64-cpython-310/alphapose/utils/presets\n",
            "copying alphapose/utils/presets/simple_transform.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils/presets\n",
            "copying alphapose/utils/presets/__init__.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils/presets\n",
            "copying alphapose/utils/presets/simple_transform_3d_smpl.py -> build/lib.linux-x86_64-cpython-310/alphapose/utils/presets\n",
            "running build_ext\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:495: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:414: UserWarning: The detected CUDA version (12.2) has a minor version mismatch with the version that was used to compile PyTorch (12.1). Most likely this shouldn't be a problem.\n",
            "  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:424: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 12.2\n",
            "  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
            "building 'detector.nms.soft_nms_cpu' extension\n",
            "creating build/temp.linux-x86_64-cpython-310\n",
            "creating build/temp.linux-x86_64-cpython-310/detector\n",
            "creating build/temp.linux-x86_64-cpython-310/detector/nms\n",
            "creating build/temp.linux-x86_64-cpython-310/detector/nms/src\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/numpy/core/include -I/usr/include/python3.10 -c detector/nms/src/soft_nms_cpu.cpp -o build/temp.linux-x86_64-cpython-310/detector/nms/src/soft_nms_cpu.o -Wno-unused-function -Wno-write-strings -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=soft_nms_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1929\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/numpy/core/include/numpy/arrayobject.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kdetector/nms/src/soft_nms_cpu.cpp:1268\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wcpp\u0007-Wcpp\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "creating build/lib.linux-x86_64-cpython-310/detector\n",
            "creating build/lib.linux-x86_64-cpython-310/detector/nms\n",
            "x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/detector/nms/src/soft_nms_cpu.o -L/usr/lib/x86_64-linux-gnu -o build/lib.linux-x86_64-cpython-310/detector/nms/soft_nms_cpu.cpython-310-x86_64-linux-gnu.so\n",
            "building 'detector.nms.nms_cpu' extension\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c detector/nms/src/nms_cpu.cpp -o build/temp.linux-x86_64-cpython-310/detector/nms/src/nms_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=nms_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/detector/nms/src/nms_cpu.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/local/cuda/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/detector/nms/nms_cpu.cpython-310-x86_64-linux-gnu.so\n",
            "building 'detector.nms.nms_cuda' extension\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c detector/nms/src/nms_cuda.cpp -o build/temp.linux-x86_64-cpython-310/detector/nms/src/nms_cuda.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=nms_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1965: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/AlphaPose/setup.py\", line 187, in <module>\n",
            "    setup(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/__init__.py\", line 108, in setup\n",
            "    return distutils.core.setup(**attrs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/core.py\", line 184, in setup\n",
            "    return run_commands(dist)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/core.py\", line 200, in run_commands\n",
            "    dist.run_commands()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/dist.py\", line 970, in run_commands\n",
            "    self.run_command(cmd)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/dist.py\", line 956, in run_command\n",
            "    super().run_command(command)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/dist.py\", line 989, in run_command\n",
            "    cmd_obj.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/command/build.py\", line 135, in run\n",
            "    self.run_command(cmd_name)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py\", line 316, in run_command\n",
            "    self.distribution.run_command(command)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/dist.py\", line 956, in run_command\n",
            "    super().run_command(command)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/dist.py\", line 989, in run_command\n",
            "    cmd_obj.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/command/build_ext.py\", line 93, in run\n",
            "    _build_ext.run(self)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/command/build_ext.py\", line 359, in run\n",
            "    self.build_extensions()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py\", line 866, in build_extensions\n",
            "    build_ext.build_extensions(self)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/command/build_ext.py\", line 479, in build_extensions\n",
            "    self._build_extensions_serial()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/command/build_ext.py\", line 505, in _build_extensions_serial\n",
            "    self.build_extension(ext)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/command/build_ext.py\", line 254, in build_extension\n",
            "    _build_ext.build_extension(self, ext)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/Cython/Distutils/build_ext.py\", line 135, in build_extension\n",
            "    super(build_ext, self).build_extension(ext)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/command/build_ext.py\", line 560, in build_extension\n",
            "    objects = self.compiler.compile(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/ccompiler.py\", line 605, in compile\n",
            "    self._compile(obj, src, ext, cc_args, extra_postargs, pp_opts)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py\", line 602, in unix_wrap_single_compile\n",
            "    cflags = unix_cuda_flags(cflags)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py\", line 569, in unix_cuda_flags\n",
            "    cflags + _get_cuda_arch_flags(cflags))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py\", line 1985, in _get_cuda_arch_flags\n",
            "    arch_list[-1] += '+PTX'\n",
            "IndexError: list index out of range\n"
          ]
        }
      ],
      "source": [
        "\n",
        "os.chdir('/content/AlphaPose')\n",
        "print(os.getcwd())\n",
        "! python setup.py build develop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9tg0Z2RznSv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed7fd8ea-bfaf-43fe-a8fe-2815342310aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-08 12:16:20--  https://github.com/Megvii-BaseDetection/YOLOX/releases/download/0.1.0/yolox_x.pth\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/386811486/24b68daf-00bc-41f7-8d5d-92d673d84a63?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241008%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241008T121620Z&X-Amz-Expires=300&X-Amz-Signature=72df86d531039057e7ca8e801341a788129fab070dd09f822c2f42851fd4f762&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolox_x.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-10-08 12:16:20--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/386811486/24b68daf-00bc-41f7-8d5d-92d673d84a63?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241008%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241008T121620Z&X-Amz-Expires=300&X-Amz-Signature=72df86d531039057e7ca8e801341a788129fab070dd09f822c2f42851fd4f762&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolox_x.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 793388371 (757M) [application/octet-stream]\n",
            "Saving to: ‘./detector/yolox/data/yolox_x.pth’\n",
            "\n",
            "yolox_x.pth         100%[===================>] 756.63M  51.8MB/s    in 16s     \n",
            "\n",
            "2024-10-08 12:16:37 (48.5 MB/s) - ‘./detector/yolox/data/yolox_x.pth’ saved [793388371/793388371]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "! mkdir /content/AlphaPose/detector/yolo/data\n",
        "file_id = '1D47msNOOiJKvPOXlnpyzdKA3k6E97NTC'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('/content/AlphaPose/detector/yolo/data/yolov3-spp.weights')\n",
        "\n",
        "! mkdir /content/AlphaPose/detector/tracker/data\n",
        "file_id = '1nlnuYfGNuHWZztQHXwVZSL_FvfE551pA'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('/content/AlphaPose/detector/tracker/data/JDE-1088x608-uncertainty')\n",
        "\n",
        "file_id = '1kQhnMRURFiy7NsdS8EFL-8vtqEXOgECn'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('/content/AlphaPose/pretrained_models/fast_res50_256x192.pth')\n",
        "\n",
        "!wget -P ./detector/yolox/data/ https://github.com/Megvii-BaseDetection/YOLOX/releases/download/0.1.0/yolox_x.pth\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiJCOUjj-g-M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a8d2128-a0ce-4a71-faa2-e56eee4d0a76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alphapose  configs   docs      LICENSE\t    pretrained_models  scripts\t  setup.py\n",
            "build\t   detector  examples  model_files  README.md\t       setup.cfg  trackers\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/AlphaPose/scripts/demo_inference.py\", line 13, in <module>\n",
            "    from detector.apis import get_detector\n",
            "ModuleNotFoundError: No module named 'detector'\n",
            "ls: cannot access 'examples/res/': No such file or directory\n",
            "ls: cannot access 'examples/res/vis': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.chdir('/content/AlphaPose')\n",
        "! ls\n",
        "! python3 scripts/demo_inference.py --cfg configs/coco/resnet/256x192_res50_lr1e-3_1x.yaml --checkpoint pretrained_models/fast_res50_256x192.pth --indir examples/demo/ --save_img\n",
        "# result json and rendered images are saved here:\n",
        "! ls examples/res/\n",
        "! ls examples/res/vis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C17tdN7MrmyL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec84fb69-1b54-412b-90bc-22fa9a23f018"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.7-py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (10.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.19.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.9-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Downloading ultralytics-8.3.7-py3-none-any.whl (882 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.0/883.0 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.9-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.7 ultralytics-thop-2.0.9\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import xml.etree.ElementTree as ET  # ET 모듈 import\n",
        "from PIL import Image, ImageDraw\n",
        "import os\n",
        "import logging\n",
        "from ultralytics import YOLO\n",
        "import pandas as pd\n",
        "\n",
        "class Opt:\n",
        "    def __init__(self):\n",
        "        self.dataset = 'coco'\n",
        "        self.sp = False\n",
        "        self.save_img = False\n",
        "        self.outputpath = './results/'\n",
        "        self.pose_flow = False\n",
        "        self.vis = True\n",
        "\n",
        "class GetKeypoint:\n",
        "    NOSE = 0\n",
        "    LEFT_EYE = 1\n",
        "    RIGHT_EYE = 2\n",
        "    LEFT_EAR = 3\n",
        "    RIGHT_EAR = 4\n",
        "    LEFT_SHOULDER = 5\n",
        "    RIGHT_SHOULDER = 6\n",
        "    LEFT_ELBOW = 7\n",
        "    RIGHT_ELBOW = 8\n",
        "    LEFT_WRIST = 9\n",
        "    RIGHT_WRIST = 10\n",
        "    LEFT_HIP = 11\n",
        "    RIGHT_HIP = 12\n",
        "    LEFT_KNEE = 13\n",
        "    RIGHT_KNEE = 14\n",
        "    LEFT_ANKLE = 15\n",
        "    RIGHT_ANKLE = 16\n",
        "\n",
        "get_keypoint = GetKeypoint()\n",
        "\n",
        "\n",
        "\n",
        "# XML 파일에서 폭행이 일어나는 시간과 행동 정보 파싱\n",
        "def parse_assault_frames(xml_file):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "    event = root.find('event')\n",
        "\n",
        "    start_time = event.find('starttime').text\n",
        "    duration = event.find('duration').text\n",
        "\n",
        "    start_frame = time_to_frames(start_time)  # starttime을 프레임으로 변환\n",
        "    end_frame = start_frame + time_to_frames(duration)  # duration을 프레임으로 변환 후 더함\n",
        "\n",
        "    return start_frame, end_frame\n",
        "\n",
        "\n",
        "def time_to_frames(time_str, fps=30):\n",
        "    \"\"\"시간 문자열을 프레임 수로 변환하는 함수 (fps는 30으로 가정).\"\"\"\n",
        "    time_parts = time_str.split(':')\n",
        "\n",
        "    if len(time_parts) == 3:\n",
        "        hours, minutes, seconds = map(float, time_parts)\n",
        "    elif len(time_parts) == 2:\n",
        "        hours = 0\n",
        "        minutes, seconds = map(float, time_parts)\n",
        "    else:\n",
        "        raise ValueError(f\"Unexpected time format: {time_str}\")\n",
        "\n",
        "    total_seconds = hours * 3600 + minutes * 60 + seconds\n",
        "    return int(total_seconds * fps)\n",
        "\n",
        "\n",
        "\n",
        "# 포즈 분류 함수\n",
        "def classify_pose(keypoints):\n",
        "    \"\"\"\n",
        "    신체 키포인트를 사용하여 포즈를 분석하고 'standing', 'walking', 'punching', 'kicking', 'falling', 'fighting', 'assault' 중 하나로 라벨을 반환합니다.\n",
        "    \"\"\"\n",
        "    nose_y = keypoints[GetKeypoint.NOSE * 2 + 1]\n",
        "    left_knee_y = keypoints[GetKeypoint.LEFT_KNEE * 2 + 1]\n",
        "    right_knee_y = keypoints[GetKeypoint.RIGHT_KNEE * 2 + 1]\n",
        "    left_ankle_y = keypoints[GetKeypoint.LEFT_ANKLE * 2 + 1]\n",
        "    right_ankle_y = keypoints[GetKeypoint.RIGHT_ANKLE * 2 + 1]\n",
        "    left_wrist_y = keypoints[GetKeypoint.LEFT_WRIST * 2 + 1]\n",
        "    right_wrist_y = keypoints[GetKeypoint.RIGHT_WRIST * 2 + 1]\n",
        "\n",
        "    fall_threshold = 50\n",
        "    height_threshold = 100\n",
        "    punch_threshold = 100  # 펀치를 위한 기준\n",
        "    kick_threshold = 50     # 킥을 위한 기준\n",
        "    walk_threshold = 30     # 걷는 포즈 기준\n",
        "    standing_threshold = 10  # 서 있는 자세를 위한 기준 (무릎과 발목 높이 차이가 적은 경우)\n",
        "\n",
        "    # 서 있는 포즈\n",
        "    if abs(left_knee_y - right_knee_y) < standing_threshold and abs(left_ankle_y - right_ankle_y) < standing_threshold:\n",
        "        return 'standing'\n",
        "\n",
        "    # 걷는 포즈\n",
        "    elif abs(left_knee_y - right_knee_y) < walk_threshold and abs(left_ankle_y - right_ankle_y) < walk_threshold:\n",
        "        return 'walking'\n",
        "\n",
        "    # 펀치 포즈\n",
        "    elif abs(left_wrist_y - nose_y) < punch_threshold or abs(right_wrist_y - nose_y) < punch_threshold:\n",
        "        return 'punching'\n",
        "\n",
        "    # 킥 포즈\n",
        "    elif abs(left_knee_y - right_knee_y) > kick_threshold:\n",
        "        return 'kicking'\n",
        "\n",
        "    # 싸움 포즈\n",
        "    elif (abs(left_knee_y - right_knee_y) > 20) and (nose_y < min(left_knee_y, right_knee_y)):\n",
        "        return 'fighting'\n",
        "\n",
        "    # 기본 포즈\n",
        "    return 'normal'\n",
        "\n",
        "# 유클리드 거리 계산\n",
        "def calculate_euclidean_distance(point1, point2):\n",
        "    return np.linalg.norm(np.array(point1) - np.array(point2))\n",
        "\n",
        "# 관절 각도 계산\n",
        "def calculate_angle(point1, point2, point3):\n",
        "    vector1 = np.array([point1[0] - point2[0], point1[1] - point2[1]])\n",
        "    vector2 = np.array([point3[0] - point2[0], point3[1] - point2[1]])\n",
        "    unit_vector1 = vector1 / np.linalg.norm(vector1)\n",
        "    unit_vector2 = vector2 / np.linalg.norm(vector2)\n",
        "    dot_product = np.dot(unit_vector1, unit_vector2)\n",
        "    angle = np.arccos(dot_product)\n",
        "    return np.degrees(angle)\n",
        "\n",
        "def calculate_joint_angles(keypoints):\n",
        "    \"\"\"\n",
        "    각 관절에 대한 각도를 계산하는 함수\n",
        "    \"\"\"\n",
        "    left_elbow_angle = calculate_angle(\n",
        "        [keypoints[GetKeypoint.LEFT_WRIST * 2], keypoints[GetKeypoint.LEFT_WRIST * 2 + 1]],\n",
        "        [keypoints[GetKeypoint.LEFT_ELBOW * 2], keypoints[GetKeypoint.LEFT_ELBOW * 2 + 1]],\n",
        "        [keypoints[GetKeypoint.LEFT_SHOULDER * 2], keypoints[GetKeypoint.LEFT_SHOULDER * 2 + 1]]\n",
        "    )\n",
        "\n",
        "    right_elbow_angle = calculate_angle(\n",
        "        [keypoints[GetKeypoint.RIGHT_WRIST * 2], keypoints[GetKeypoint.RIGHT_WRIST * 2 + 1]],\n",
        "        [keypoints[GetKeypoint.RIGHT_ELBOW * 2], keypoints[GetKeypoint.RIGHT_ELBOW * 2 + 1]],\n",
        "        [keypoints[GetKeypoint.RIGHT_SHOULDER * 2], keypoints[GetKeypoint.RIGHT_SHOULDER * 2 + 1]]\n",
        "    )\n",
        "\n",
        "    left_knee_angle = calculate_angle(\n",
        "        [keypoints[GetKeypoint.LEFT_ANKLE * 2], keypoints[GetKeypoint.LEFT_ANKLE * 2 + 1]],\n",
        "        [keypoints[GetKeypoint.LEFT_KNEE * 2], keypoints[GetKeypoint.LEFT_KNEE * 2 + 1]],\n",
        "        [keypoints[GetKeypoint.LEFT_HIP * 2], keypoints[GetKeypoint.LEFT_HIP * 2 + 1]]\n",
        "    )\n",
        "\n",
        "    right_knee_angle = calculate_angle(\n",
        "        [keypoints[GetKeypoint.RIGHT_ANKLE * 2], keypoints[GetKeypoint.RIGHT_ANKLE * 2 + 1]],\n",
        "        [keypoints[GetKeypoint.RIGHT_KNEE * 2], keypoints[GetKeypoint.RIGHT_KNEE * 2 + 1]],\n",
        "        [keypoints[GetKeypoint.RIGHT_HIP * 2], keypoints[GetKeypoint.RIGHT_HIP * 2 + 1]]\n",
        "    )\n",
        "\n",
        "    return left_elbow_angle, right_elbow_angle, left_knee_angle, right_knee_angle\n",
        "\n",
        "def heatmap_to_coord(hm, box):\n",
        "    \"\"\"\n",
        "    히트맵에서 신체 키포인트 좌표를 추출하는 함수\n",
        "    :param hm: 히트맵 (AlphaPose 모델이 출력한 히트맵)\n",
        "    :param box: 객체의 경계 상자 (사람의 좌표 상자)\n",
        "    :return: 추출된 신체 키포인트 좌표 (x, y)\n",
        "    \"\"\"\n",
        "    coords = []\n",
        "    for i in range(hm.shape[0]):\n",
        "        heatmap = hm[i, :, :].cpu().numpy()  # 텐서를 Numpy 배열로 변환 (필요한 경우에만)\n",
        "        max_val = np.max(heatmap)  # 최대값 찾기 (가장 높은 확률의 포인트)\n",
        "        y, x = np.unravel_index(np.argmax(heatmap), heatmap.shape)  # 최대값의 좌표 찾기\n",
        "\n",
        "        # 원래 이미지의 경계 상자 좌표로 변환 (박스 크기와 히트맵 비율을 고려)\n",
        "        box_width = box[2] - box[0]\n",
        "        box_height = box[3] - box[1]\n",
        "        x = box[0] + (x / heatmap.shape[1]) * box_width\n",
        "        y = box[1] + (y / heatmap.shape[0]) * box_height\n",
        "\n",
        "        coords.append([x, y])\n",
        "    return np.array(coords), max_val  # 키포인트 좌표와 해당 히트맵의 최대값 반환\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def classify_and_store_keypoints(yolo_model, pose_model, input_image, frame_num, assault_frames, cfg, device, video_file, all_keypoints):\n",
        "    \"\"\"\n",
        "    YOLO 및 AlphaPose를 사용하여 객체 감지 및 포즈 추출, 키포인트 및 라벨 저장.\n",
        "    \"\"\"\n",
        "    results = yolo_model.predict(input_image, save=False, classes=[0])\n",
        "    human_detections = [d for d in results[0].boxes.data.cpu().numpy() if int(d[-1]) == 0]\n",
        "\n",
        "    # 사람이 감지되지 않으면 NaN 값으로 채워진 데이터를 추가\n",
        "    if not human_detections:\n",
        "        print(f\"No human detections in frame {frame_num}. Adding NaN values for this frame...\")\n",
        "        nan_row = [np.nan] * 34 + [np.nan] * 4 + [np.nan] * 4 + ['normal'] + [np.nan] * 34 + [np.nan] * 4 + [np.nan] * 4 + ['normal'] + [0]\n",
        "        all_keypoints.append([video_file, frame_num] + nan_row)\n",
        "        return  # continue 대신 return 사용\n",
        "\n",
        "    inps = []\n",
        "    boxes = []\n",
        "    for detection in human_detections:\n",
        "        x1, y1, x2, y2 = map(int, detection[:4])\n",
        "        boxes.append([x1, y1, x2, y2])\n",
        "        inp = cv2.resize(input_image[y1:y2, x1:x2], (cfg.DATA_PRESET.IMAGE_SIZE[0], cfg.DATA_PRESET.IMAGE_SIZE[1]))\n",
        "        inps.append(inp)\n",
        "\n",
        "    inps = torch.stack([torch.from_numpy(np.array(inp)).permute(2, 0, 1).float() for inp in inps]).to(device)\n",
        "\n",
        "    # AlphaPose 모델로 스켈레톤 추출\n",
        "    with torch.no_grad():\n",
        "        hm = pose_model(inps)\n",
        "\n",
        "    keypoints = []\n",
        "    angles = []\n",
        "    distances = []\n",
        "    labels = []\n",
        "\n",
        "    # 각 사람에 대한 키포인트 및 라벨 추출\n",
        "    for i, box in enumerate(boxes):\n",
        "        preds, maxvals = heatmap_to_coord(hm[i], box)\n",
        "        keypoints_flatten = preds.flatten().tolist()  # (17개 관절 x 2 좌표) => 34개의 값\n",
        "\n",
        "        # 관절 각도 계산\n",
        "        left_elbow_angle, right_elbow_angle, left_knee_angle, right_knee_angle = calculate_joint_angles(keypoints_flatten)\n",
        "\n",
        "        # 유클리드 거리 계산\n",
        "        left_shoulder_left_elbow_dist = calculate_euclidean_distance(\n",
        "            (keypoints_flatten[GetKeypoint.LEFT_SHOULDER * 2], keypoints_flatten[GetKeypoint.LEFT_SHOULDER * 2 + 1]),\n",
        "            (keypoints_flatten[GetKeypoint.LEFT_ELBOW * 2], keypoints_flatten[GetKeypoint.LEFT_ELBOW * 2 + 1])\n",
        "        )\n",
        "\n",
        "        right_shoulder_right_elbow_dist = calculate_euclidean_distance(\n",
        "            (keypoints_flatten[GetKeypoint.RIGHT_SHOULDER * 2], keypoints_flatten[GetKeypoint.RIGHT_SHOULDER * 2 + 1]),\n",
        "            (keypoints_flatten[GetKeypoint.RIGHT_ELBOW * 2], keypoints_flatten[GetKeypoint.RIGHT_ELBOW * 2 + 1])\n",
        "        )\n",
        "\n",
        "        # 힙-무릎 거리 계산\n",
        "        left_hip_left_knee_dist = calculate_euclidean_distance(\n",
        "            (keypoints_flatten[GetKeypoint.LEFT_HIP * 2], keypoints_flatten[GetKeypoint.LEFT_HIP * 2 + 1]),\n",
        "            (keypoints_flatten[GetKeypoint.LEFT_KNEE * 2], keypoints_flatten[GetKeypoint.LEFT_KNEE * 2 + 1])\n",
        "        )\n",
        "\n",
        "        right_hip_right_knee_dist = calculate_euclidean_distance(\n",
        "            (keypoints_flatten[GetKeypoint.RIGHT_HIP * 2], keypoints_flatten[GetKeypoint.RIGHT_HIP * 2 + 1]),\n",
        "            (keypoints_flatten[GetKeypoint.RIGHT_KNEE * 2], keypoints_flatten[GetKeypoint.RIGHT_KNEE * 2 + 1])\n",
        "        )\n",
        "\n",
        "        distances.append([left_shoulder_left_elbow_dist, right_shoulder_right_elbow_dist, left_hip_left_knee_dist, right_hip_right_knee_dist])\n",
        "\n",
        "        # 키포인트와 각도를 저장\n",
        "        keypoints.append(keypoints_flatten)\n",
        "        angles.append([left_elbow_angle, right_elbow_angle, left_knee_angle, right_knee_angle])\n",
        "\n",
        "        # 포즈 분석을 통해 라벨 추정\n",
        "        label = classify_pose(keypoints_flatten)\n",
        "        labels.append(label)\n",
        "\n",
        "    # 사람 1명일 경우, 두 번째 사람의 데이터를 모두 NaN으로 처리\n",
        "    if len(boxes) == 1:\n",
        "        second_person_keypoints = [np.nan] * 34\n",
        "        second_person_angles = [np.nan] * 4\n",
        "        second_person_distances = [np.nan] * 4\n",
        "        second_person_label = 'normal'\n",
        "    else:\n",
        "        second_person_keypoints = keypoints[1]\n",
        "        second_person_angles = angles[1]\n",
        "        second_person_distances = distances[1]\n",
        "        second_person_label = labels[1]\n",
        "\n",
        "    # 폭행 프레임에 대한 라벨링 처리\n",
        "    if not labels[0] or labels[0] == 'normal':\n",
        "        print(f\"No violent pose detected in frame {frame_num}, setting label to 'normal'\")\n",
        "        final_label = 0\n",
        "    elif assault_frames and (assault_frames[0] <= frame_num <= assault_frames[1]):\n",
        "        print(f\"Violent frame {frame_num} detected, setting final label to 1\")\n",
        "        final_label = 1  # 폭행 중인 프레임\n",
        "    else:\n",
        "        final_label = 0  # 비폭행 프레임\n",
        "\n",
        "    all_keypoints.append([video_file, frame_num] + keypoints[0] + angles[0] + distances[0] + [labels[0]] + second_person_keypoints + second_person_angles + second_person_distances + [second_person_label] + [final_label])\n",
        "    return all_keypoints\n",
        "\n",
        "\n",
        "\n",
        "def load_existing_csv(csv_file_path):\n",
        "    \"\"\"이미 존재하는 CSV 파일이 있으면 읽어옵니다.\"\"\"\n",
        "    if os.path.exists(csv_file_path):\n",
        "        df_existing = pd.read_csv(csv_file_path)\n",
        "        processed_videos = set(df_existing['video_name'].unique())  # 이미 처리된 비디오 목록\n",
        "        return df_existing, processed_videos\n",
        "    else:\n",
        "        df_existing = pd.DataFrame(columns=['video_name', 'frame_num'])  # 비어 있는 데이터프레임 (필요한 컬럼 지정)\n",
        "        processed_videos = set()  # 빈 비디오 목록\n",
        "        return df_existing, processed_videos\n",
        "\n",
        "# 비디오 처리 후 CSV 저장하는 부분 수정:\n",
        "def save_to_csv(df_existing, all_keypoints, header, csv_file_path):\n",
        "    \"\"\"키포인트 데이터를 CSV 파일에 저장합니다.\"\"\"\n",
        "    if all_keypoints:\n",
        "        df_temp = pd.DataFrame(all_keypoints, columns=header)\n",
        "\n",
        "\n",
        "        # 기존 CSV와 합치기 전에 중복 확인 (video_name과 frame_num 기준으로 중복 제거)\n",
        "        df_combined = pd.concat([df_existing, df_temp], ignore_index=True)\n",
        "        df_combined.drop_duplicates(subset=['video_name', 'frame_num'], keep='last', inplace=True)\n",
        "\n",
        "        # 덮어쓰기 방지하며 저장\n",
        "        df_combined.to_csv(csv_file_path, index=False)\n",
        "        print(f'CSV 파일 {csv_file_path}에 저장되었습니다.')\n",
        "\n",
        "        return df_combined\n",
        "\n",
        "\n",
        "\n",
        "def check_row_data_lengths(video_filename, frame_num, keypoint_data_1, angle_data_1, distance_data_1, label_data_1, keypoint_data_2, angle_data_2, distance_data_2, label_data_2):\n",
        "    print(f\"Video filename: {video_filename}\")\n",
        "    print(f\"Frame number: {frame_num}\")\n",
        "    print(f\"Keypoint data 1 length: {len(keypoint_data_1)}\")  # 34개여야 함\n",
        "    print(f\"Angle data 1 length: {len(angle_data_1)}\")        # 4개여야 함\n",
        "    print(f\"Distance data 1 length: {len(distance_data_1)}\")  # 4개여야 함\n",
        "    print(f\"Label 1 length: {len(label_data_1)}\")             # 1개여야 함\n",
        "\n",
        "    print(f\"Keypoint data 2 length: {len(keypoint_data_2)}\")  # 34개여야 함\n",
        "    print(f\"Angle data 2 length: {len(angle_data_2)}\")        # 4개여야 함\n",
        "    print(f\"Distance data 2 length: {len(distance_data_2)}\")  # 4개여야 함\n",
        "    print(f\"Label 2 length: {len(label_data_2)}\")             # 1개여야 함\n",
        "\n",
        "\n",
        "import logging  # 로깅 추가\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "\n",
        "def process_video(video_file, yolo_model, pose_model, cfg, device, header):\n",
        "    \"\"\"\n",
        "    비디오 파일을 처리하여 프레임별로 키포인트 및 라벨을 추출합니다.\n",
        "    \"\"\"\n",
        "    all_keypoints = []  # 모든 프레임에 대한 키포인트 데이터를 저장할 리스트\n",
        "\n",
        "    # 비디오 파일 열기\n",
        "    cap = cv2.VideoCapture(video_file)\n",
        "    frame_num = 0\n",
        "\n",
        "    # assault_frames 정보를 XML 파일에서 가져오기\n",
        "    xml_file = video_file.replace('.mp4', '.xml').replace('.avi', '.xml')  # XML 파일 경로 추정\n",
        "    assault_frames = parse_assault_frames(xml_file) if os.path.exists(xml_file) else None\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break  # 프레임을 더 이상 읽을 수 없으면 종료\n",
        "\n",
        "        # 객체 탐지 및 포즈 추출 함수 호출\n",
        "        classify_and_store_keypoints(yolo_model, pose_model, frame, frame_num, assault_frames, cfg, device, video_file, all_keypoints)\n",
        "\n",
        "        frame_num += 1\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    return all_keypoints\n",
        "\n",
        "# 메인 함수\n",
        "def main(root_dir, output_dir, csv_base_path, output_image_dir, yolo_model, pose_model, cfg, device):\n",
        "\n",
        "    try:\n",
        "        image_files = []\n",
        "\n",
        "        # root_dir에서 모든 비디오 파일 탐색\n",
        "        for root, dirs, files in os.walk(root_dir):\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.mp4', '.avi')):\n",
        "                    image_files.append(os.path.join(root, file))  # 동영상 파일 경로 저장\n",
        "\n",
        "        image_files = sorted(image_files)  # 파일 정렬\n",
        "\n",
        "        # 출력 디렉토리가 없으면 생성\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        header = [\n",
        "            'video_filename', 'frame_num',\n",
        "            'target_person_nose_x', 'target_person_nose_y',\n",
        "            'target_person_left_eye_x', 'target_person_left_eye_y',\n",
        "            'target_person_right_eye_x', 'target_person_right_eye_y',\n",
        "            'target_person_left_ear_x', 'target_person_left_ear_y',\n",
        "            'target_person_right_ear_x', 'target_person_right_ear_y',\n",
        "            'target_person_left_shoulder_x', 'target_person_left_shoulder_y',\n",
        "            'target_person_right_shoulder_x', 'target_person_right_shoulder_y',\n",
        "            'target_person_left_elbow_x', 'target_person_left_elbow_y',\n",
        "            'target_person_right_elbow_x', 'target_person_right_elbow_y',\n",
        "            'target_person_left_wrist_x', 'target_person_left_wrist_y',\n",
        "            'target_person_right_wrist_x', 'target_person_right_wrist_y',\n",
        "            'target_person_left_hip_x', 'target_person_left_hip_y',\n",
        "            'target_person_right_hip_x', 'target_person_right_hip_y',\n",
        "            'target_person_left_knee_x', 'target_person_left_knee_y',\n",
        "            'target_person_right_knee_x', 'target_person_right_knee_y',\n",
        "            'target_person_left_ankle_x', 'target_person_left_ankle_y',\n",
        "            'target_person_right_ankle_x', 'target_person_right_ankle_y',\n",
        "            # 추가된 관절 각도 및 거리 (첫 번째 사람)\n",
        "            'left_elbow_angle_1', 'right_elbow_angle_1',\n",
        "            'left_knee_angle_1', 'right_knee_angle_1',\n",
        "            'left_shoulder_left_elbow_dist_1',\n",
        "            'right_shoulder_right_elbow_dist_1',\n",
        "            'left_hip_left_knee_dist_1',\n",
        "            'right_hip_right_knee_dist_1',\n",
        "            'target_person_label',\n",
        "            # 두 번째 사람\n",
        "            'closest_person_nose_x', 'closest_person_nose_y',\n",
        "            'closest_person_left_eye_x', 'closest_person_left_eye_y',\n",
        "            'closest_person_right_eye_x', 'closest_person_right_eye_y',\n",
        "            'closest_person_left_ear_x', 'closest_person_left_ear_y',\n",
        "            'closest_person_right_ear_x', 'closest_person_right_ear_y',\n",
        "            'closest_person_left_shoulder_x', 'closest_person_left_shoulder_y',\n",
        "            'closest_person_right_shoulder_x', 'closest_person_right_shoulder_y',\n",
        "            'closest_person_left_elbow_x', 'closest_person_left_elbow_y',\n",
        "            'closest_person_right_elbow_x', 'closest_person_right_elbow_y',\n",
        "            'closest_person_left_wrist_x', 'closest_person_left_wrist_y',\n",
        "            'closest_person_right_wrist_x', 'closest_person_right_wrist_y',\n",
        "            'closest_person_left_hip_x', 'closest_person_left_hip_y',\n",
        "            'closest_person_right_hip_x', 'closest_person_right_hip_y',\n",
        "            'closest_person_left_knee_x', 'closest_person_left_knee_y',\n",
        "            'closest_person_right_knee_x', 'closest_person_right_knee_y',\n",
        "            'closest_person_left_ankle_x', 'closest_person_left_ankle_y',\n",
        "            'closest_person_right_ankle_x', 'closest_person_right_ankle_y',\n",
        "            'left_elbow_angle_2', 'right_elbow_angle_2',\n",
        "            'left_knee_angle_2', 'right_knee_angle_2',\n",
        "            'left_shoulder_left_elbow_dist_2',\n",
        "            'right_shoulder_right_elbow_dist_2',\n",
        "            'left_hip_left_knee_dist_2',\n",
        "            'right_hip_right_knee_dist_2',\n",
        "            'closest_person_label',\n",
        "            'final_label'\n",
        "        ]\n",
        "\n",
        "        batch_number = 1\n",
        "        batch_size = 2  # 두 개씩 처리\n",
        "\n",
        "        for i in range(0, len(image_files), batch_size):\n",
        "            batch_files = image_files[i:i + batch_size]\n",
        "            csv_file_path = f\"{csv_base_path}_batch_{batch_number}.csv\"\n",
        "\n",
        "            all_keypoints = []  # 모든 프레임의 데이터를 저장할 리스트\n",
        "\n",
        "            for video_file in batch_files:\n",
        "                try:\n",
        "                    logging.info(f\"Processing video file: {video_file}\")\n",
        "                    keypoints = process_video(video_file, yolo_model, pose_model, cfg, device, header)\n",
        "                    if keypoints:\n",
        "                        all_keypoints.extend(keypoints)\n",
        "                        logging.info(f\"Processed {len(keypoints)} keypoints from {video_file}\")\n",
        "                    else:\n",
        "                        logging.warning(f\"No keypoints found for {video_file}\")\n",
        "                except Exception as e:\n",
        "                    logging.error(f\"Error processing {video_file}: {e}\")\n",
        "\n",
        "            if all_keypoints:\n",
        "                logging.info(f\"Saving batch {batch_number} to {csv_file_path}\")\n",
        "                df_temp = pd.DataFrame(all_keypoints, columns=header)\n",
        "                df_temp.to_csv(csv_file_path, index=False)\n",
        "                logging.info(f\"Batch {batch_number} saved to {csv_file_path}\")\n",
        "            else:\n",
        "                logging.warning(f\"No keypoints to save for batch {batch_number}\")\n",
        "\n",
        "            batch_number += 1\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Main function error: {e}\")"
      ],
      "metadata": {
        "id": "OXwJuOe9D7z_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e19715aa-a1c8-4696-b6c4-5d737edc84ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "7CxA_suRJDnT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from alphapose.models import builder\n",
        "from alphapose.utils.config import update_config\n",
        "from alphapose.utils.presets import SimpleTransform\n",
        "from alphapose.utils.transforms import get_func_heatmap_to_coord\n",
        "from ultralytics import YOLO\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 경로 설정\n",
        "    root_dir = '/content/drive/MyDrive/논문주제/이상행동 CCTV 영상/01.폭행(assult)'\n",
        "    output_dir = '/content/drive/MyDrive/논문주제/이상행동 CCTV 영상/01.폭행(assult)3'\n",
        "    csv_base_path = '/content/drive/MyDrive/논문주제/이상행동 CCTV 영상/rere_results_batch'\n",
        "    output_image_dir = '/content/drive/MyDrive/논문주제/이상행동 CCTV 영상/missing_keypoints_images'  # 결측치 발생 시 이미지를 저장할 폴더 경로\n",
        "\n",
        "    # YOLO 모델 로드\n",
        "    yolo_model_path = 'yolov8n.pt'  # YOLO 모델 경로\n",
        "    yolo_model = YOLO(yolo_model_path)  # YOLO 모델 로드\n",
        "\n",
        "    # AlphaPose 모델 설정\n",
        "    pretrained_model_path = '/content/drive/MyDrive/논문주제/Final_project/pretrained_models/fast_res50_256x192.pth'\n",
        "    cfg_file = '/content/AlphaPose/configs/coco/resnet/256x192_res50_lr1e-3_1x.yaml'\n",
        "\n",
        "    # AlphaPose Config 업데이트\n",
        "    cfg = update_config(cfg_file)  # Config 파일 업데이트\n",
        "\n",
        "    # AlphaPose 모델 빌드\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    pose_model = builder.build_sppe(cfg.MODEL, preset_cfg=cfg.DATA_PRESET)  # 모델 빌드\n",
        "    pose_model.load_state_dict(torch.load(pretrained_model_path, map_location=device))  # 가중치 로드\n",
        "    pose_model = torch.nn.DataParallel(pose_model).to(device)\n",
        "    pose_model.eval()  # 평가 모드로 설정\n",
        "\n",
        "    # main 함수 실행\n",
        "    main(root_dir, output_dir, csv_base_path, output_image_dir, yolo_model, pose_model, cfg, device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZbrYjRrCaKj",
        "outputId": "b3da18e9-d9cf-4cff-dc8f-c8984931b188"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 가져오기"
      ],
      "metadata": {
        "id": "vUb6_uetfsaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 파일 경로와 이름 설정\n",
        "# 파일 경로 설정\n",
        "files = [\n",
        "    '/content/drive/MyDrive/논문주제/이상행동 CCTV 영상/re_results_batch_batch_1.csv',\n",
        "    '/content/drive/MyDrive/논문주제/이상행동 CCTV 영상/re_results_batch_batch_2.csv',\n",
        "    '/content/drive/MyDrive/논문주제/이상행동 CCTV 영상/re_results_batch_batch_3.csv',\n",
        "    '/content/drive/MyDrive/논문주제/이상행동 CCTV 영상/re_results_batch_batch_4.csv',\n",
        "    '/content/drive/MyDrive/논문주제/이상행동 CCTV 영상/re_results_batch_batch_5.csv',\n",
        "    '/content/drive/MyDrive/논문주제/이상행동 CCTV 영상/re_results_batch_batch_18.csv',\n",
        "    '/content/drive/MyDrive/논문주제/이상행동 CCTV 영상/re_results_batch_batch_9.csv',\n",
        "    '/content/drive/MyDrive/논문주제/이상행동 CCTV 영상/re_results_batch_batch_17.csv',\n",
        "    '/content/drive/MyDrive/논문주제/이상행동 CCTV 영상/re_results_batch_batch_6.csv',\n",
        "    '/content/drive/MyDrive/논문주제/이상행동 CCTV 영상/re_results_batch_batch_15.csv'\n",
        "\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "# 사람 카운트를 계산하는 함수\n",
        "def count_people_from_keypoints(df):\n",
        "    \"\"\"\n",
        "    주어진 DataFrame에서 각 프레임에 사람 수를 카운트하여 새로운 'person_count' 열을 추가하는 함수.\n",
        "    \"\"\"\n",
        "    def count_person(row):\n",
        "        # 첫 번째 사람의 코와 어깨 키포인트가 0이거나 NaN이면 사람이 없다고 간주\n",
        "        first_person_keypoints = row[['target_person_nose_x', 'target_person_nose_y',\n",
        "            'target_person_left_eye_x', 'target_person_left_eye_y',\n",
        "            'target_person_right_eye_x', 'target_person_right_eye_y',\n",
        "            'target_person_left_ear_x', 'target_person_left_ear_y',\n",
        "            'target_person_right_ear_x', 'target_person_right_ear_y',\n",
        "            'target_person_left_shoulder_x', 'target_person_left_shoulder_y',\n",
        "            'target_person_right_shoulder_x', 'target_person_right_shoulder_y',\n",
        "            'target_person_left_elbow_x', 'target_person_left_elbow_y',\n",
        "            'target_person_right_elbow_x', 'target_person_right_elbow_y',\n",
        "            'target_person_left_wrist_x', 'target_person_left_wrist_y',\n",
        "            'target_person_right_wrist_x', 'target_person_right_wrist_y',\n",
        "            'target_person_left_hip_x', 'target_person_left_hip_y',\n",
        "            'target_person_right_hip_x', 'target_person_right_hip_y',\n",
        "            'target_person_left_knee_x', 'target_person_left_knee_y',\n",
        "            'target_person_right_knee_x', 'target_person_right_knee_y',\n",
        "            'target_person_left_ankle_x', 'target_person_left_ankle_y',\n",
        "            'target_person_right_ankle_x', 'target_person_right_ankle_y']]\n",
        "        second_person_keypoints = row[['closest_person_nose_x', 'closest_person_nose_y',\n",
        "            'closest_person_left_eye_x', 'closest_person_left_eye_y',\n",
        "            'closest_person_right_eye_x', 'closest_person_right_eye_y',\n",
        "            'closest_person_left_ear_x', 'closest_person_left_ear_y',\n",
        "            'closest_person_right_ear_x', 'closest_person_right_ear_y',\n",
        "            'closest_person_left_shoulder_x', 'closest_person_left_shoulder_y',\n",
        "            'closest_person_right_shoulder_x', 'closest_person_right_shoulder_y',\n",
        "            'closest_person_left_elbow_x', 'closest_person_left_elbow_y',\n",
        "            'closest_person_right_elbow_x', 'closest_person_right_elbow_y',\n",
        "            'closest_person_left_wrist_x', 'closest_person_left_wrist_y',\n",
        "            'closest_person_right_wrist_x', 'closest_person_right_wrist_y',\n",
        "            'closest_person_left_hip_x', 'closest_person_left_hip_y',\n",
        "            'closest_person_right_hip_x', 'closest_person_right_hip_y',\n",
        "            'closest_person_left_knee_x', 'closest_person_left_knee_y',\n",
        "            'closest_person_right_knee_x', 'closest_person_right_knee_y',\n",
        "            'closest_person_left_ankle_x', 'closest_person_left_ankle_y',\n",
        "            'closest_person_right_ankle_x', 'closest_person_right_ankle_y']]\n",
        "\n",
        "        person_count = 0\n",
        "        if not first_person_keypoints.isnull().all() and (first_person_keypoints != 0).any():\n",
        "\n",
        "            person_count += 1\n",
        "        if not second_person_keypoints.isnull().all() and (second_person_keypoints != 0).any():\n",
        "            person_count += 1\n",
        "\n",
        "        return person_count\n",
        "\n",
        "    # 'person_count' 열을 추가\n",
        "    df['person_count'] = df.apply(count_person, axis=1)\n",
        "    return df\n",
        "\n",
        "# 파일을 train, val, test로 나누는 함수 (모든 데이터를 포함하여 저장)\n",
        "def split_files_into_single_csv(files, train_csv, val_csv, test_csv):\n",
        "    # 첫 6개 파일은 train, 그 다음 2개는 val, 마지막 2개는 test\n",
        "    train_files = files[:6]\n",
        "    val_files = files[6:8]\n",
        "    test_files = files[8:]\n",
        "\n",
        "    # 각각의 파일들을 하나의 DataFrame으로 묶음\n",
        "    train_df_list = []\n",
        "    val_df_list = []\n",
        "    test_df_list = []\n",
        "\n",
        "    for file in train_files:\n",
        "        df = pd.read_csv(file)\n",
        "        train_df_list.append(df)\n",
        "    train_df = pd.concat(train_df_list).reset_index(drop=True)\n",
        "\n",
        "    # 사람 카운트 추가\n",
        "    train_df = count_people_from_keypoints(train_df)\n",
        "    train_df.to_csv(train_csv, index=False)\n",
        "\n",
        "    for file in val_files:\n",
        "        df = pd.read_csv(file)\n",
        "        val_df_list.append(df)\n",
        "    val_df = pd.concat(val_df_list).reset_index(drop=True)\n",
        "\n",
        "    # 사람 카운트 추가\n",
        "    val_df = count_people_from_keypoints(val_df)\n",
        "    val_df.to_csv(val_csv, index=False)\n",
        "\n",
        "    for file in test_files:\n",
        "        df = pd.read_csv(file)\n",
        "        test_df_list.append(df)\n",
        "    test_df = pd.concat(test_df_list).reset_index(drop=True)\n",
        "\n",
        "    # 사람 카운트 추가\n",
        "    test_df = count_people_from_keypoints(test_df)\n",
        "    test_df.to_csv(test_csv, index=False)\n",
        "\n",
        "    print(f\"Train, Val, Test 파일들이 각각 {train_csv}, {val_csv}, {test_csv}로 저장되었습니다.\")\n",
        "\n",
        "# 함수 실행\n",
        "train_csv = '/content/drive/MyDrive/논문주제/train1.csv'. # train, train1\n",
        "val_csv = '/content/drive/MyDrive/논문주제/val1.csv'. # val, val1\n",
        "test_csv = '/content/drive/MyDrive/논문주제/test1.csv' # test, test1\n",
        "\n",
        "split_files_into_single_csv(files, train_csv, val_csv, test_csv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQu-Ta-bEbq8",
        "outputId": "3493c32e-df84-4fd8-aef1-884cd97221e6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train, Val, Test 파일들이 각각 /content/drive/MyDrive/논문주제/train1.csv, /content/drive/MyDrive/논문주제/val1.csv, /content/drive/MyDrive/논문주제/test1.csv로 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # 필요한 라이브러리 불러오기\n",
        "# import pandas as pd\n",
        "\n",
        "# # 파일 경로 설정\n",
        "# train_csv = '/content/drive/MyDrive/논문주제/train_filled.csv'\n",
        "# val_csv = '/content/drive/MyDrive/논문주제/train_filled.csv'\n",
        "# test_csv = '/content/drive/MyDrive/논문주제/train_filled.csv'\n",
        "\n",
        "# # CSV 파일 읽어오기\n",
        "# train_df = pd.read_csv(train_csv)\n",
        "# val_df = pd.read_csv(val_csv)\n",
        "# test_df = pd.read_csv(test_csv)\n",
        "\n",
        "# def fill_missing_person_data(df):\n",
        "#     # 'target_person' 관련 열과 'closest_person' 관련 열을 구분\n",
        "#     target_cols = [col for col in df.columns if 'target_person' in col]\n",
        "#     closest_cols = [col.replace('target_person', 'closest_person') for col in target_cols]\n",
        "\n",
        "#     # 첫 번째 사람 관절 각도 및 유클리드 거리 관련 열\n",
        "#     target_angles_distances = ['left_elbow_angle_1', 'right_elbow_angle_1',\n",
        "#                                'left_knee_angle_1', 'right_knee_angle_1',\n",
        "#                                'left_shoulder_left_elbow_dist_1', 'right_shoulder_right_elbow_dist_1',\n",
        "#                                'left_hip_left_knee_dist_1', 'right_hip_right_knee_dist_1']\n",
        "\n",
        "#     # 두 번째 사람 관절 각도 및 유클리드 거리 관련 열\n",
        "#     closest_angles_distances = ['left_elbow_angle_2', 'right_elbow_angle_2',\n",
        "#                                 'left_knee_angle_2', 'right_knee_angle_2',\n",
        "#                                 'left_shoulder_left_elbow_dist_2', 'right_shoulder_right_elbow_dist_2',\n",
        "#                                 'left_hip_left_knee_dist_2', 'right_hip_right_knee_dist_2']\n",
        "\n",
        "#     # 'target_person'의 값이 NaN일 경우 'closest_person'의 값으로 채움\n",
        "#     for t_col, c_col in zip(target_cols, closest_cols):\n",
        "#         df[t_col].fillna(df[c_col], inplace=True)\n",
        "\n",
        "#     # 'closest_person'의 값이 NaN일 경우 'target_person'의 값으로 채움\n",
        "#     for t_col, c_col in zip(target_cols, closest_cols):\n",
        "#         df[c_col].fillna(df[t_col], inplace=True)\n",
        "\n",
        "#     return df\n",
        "\n",
        "# # 각 데이터셋에 결측값 처리 적용\n",
        "# train_df = fill_missing_person_data(train_df)\n",
        "# val_df = fill_missing_person_data(val_df)\n",
        "# test_df = fill_missing_person_data(test_df)\n",
        "\n",
        "# # 결측치 처리된 데이터를 확인하고 싶다면 다음과 같은 방법으로 출력 가능\n",
        "# print(train_df.head())\n",
        "# print(val_df.head())\n",
        "# print(test_df.head())\n",
        "\n",
        "# # 필요한 경우, 다시 CSV 파일로 저장할 수 있습니다.\n",
        "# train_df.to_csv('/content/drive/MyDrive/논문주제/train_filled.csv', index=False)\n",
        "# val_df.to_csv('/content/drive/MyDrive/논문주제/val_filled.csv', index=False)\n",
        "# test_df.to_csv('/content/drive/MyDrive/논문주제/test_filled.csv', index=False)"
      ],
      "metadata": {
        "id": "1pgIkh9BuekA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "\n",
        "# # 관절 각도 및 거리 계산 함수\n",
        "# def calculate_angle(point1, point2, point3):\n",
        "#     vector1 = np.array([point1[0] - point2[0], point1[1] - point2[1]])\n",
        "#     vector2 = np.array([point3[0] - point2[0], point3[1] - point2[1]])\n",
        "#     unit_vector1 = vector1 / np.linalg.norm(vector1)\n",
        "#     unit_vector2 = vector2 / np.linalg.norm(vector2)\n",
        "#     dot_product = np.dot(unit_vector1, unit_vector2)\n",
        "#     angle = np.arccos(dot_product)\n",
        "#     return np.degrees(angle)\n",
        "\n",
        "# def calculate_euclidean_distance(point1, point2):\n",
        "#     return np.linalg.norm(np.array(point1) - np.array(point2))\n",
        "\n",
        "# def recalculate_joint_data(df):\n",
        "#     for index, row in df.iterrows():\n",
        "#         keypoints_1 = [\n",
        "#             [row[f'target_person_{part}_x'], row[f'target_person_{part}_y']] for part in\n",
        "#             ['left_wrist', 'left_elbow', 'left_shoulder', 'right_wrist', 'right_elbow', 'right_shoulder', 'left_knee', 'left_hip', 'right_knee', 'right_hip']\n",
        "#         ]\n",
        "\n",
        "#         # 관절 각도 재계산\n",
        "#         row['left_elbow_angle_1'] = calculate_angle(keypoints_1[0], keypoints_1[1], keypoints_1[2])\n",
        "#         row['right_elbow_angle_1'] = calculate_angle(keypoints_1[3], keypoints_1[4], keypoints_1[5])\n",
        "#         row['left_knee_angle_1'] = calculate_angle(keypoints_1[6], keypoints_1[7], keypoints_1[8])\n",
        "#         row['right_knee_angle_1'] = calculate_angle(keypoints_1[8], keypoints_1[9], keypoints_1[6])\n",
        "\n",
        "#         # 유클리드 거리 재계산\n",
        "#         row['left_shoulder_left_elbow_dist_1'] = calculate_euclidean_distance(keypoints_1[2], keypoints_1[1])\n",
        "#         row['right_shoulder_right_elbow_dist_1'] = calculate_euclidean_distance(keypoints_1[5], keypoints_1[4])\n",
        "#         row['left_hip_left_knee_dist_1'] = calculate_euclidean_distance(keypoints_1[7], keypoints_1[6])\n",
        "#         row['right_hip_right_knee_dist_1'] = calculate_euclidean_distance(keypoints_1[9], keypoints_1[8])\n",
        "\n",
        "#         # 두 번째 사람에 대한 계산 (만약 데이터가 있다면)\n",
        "#         if pd.notna(row['closest_person_nose_x']):\n",
        "#             keypoints_2 = [\n",
        "#                 [row[f'closest_person_{part}_x'], row[f'closest_person_{part}_y']] for part in\n",
        "#                 ['left_wrist', 'left_elbow', 'left_shoulder', 'right_wrist', 'right_elbow', 'right_shoulder', 'left_knee', 'left_hip', 'right_knee', 'right_hip']\n",
        "#             ]\n",
        "\n",
        "#             # 관절 각도 재계산\n",
        "#             row['left_elbow_angle_2'] = calculate_angle(keypoints_2[0], keypoints_2[1], keypoints_2[2])\n",
        "#             row['right_elbow_angle_2'] = calculate_angle(keypoints_2[3], keypoints_2[4], keypoints_2[5])\n",
        "#             row['left_knee_angle_2'] = calculate_angle(keypoints_2[6], keypoints_2[7], keypoints_2[8])\n",
        "#             row['right_knee_angle_2'] = calculate_angle(keypoints_2[8], keypoints_2[9], keypoints_2[6])\n",
        "\n",
        "#             # 유클리드 거리 재계산\n",
        "#             row['left_shoulder_left_elbow_dist_2'] = calculate_euclidean_distance(keypoints_2[2], keypoints_2[1])\n",
        "#             row['right_shoulder_right_elbow_dist_2'] = calculate_euclidean_distance(keypoints_2[5], keypoints_2[4])\n",
        "#             row['left_hip_left_knee_dist_2'] = calculate_euclidean_distance(keypoints_2[7], keypoints_2[6])\n",
        "#             row['right_hip_right_knee_dist_2'] = calculate_euclidean_distance(keypoints_2[9], keypoints_2[8])\n",
        "\n",
        "#     return df\n",
        "\n",
        "# def update_csv_with_recalculated_data(csv_file_path):\n",
        "#     # 기존 CSV 파일 로드\n",
        "#     df = pd.read_csv(csv_file_path)\n",
        "\n",
        "#     # 관절 각도 및 거리 재계산\n",
        "#     df_updated = recalculate_joint_data(df)\n",
        "\n",
        "#     # CSV 파일 덮어쓰기\n",
        "#     df_updated.to_csv(csv_file_path, index=False)\n",
        "#     print(f'Updated CSV file saved to {csv_file_path}')\n",
        "\n",
        "# def update_all_datasets(train_csv_path, val_csv_path, test_csv_path):\n",
        "#     # Train CSV 파일 업데이트\n",
        "#     print(\"Updating train dataset...\")\n",
        "#     update_csv_with_recalculated_data(train_csv_path)\n",
        "\n",
        "#     # Validation CSV 파일 업데이트\n",
        "#     print(\"Updating validation dataset...\")\n",
        "#     update_csv_with_recalculated_data(val_csv_path)\n",
        "\n",
        "#     # Test CSV 파일 업데이트\n",
        "#     print(\"Updating test dataset...\")\n",
        "#     update_csv_with_recalculated_data(test_csv_path)\n",
        "\n",
        "# # 각 CSV 파일 경로\n",
        "# train_csv = '/content/drive/MyDrive/논문주제/train_filled.csv'\n",
        "# val_csv = '/content/drive/MyDrive/논문주제/val_filled.csv'\n",
        "# test_csv = '/content/drive/MyDrive/논문주제/test_filled.csv'\n",
        "\n",
        "# # 모든 CSV 파일 업데이트 실행\n",
        "# update_all_datasets(train_csv, val_csv, test_csv)"
      ],
      "metadata": {
        "id": "wYS1dhEnrn8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tP9o6dy9dvdb"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}